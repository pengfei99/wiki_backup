a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1574347281;s:8:"modified";i:1574413979;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1574413979;s:2:"ip";s:14:"159.84.108.117";s:4:"type";s:1:"E";s:2:"id";s:41:"employes:pengfei.liu:big_data:hdp:lesson3";s:4:"user";s:4:"pliu";s:3:"sum";s:0:"";s:5:"extra";s:0:"";s:10:"sizechange";i:1142;}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:33:"Lesson3: Handle unstructured data";s:11:"description";a:2:{s:15:"tableofcontents";a:15:{i:0;a:4:{s:3:"hid";s:31:"lesson3handle_unstructured_data";s:5:"title";s:33:"Lesson3: Handle unstructured data";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:11:"data_source";s:5:"title";s:15:"3.1 Data source";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:38:"read_the_log_file_and_give_it_a_schema";s:5:"title";s:42:"3.2 Read the log file and give it a schema";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:3;a:4:{s:3:"hid";s:16:"analyze_the_data";s:5:"title";s:20:"3.3 Analyze the data";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:4;a:4:{s:3:"hid";s:14:"clean_the_data";s:5:"title";s:18:"3.4 Clean the data";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:5;a:4:{s:3:"hid";s:23:"save_the_result_to_hive";s:5:"title";s:27:"3.5 Save the result to hive";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:6;a:4:{s:3:"hid";s:47:"write_data_frame_as_hive_table_in_spark_catalog";s:5:"title";s:47:"Write data frame as hive table in spark catalog";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:7;a:4:{s:3:"hid";s:35:"export_csv_and_load_to_hive_catalog";s:5:"title";s:35:"Export csv and load to hive catalog";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:8;a:4:{s:3:"hid";s:57:"full_code_for_creating_the_product_visit_number_dataframe";s:5:"title";s:61:"3.6 Full code for creating the product visit number dataframe";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:9;a:4:{s:3:"hid";s:48:"join_with_the_product_revenu_to_find_the_anomaly";s:5:"title";s:52:"3.7 Join with the product_revenu to find the anomaly";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:10;a:4:{s:3:"hid";s:15:"common_problems";s:5:"title";s:15:"Common problems";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:11;a:4:{s:3:"hid";s:57:"file_format_does_not_match_when_load_data_into_hive_table";s:5:"title";s:59:"1.File format does not match when load data into hive table";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:12;a:4:{s:3:"hid";s:7:"symptom";s:5:"title";s:7:"Symptom";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:13;a:4:{s:3:"hid";s:14:"fault_locating";s:5:"title";s:14:"Fault locating";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:14;a:4:{s:3:"hid";s:8:"solution";s:5:"title";s:8:"Solution";s:4:"type";s:2:"ul";s:5:"level";i:3;}}s:8:"abstract";s:310:"Lesson3: Handle unstructured data

In this tutorial, we will learn how to use spark to read unstructured data and convert them to structure data.

3.1 Data source

The source data is generated by an apache web server, which is the access log of a web site. The following shows the first five lines of the file.";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:8:"relation";a:1:{s:10:"firstimage";s:0:"";}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1574347281;s:8:"modified";i:1574413979;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1574413979;s:2:"ip";s:14:"159.84.108.117";s:4:"type";s:1:"E";s:2:"id";s:41:"employes:pengfei.liu:big_data:hdp:lesson3";s:4:"user";s:4:"pliu";s:3:"sum";s:0:"";s:5:"extra";s:0:"";s:10:"sizechange";i:1142;}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}