a:2:{s:7:"current";a:8:{s:4:"date";a:2:{s:7:"created";i:1515427843;s:8:"modified";i:1515427843;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1515427843;s:2:"ip";s:14:"134.158.37.239";s:4:"type";s:1:"C";s:2:"id";s:50:"employes:pengfei.liu:big_data:spark:spark_hbase_io";s:4:"user";s:4:"pliu";s:3:"sum";s:7:"created";s:5:"extra";s:0:"";s:10:"sizechange";i:6377;}s:5:"title";s:38:"Use spark to get and set data in HBase";s:11:"description";a:2:{s:15:"tableofcontents";a:1:{i:0;a:4:{s:3:"hid";s:38:"use_spark_to_get_and_set_data_in_hbase";s:5:"title";s:38:"Use spark to get and set data in HBase";s:4:"type";s:2:"ul";s:5:"level";i:1;}}s:8:"abstract";s:292:"Use spark to get and set data in HBase

In this example, we suppose you have a local hadoop cluster runs on localhost:9000 and hbase runs on top of it. In a real Hbase environment, the Hbase uses zookeeper quorum to coordinate HMaster and HRegionServer.
So the code will be a little different";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:8:"relation";a:1:{s:10:"firstimage";s:0:"";}}s:10:"persistent";a:4:{s:4:"date";a:1:{s:7:"created";i:1515427843;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1515427843;s:2:"ip";s:14:"134.158.37.239";s:4:"type";s:1:"C";s:2:"id";s:50:"employes:pengfei.liu:big_data:spark:spark_hbase_io";s:4:"user";s:4:"pliu";s:3:"sum";s:7:"created";s:5:"extra";s:0:"";s:10:"sizechange";i:6377;}}}