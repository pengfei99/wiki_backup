a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1520239026;s:8:"modified";i:1520243409;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:13:"Spark dataset";s:11:"description";a:2:{s:15:"tableofcontents";a:1:{i:0;a:4:{s:3:"hid";s:13:"spark_dataset";s:5:"title";s:13:"Spark dataset";s:4:"type";s:2:"ul";s:5:"level";i:1;}}s:8:"abstract";s:503:"Spark dataset

The Apache Spark Dataset API provides a type-safe, object-oriented programming interface. 

In Spark 2.0, Dataset API and DataFrame API are unified. In Scala, DataFrame becomes a type alias for Dataset[Row], while Java API users must replace DataFrame with Dataset<Row>. Both the typed transformations (e.g., map, filter, and groupByKey) and untyped transformations (e.g., select and groupBy) are available on the Dataset class. Since compile-time type-safety in Python and R is not a â€¦";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:8:"relation";a:1:{s:10:"firstimage";s:0:"";}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1520239026;s:8:"modified";i:1520243409;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}