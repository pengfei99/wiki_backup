a:2:{s:7:"current";a:8:{s:4:"date";a:2:{s:7:"created";i:1515659985;s:8:"modified";i:1598891490;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:5:"title";s:23:"Data structure overview";s:11:"description";a:2:{s:15:"tableofcontents";a:1:{i:0;a:4:{s:3:"hid";s:23:"data_structure_overview";s:5:"title";s:23:"Data structure overview";s:4:"type";s:2:"ul";s:5:"level";i:1;}}s:8:"abstract";s:385:"Data structure overview

Generally speaking, Spark provides 3 main abstractions to work with it. First, we will provide you with a holistic view of all of them in one place. Second, we will explore each option with examples.

	*  RDD (Resilient Distributed Dataset). The main approach to work with unstructured data. Pretty similar to a distributed collection that is not always typed.";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:8:"relation";a:1:{s:10:"firstimage";s:0:"";}}s:10:"persistent";a:4:{s:4:"date";a:1:{s:7:"created";i:1515659985;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;}}