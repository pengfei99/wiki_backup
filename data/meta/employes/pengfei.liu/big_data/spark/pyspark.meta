a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1556635897;s:8:"modified";i:1601363153;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:23:"Install and use pyspark";s:11:"description";a:2:{s:15:"tableofcontents";a:13:{i:0;a:4:{s:3:"hid";s:23:"install_and_use_pyspark";s:5:"title";s:23:"Install and use pyspark";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:27:"install_python_dependencies";s:5:"title";s:29:"1.Install python dependencies";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:13:"install_conda";s:5:"title";s:17:"1.1 Install conda";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:3;a:4:{s:3:"hid";s:38:"create_a_conda_virtual_env_for_pyspark";s:5:"title";s:42:"1.2 Create a conda virtual env for pyspark";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:4;a:4:{s:3:"hid";s:25:"install_required_packages";s:5:"title";s:29:"1.3 install required packages";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:5;a:4:{s:3:"hid";s:22:"install_java_and_scala";s:5:"title";s:24:"2 Install Java and Scala";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:6;a:4:{s:3:"hid";s:13:"install_spark";s:5:"title";s:16:"3. Install spark";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:7;a:4:{s:3:"hid";s:15:"edit_the_bashrc";s:5:"title";s:19:"4. Edit the .bashrc";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:8;a:4:{s:3:"hid";s:29:"test_your_pyspark_via_jupyter";s:5:"title";s:32:"5. Test your pyspark via Jupyter";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:9;a:4:{s:3:"hid";s:48:"add_spylon_kernel_into_jupyter_for_scala_support";s:5:"title";s:51:"6. Add spylon kernel into Jupyter for scala support";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:10;a:4:{s:3:"hid";s:22:"use_pyspark_in_pycharm";s:5:"title";s:22:"Use pyspark in pycharm";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:11;a:4:{s:3:"hid";s:28:"pycharm_embedded_interpreter";s:5:"title";s:31:"1. pycharm embedded interpreter";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:12;a:4:{s:3:"hid";s:56:"manually_add_user-provided_spark_installation_to_pycharm";s:5:"title";s:59:"2. Manually add user-provided Spark installation to pycharm";s:4:"type";s:2:"ul";s:5:"level";i:2;}}s:8:"abstract";s:365:"Install and use pyspark

1.Install python dependencies

1.1 Install conda

To install and use conda, please go check Anaconda documents

1.2 Create a conda virtual env for pyspark


# list existing env
conda env list

# create an env
conda create --name spark --channel conda-forge python=3.8

# activate env
source activate spark

# deactivate env
conda deactivate";}s:8:"relation";a:2:{s:10:"references";a:3:{s:39:"employes:pengfei.liu:python:conda:start";b:1;s:37:"employes:pengfei.liu:java:install_jdk";b:1;s:31:"employes:pengfei.liu:java:scala";b:1;}s:10:"firstimage";s:0:"";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1556635897;s:8:"modified";i:1601363153;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}