a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1514206270;s:8:"modified";i:1599639459;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:32:"Install spark on multi node mode";s:11:"description";a:2:{s:15:"tableofcontents";a:16:{i:0;a:4:{s:3:"hid";s:32:"install_spark_on_multi_node_mode";s:5:"title";s:32:"Install spark on multi node mode";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:11:"pre-requise";s:5:"title";s:11:"Pre-requise";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:16:"get_spark_source";s:5:"title";s:16:"Get spark source";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:3;a:4:{s:3:"hid";s:15:"configure_spark";s:5:"title";s:15:"Configure spark";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:4;a:4:{s:3:"hid";s:11:"spark-mesos";s:5:"title";s:11:"Spark-Mesos";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:5;a:4:{s:3:"hid";s:10:"spark-yarn";s:5:"title";s:10:"Spark-YARN";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:6;a:4:{s:3:"hid";s:32:"ibm_platform_conductor_for_spark";s:5:"title";s:32:"IBM Platform Conductor For Spark";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:7;a:4:{s:3:"hid";s:16:"spark_standalone";s:5:"title";s:16:"Spark Standalone";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:8;a:4:{s:3:"hid";s:22:"configure_spark_master";s:5:"title";s:22:"Configure spark master";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:9;a:4:{s:3:"hid";s:22:"configure_spark_worker";s:5:"title";s:22:"Configure spark worker";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:10;a:4:{s:3:"hid";s:13:"run_the_spark";s:5:"title";s:13:"Run the spark";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:11;a:4:{s:3:"hid";s:16:"check_the_status";s:5:"title";s:16:"Check the status";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:12;a:4:{s:3:"hid";s:3:"faq";s:5:"title";s:3:"FAQ";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:13;a:4:{s:3:"hid";s:20:"spark_shuffle_failed";s:5:"title";s:20:"Spark shuffle failed";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:14;a:4:{s:3:"hid";s:21:"losing_spark_pid_file";s:5:"title";s:21:"Losing spark pid file";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:15;a:4:{s:3:"hid";s:34:"spark_use_all_disk_in_the_sever_vm";s:5:"title";s:34:"Spark use all disk in the sever/vm";s:4:"type";s:2:"ul";s:5:"level";i:2;}}s:8:"abstract";s:503:"Install spark on multi node mode

Pre-requise

Install jdk Install oracle jdk on ubuntu 16.04

Install scala Install scala on centos

Get spark source

You can get your required version from here

<https://spark.apache.org/downloads.html>


#suppose you have downloaded spark and put it under /opt/spark/spark-2.2.0

[hadoop@CCLinDataWHD01 spark-2.2.0]$ pwd
/opt/spark/spark-2.2.0
[hadoop@CCLinDataWHD01 spark-2.2.0]$ ls -lah
total 92K
drwxr-xr-x 13 hadoop hadoop 4.0K Dec 25 11:22 .
drwxr-xr-x  3 haâ€¦";}s:8:"relation";a:2:{s:10:"references";a:3:{s:37:"employes:pengfei.liu:java:install_jdk";b:1;s:31:"employes:pengfei.liu:java:scala";b:1;s:29:"employes:pengfei.liu:big_data";b:0;}s:10:"firstimage";s:0:"";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1514206270;s:8:"modified";i:1599639459;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}