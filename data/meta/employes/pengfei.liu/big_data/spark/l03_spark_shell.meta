a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1592906364;s:8:"modified";i:1592987351;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1592987351;s:2:"ip";s:14:"213.44.168.220";s:4:"type";s:1:"E";s:2:"id";s:51:"employes:pengfei.liu:big_data:spark:l03_spark_shell";s:4:"user";s:4:"pliu";s:3:"sum";s:37:"[3.1.3 Usefull command of the shell] ";s:5:"extra";s:0:"";s:10:"sizechange";i:104;}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:50:"Lesson03: Introduction of spark shell and spark UI";s:11:"description";a:2:{s:15:"tableofcontents";a:13:{i:0;a:4:{s:3:"hid";s:48:"lesson03introduction_of_spark_shell_and_spark_ui";s:5:"title";s:50:"Lesson03: Introduction of spark shell and spark UI";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:19:"start_a_spark_shell";s:5:"title";s:23:"3.1 start a spark shell";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:11:"scala_shell";s:5:"title";s:17:"3.1.1 Scala shell";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:3;a:4:{s:3:"hid";s:12:"python_shell";s:5:"title";s:18:"3.1.2 Python shell";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:4;a:4:{s:3:"hid";s:28:"usefull_command_of_the_shell";s:5:"title";s:34:"3.1.3 Usefull command of the shell";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:5;a:4:{s:3:"hid";s:28:"understand_the_spark_context";s:5:"title";s:32:"3.2 understand the spark context";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:6;a:4:{s:3:"hid";s:30:"run_a_simple_spark_application";s:5:"title";s:34:"3.3 Run a simple spark application";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:7;a:4:{s:3:"hid";s:40:"data_flow_of_the_above_word_count_script";s:5:"title";s:46:"3.3.1 Data flow of the above word count script";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:8;a:4:{s:3:"hid";s:20:"explore_spark_web_ui";s:5:"title";s:24:"3.4 Explore spark web UI";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:9;a:4:{s:3:"hid";s:6:"stages";s:5:"title";s:12:"3.4.1 Stages";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:10;a:4:{s:3:"hid";s:24:"understand_spark_session";s:5:"title";s:28:"3.5 Understand spark session";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:11;a:4:{s:3:"hid";s:26:"create_simple_rdd_in_spark";s:5:"title";s:26:"Create simple RDD in spark";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:12;a:4:{s:3:"hid";s:21:"flatmap_vs_map_in_rdd";s:5:"title";s:21:"Flatmap vs map in RDD";s:4:"type";s:2:"ul";s:5:"level";i:3;}}s:8:"abstract";s:285:"Lesson03: Introduction of spark shell and spark UI

After you downloading the spark binary files, you can find following folders inside it

	*  bin: It contains the various executable files to bring up a Spark shell in Scala or python, submit Spark applications, and run Spark examples";}s:8:"relation";a:2:{s:5:"media";a:5:{s:66:"employes:pengfei.liu:big_data:spark:spark_word_count_data_flow.png";b:1;s:52:"employes:pengfei.liu:big_data:spark:spark_web_ui.png";b:1;s:52:"employes:pengfei.liu:big_data:spark:spark_stages.png";b:1;s:58:"employes:pengfei.liu:big_data:spark:spark_stage_detail.png";b:1;s:61:"employes:pengfei.liu:big_data:spark:spark_word_count_dag1.png";b:1;}s:10:"firstimage";s:66:"employes:pengfei.liu:big_data:spark:spark_word_count_data_flow.png";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1592906364;s:8:"modified";i:1592987351;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1592987351;s:2:"ip";s:14:"213.44.168.220";s:4:"type";s:1:"E";s:2:"id";s:51:"employes:pengfei.liu:big_data:spark:l03_spark_shell";s:4:"user";s:4:"pliu";s:3:"sum";s:37:"[3.1.3 Usefull command of the shell] ";s:5:"extra";s:0:"";s:10:"sizechange";i:104;}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}