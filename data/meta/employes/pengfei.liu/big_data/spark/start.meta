a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1555491398;s:8:"modified";i:1599577615;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1599577615;s:2:"ip";s:9:"127.0.0.1";s:4:"type";s:1:"E";s:2:"id";s:41:"employes:pengfei.liu:big_data:spark:start";s:4:"user";s:4:"pliu";s:3:"sum";s:21:"[Spark Optimization] ";s:5:"extra";s:0:"";s:10:"sizechange";i:84;}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:14:"Spark doc list";s:11:"description";a:2:{s:15:"tableofcontents";a:8:{i:0;a:4:{s:3:"hid";s:14:"spark_doc_list";s:5:"title";s:14:"Spark doc list";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:59:"lessons_for_spark_introduction_key_components_and_internals";s:5:"title";s:60:"Lessons for spark introduction, key components and internals";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:19:"spark_infratructure";s:5:"title";s:19:"Spark infratructure";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:3;a:4:{s:3:"hid";s:20:"spark_data_structure";s:5:"title";s:20:"Spark data structure";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:4;a:4:{s:3:"hid";s:8:"spark_io";s:5:"title";s:8:"Spark IO";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:5;a:4:{s:3:"hid";s:15:"spark_streaming";s:5:"title";s:15:"Spark streaming";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:6;a:4:{s:3:"hid";s:25:"spark_application_example";s:5:"title";s:25:"Spark application example";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:7;a:4:{s:3:"hid";s:18:"spark_optimization";s:5:"title";s:18:"Spark Optimization";s:4:"type";s:2:"ul";s:5:"level";i:2;}}s:8:"abstract";s:503:"Spark doc list

Lessons for spark introduction, key components and internals

Lesson01: Spark basics

Lesson02: Spark unified stack and applicatioins

Lesson03: Introduction of spark shell and spark UI

spark user define fonction use in sql and dataframe : 
Spark user define function

Spark infratructure

Install spark on multi node mode

Install a devlopment envirionment for spark

Spark data structure

1. Overview of spark data structure Data structure overview

2. Spark RDD Spark RDD

3. Sparâ€¦";}s:8:"relation";a:2:{s:10:"references";a:23:{s:58:"employes:pengfei.liu:big_data:spark:l01_spark_introduction";b:1;s:51:"employes:pengfei.liu:big_data:spark:l02_spark_stack";b:1;s:51:"employes:pengfei.liu:big_data:spark:l03_spark_shell";b:1;s:45:"employes:pengfei.liu:big_data:spark:spark_udf";b:1;s:60:"employes:pengfei.liu:big_data:spark:spark_multi_node_cluster";b:1;s:57:"employes:pengfei.liu:big_data:spark:spark_dev_environment";b:1;s:59:"employes:pengfei.liu:big_data:spark:data_structure_overview";b:1;s:45:"employes:pengfei.liu:big_data:spark:spark_rdd";b:1;s:51:"employes:pengfei.liu:big_data:spark:spark_dataframe";b:1;s:49:"employes:pengfei.liu:big_data:spark:spark_dataset";b:1;s:52:"employes:pengfei.liu:big_data:spark:spark_partitions";b:1;s:49:"employes:pengfei.liu:big_data:spark:spark_file_io";b:1;s:51:"employes:pengfei.liu:big_data:spark:spark_parquetio";b:1;s:50:"employes:pengfei.liu:big_data:spark:spark_hbase_io";b:1;s:49:"employes:pengfei.liu:big_data:spark:spark_jdbc_io";b:1;s:66:"employes:pengfei.liu:big_data:spark:spark_streaming:file_streaming";b:1;s:68:"employes:pengfei.liu:big_data:spark:spark_streaming:socket_streaming";b:1;s:67:"employes:pengfei.liu:big_data:spark:spark_streaming:kafka_streaming";b:1;s:67:"employes:pengfei.liu:big_data:spark:spark_streaming:flume_streaming";b:1;s:62:"employes:pengfei.liu:big_data:spark:spark_usecase:sf_fire_call";b:1;s:72:"employes:pengfei.liu:big_data:spark:spark_usecase:sf_client_satisfaction";b:1;s:70:"employes:pengfei.liu:big_data:spark:spark_usecase:inverted_index_shake";b:1;s:60:"employes:pengfei.liu:big_data:spark:spark_optimization:start";b:1;}s:10:"firstimage";s:0:"";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1555491398;s:8:"modified";i:1599577615;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1599577615;s:2:"ip";s:9:"127.0.0.1";s:4:"type";s:1:"E";s:2:"id";s:41:"employes:pengfei.liu:big_data:spark:start";s:4:"user";s:4:"pliu";s:3:"sum";s:21:"[Spark Optimization] ";s:5:"extra";s:0:"";s:10:"sizechange";i:84;}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}