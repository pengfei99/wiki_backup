a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1511533528;s:8:"modified";i:1532698701;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1532698701;s:2:"ip";s:14:"134.158.37.239";s:4:"type";s:1:"E";s:2:"id";s:45:"employes:pengfei.liu:big_data:spark:spark_rdd";s:4:"user";s:4:"pliu";s:3:"sum";s:0:"";s:5:"extra";s:0:"";s:10:"sizechange";i:2229;}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:9:"Spark RDD";s:11:"description";a:2:{s:15:"tableofcontents";a:16:{i:0;a:4:{s:3:"hid";s:9:"spark_rdd";s:5:"title";s:9:"Spark RDD";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:24:"what_is_apache_spark_rdd";s:5:"title";s:25:"What is Apache Spark RDD?";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:2;a:4:{s:3:"hid";s:24:"decomposing_the_name_rdd";s:5:"title";s:25:"Decomposing the name RDD:";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:3;a:4:{s:3:"hid";s:9:"immutable";s:5:"title";s:9:"Immutable";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:4;a:4:{s:3:"hid";s:11:"partitioned";s:5:"title";s:11:"Partitioned";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:5;a:4:{s:3:"hid";s:14:"fault_tolerant";s:5:"title";s:14:"Fault Tolerant";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:6;a:4:{s:3:"hid";s:9:"interface";s:5:"title";s:9:"Interface";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:7;a:4:{s:3:"hid";s:14:"strongly_typed";s:5:"title";s:14:"Strongly Typed";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:8;a:4:{s:3:"hid";s:9:"in_memory";s:5:"title";s:9:"In memory";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:9;a:4:{s:3:"hid";s:15:"creating_an_rdd";s:5:"title";s:15:"Creating an RDD";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:10;a:4:{s:3:"hid";s:36:"creating_rdd_with_parallelize_method";s:5:"title";s:36:"Creating RDD with parallelize method";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:11;a:4:{s:3:"hid";s:15:"textfile_method";s:5:"title";s:15:"textFile method";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:12;a:4:{s:3:"hid";s:14:"wholetextfiles";s:5:"title";s:14:"wholeTextFiles";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:13;a:4:{s:3:"hid";s:12:"sequencefile";s:5:"title";s:12:"SequenceFile";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:14;a:4:{s:3:"hid";s:14:"rdd_operations";s:5:"title";s:14:"RDD Operations";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:15;a:4:{s:3:"hid";s:15:"transformations";s:5:"title";s:15:"Transformations";s:4:"type";s:2:"ul";s:5:"level";i:3;}}s:8:"abstract";s:461:"Spark RDD

This doc is a copy of <https://data-flair.training/blogs/apache-spark-rdd-tutorial/>. 

What is Apache Spark RDD?

RDD stands for “Resilient Distributed Dataset”. RDD represents a collection of partitioned data elements that can be operated on in parallel. It is defined as an abstract class in the Spark library. Conceptually, RDD is similar to a Scala collection, except that it represents a distributed dataset and it supports lazy operations.";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:8:"relation";a:1:{s:10:"firstimage";s:0:"";}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1511533528;s:8:"modified";i:1532698701;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1532698701;s:2:"ip";s:14:"134.158.37.239";s:4:"type";s:1:"E";s:2:"id";s:45:"employes:pengfei.liu:big_data:spark:spark_rdd";s:4:"user";s:4:"pliu";s:3:"sum";s:0:"";s:5:"extra";s:0:"";s:10:"sizechange";i:2229;}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}