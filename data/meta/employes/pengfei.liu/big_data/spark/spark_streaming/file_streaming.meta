a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1516033367;s:8:"modified";i:1516033413;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:5:"title";s:20:"Spark file Streaming";s:11:"description";a:2:{s:15:"tableofcontents";a:1:{i:0;a:4:{s:3:"hid";s:20:"spark_file_streaming";s:5:"title";s:20:"Spark file Streaming";s:4:"type";s:2:"ul";s:5:"level";i:1;}}s:8:"abstract";s:276:"Spark file Streaming

Spark can monitor a directory, for all new files in the directory, spark can treat it when it was awaken.

Suppose we have a program which writes log file in /tmp/log/. every 30 secs. We want to write a little spark script which counts the number of word";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:8:"relation";a:1:{s:10:"firstimage";s:0:"";}s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1516033367;s:8:"modified";i:1516033413;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}