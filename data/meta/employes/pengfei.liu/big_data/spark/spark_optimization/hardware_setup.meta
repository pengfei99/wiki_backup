a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1599638925;s:8:"modified";i:1600241500;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:28:"Spark cluster hardware setup";s:11:"description";a:2:{s:15:"tableofcontents";a:11:{i:0;a:4:{s:3:"hid";s:28:"spark_cluster_hardware_setup";s:5:"title";s:28:"Spark cluster hardware setup";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:32:"general_rules_for_hardware_setup";s:5:"title";s:35:"0. General rules for hardware setup";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:11:"data_source";s:5:"title";s:14:"1. Data source";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:3;a:4:{s:3:"hid";s:19:"hdfs_as_data_source";s:5:"title";s:23:"1.1 HDFS as data source";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:4;a:4:{s:3:"hid";s:26:"other_external_data_source";s:5:"title";s:30:"1.2 Other external data source";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:5;a:4:{s:3:"hid";s:7:"network";s:5:"title";s:9:"2 Network";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:6;a:4:{s:3:"hid";s:5:"disks";s:5:"title";s:7:"3 Disks";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:7;a:4:{s:3:"hid";s:6:"memory";s:5:"title";s:8:"4 Memory";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:8;a:4:{s:3:"hid";s:21:"jvm_memory_limitation";s:5:"title";s:25:"4.1 JVM memory limitation";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:9;a:4:{s:3:"hid";s:49:"change_the_default_jvm_gc_to_support_large_memory";s:5:"title";s:49:"Change the default JVM GC to support large memory";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:10;a:4:{s:3:"hid";s:9:"cpu_cores";s:5:"title";s:12:"5. CPU Cores";s:4:"type";s:2:"ul";s:5:"level";i:2;}}s:8:"abstract";s:361:"Spark cluster hardware setup

0. General rules for hardware setup

The general rule of thumb for a balanced Spark cluster is 4GB and 1 disk per CPU core. For disk-bound tasks, add more disks per CPU; CPU-bound tasks can get by with fewer disks per CPU. For memory-intensive jobs add more memory. Profile your application so you know what the limiting factor is.";}s:8:"relation";a:2:{s:10:"references";a:2:{s:60:"employes:pengfei.liu:big_data:spark:spark_multi_node_cluster";b:1;s:33:"employes:pengfei.liu:java:java_gc";b:1;}s:10:"firstimage";s:0:"";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1599638925;s:8:"modified";i:1600241500;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}