a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1599644443;s:8:"modified";i:1600419614;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}s:5:"title";s:23:"Spark Job Configuration";s:11:"description";a:2:{s:15:"tableofcontents";a:20:{i:0;a:4:{s:3:"hid";s:23:"spark_job_configuration";s:5:"title";s:23:"Spark Job Configuration";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:18:"data_serialization";s:5:"title";s:21:"1. Data Serialization";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:48:"configure_spark_job_to_use_kryo_as_serialization";s:5:"title";s:52:"1.1 Configure Spark job to use Kryo as serialization";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:3;a:4:{s:3:"hid";s:42:"memory_management_inside_spark_application";s:5:"title";s:45:"2. Memory management inside spark application";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:4;a:4:{s:3:"hid";s:32:"reset_default_memory_region_size";s:5:"title";s:36:"2.1 Reset default memory region size";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:5;a:4:{s:3:"hid";s:30:"determining_memory_consumption";s:5:"title";s:34:"2.2 Determining Memory Consumption";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:6;a:4:{s:3:"hid";s:59:"reduce_memory_consumption_by_choosing_right_data_structures";s:5:"title";s:63:"2.3 Reduce memory consumption by choosing right data structures";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:7;a:4:{s:3:"hid";s:45:"reduce_object_overhead_by_changing_jvm_config";s:5:"title";s:49:"2.4 Reduce object overhead by changing JVM config";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:8;a:4:{s:3:"hid";s:63:"reduce_memory_consumption_by_caching_data_rdd_in_serialize_form";s:5:"title";s:68:"2.5 Reduce memory consumption by caching data(RDD) in serialize form";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:9;a:4:{s:3:"hid";s:16:"spark_partitions";s:5:"title";s:19:"3. Spark partitions";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:10;a:4:{s:3:"hid";s:21:"input_data_partitions";s:5:"title";s:25:"3.1 Input data partitions";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:11;a:4:{s:3:"hid";s:23:"shuffle_data_partitions";s:5:"title";s:27:"3.2 Shuffle data partitions";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:12;a:4:{s:3:"hid";s:22:"output_data_partitions";s:5:"title";s:26:"3.3 Output data partitions";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:13;a:4:{s:3:"hid";s:29:"jvm_garbage_collection_tuning";s:5:"title";s:32:"4. JVM Garbage Collection Tuning";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:14;a:4:{s:3:"hid";s:50:"measuring_the_impact_of_gc_for_all_your_spark_jobs";s:5:"title";s:54:"4.1 Measuring the Impact of GC for all your spark jobs";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:15;a:4:{s:3:"hid";s:25:"basic_jvm_gc_tunning_tips";s:5:"title";s:29:"4.2 Basic JVM GC tunning tips";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:16;a:4:{s:3:"hid";s:34:"deal_with_large_memory_worker_node";s:5:"title";s:38:"4.3 Deal with large memory worker node";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:17;a:4:{s:3:"hid";s:17:"gc_tuning_summery";s:5:"title";s:21:"4.4 GC tuning Summery";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:18;a:4:{s:3:"hid";s:43:"increase_parallelism_on_reading_input_paths";s:5:"title";s:46:"5. Increase Parallelism on reading input paths";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:19;a:4:{s:3:"hid";s:13:"data_locality";s:5:"title";s:16:"6. Data locality";s:4:"type";s:2:"ul";s:5:"level";i:2;}}s:8:"abstract";s:377:"Spark Job Configuration

1. Data Serialization

Spark is a distributed computation engine, which requires send and receive data(objects) through network. Serialization and De-serialization plays an important role in the performance. Formats and data structures that are slow to serialize objects into, or consume a large number of bytes, will greatly slow down the computation.";}s:8:"relation";a:2:{s:10:"references";a:1:{s:33:"employes:pengfei.liu:java:java_gc";b:1;}s:10:"firstimage";s:0:"";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1599644443;s:8:"modified";i:1600419614;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";b:0;s:11:"contributor";a:1:{s:4:"pliu";s:11:"pengfei liu";}}}