a:2:{s:7:"current";a:8:{s:4:"date";a:2:{s:7:"created";i:1530092629;s:8:"modified";i:1530092629;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1530092629;s:2:"ip";s:14:"134.158.37.239";s:4:"type";s:1:"C";s:2:"id";s:56:"employes:pengfei.liu:data_science:nifi:spark_integration";s:4:"user";s:4:"pliu";s:3:"sum";s:7:"created";s:5:"extra";s:0:"";s:10:"sizechange";i:537;}s:5:"title";s:47:"Integrating Apache spark 2.x jobs with NiFi 1.7";s:11:"description";a:2:{s:15:"tableofcontents";a:1:{i:0;a:4:{s:3:"hid";s:45:"integrating_apache_spark_2x_jobs_with_nifi_17";s:5:"title";s:47:"Integrating Apache spark 2.x jobs with NiFi 1.7";s:4:"type";s:2:"ul";s:5:"level";i:1;}}s:8:"abstract";s:408:"Integrating Apache spark 2.x jobs with NiFi 1.7

There are many ways to integrate Apache NiFi and Apache Spark.

We can call Apache Spark Streaming via S2S (Apache NiFi's Site to Site) or Kafka. If you want to execute a regular Apache Spark job, you can do that via Apache Livy which is included in HDP 2.6+. This is how Apache Zeppelin integrates with Apache Spark, so it's secure and a reasonable approach.";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:8:"relation";a:1:{s:10:"firstimage";s:0:"";}}s:10:"persistent";a:4:{s:4:"date";a:1:{s:7:"created";i:1530092629;}s:7:"creator";s:11:"pengfei liu";s:4:"user";s:4:"pliu";s:11:"last_change";a:8:{s:4:"date";i:1530092629;s:2:"ip";s:14:"134.158.37.239";s:4:"type";s:1:"C";s:2:"id";s:56:"employes:pengfei.liu:data_science:nifi:spark_integration";s:4:"user";s:4:"pliu";s:3:"sum";s:7:"created";s:5:"extra";s:0:"";s:10:"sizechange";i:537;}}}