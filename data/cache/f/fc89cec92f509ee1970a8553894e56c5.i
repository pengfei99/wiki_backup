a:295:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:36:"Flume installation and configuration";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:53;}i:4;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:14:"What is Flume?";i:1;i:2;i:2;i:53;}i:2;i:53;}i:5;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:53;}i:6;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:53;}i:7;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:162:"Apache Flume is a tool/service/data ingestion mechanism for collecting aggregating and transporting large amounts of streaming data such as log files, events (etc";}i:2;i:81;}i:8;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:3:"...";}i:2;i:243;}i:9;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:51:") from various sources to a centralized data store.";}i:2;i:246;}i:10;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:297;}i:11;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:297;}i:12;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:158:"Flume is a highly reliable, distributed, and configurable tool. It is principally designed to copy streaming data (log data) from various web servers to HDFS.";}i:2;i:299;}i:13;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:457;}i:14;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:459;}i:15;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:20:"Application of Flume";i:1;i:2;i:2;i:459;}i:2;i:459;}i:16;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:459;}i:17;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:459;}i:18;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:225:"Assume an e-commerce web application wants to analyze the customer behavior from a particular region. To do so, they would need to move the available log data in to Hadoop for analysis. Here, Apache Flume comes to our rescue.";}i:2;i:493;}i:19;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:718;}i:20;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:718;}i:21;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:96:"Flume is used to move the log data generated by application servers into HDFS at a higher speed.";}i:2;i:720;}i:22;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:816;}i:23;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:818;}i:24;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:32:"Advantages and features of Flume";i:1;i:2;i:2;i:818;}i:2;i:818;}i:25;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:818;}i:26;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:864;}i:27;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:19:"Advantages of Flume";i:1;i:3;i:2;i:864;}i:2;i:864;}i:28;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:864;}i:29;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:864;}i:30;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:39:"Here are the advantages of using Flume:";}i:2;i:895;}i:31;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:935;}i:32;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:935;}i:33;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:935;}i:34;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:935;}i:35;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:92:" Using Apache Flume we can store the data in to any of the centralized stores (HBase, HDFS).";}i:2;i:939;}i:36;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1031;}i:37;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1031;}i:38;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1031;}i:39;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1031;}i:40;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:221:" When the rate of incoming data exceeds the rate at which data can be written to the destination, Flume acts as a mediator between data producers and the centralized stores and provides a steady flow of data between them.";}i:2;i:1035;}i:41;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1256;}i:42;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1256;}i:43;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1256;}i:44;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1256;}i:45;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:50:" Flume provides the feature of contextual routing.";}i:2;i:1260;}i:46;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1310;}i:47;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1310;}i:48;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1310;}i:49;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1310;}i:50;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:171:" The transactions in Flume are channel-based where two transactions (one sender and one receiver) are maintained for each message. It guarantees reliable message delivery.";}i:2;i:1314;}i:51;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1485;}i:52;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1485;}i:53;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1485;}i:54;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1485;}i:55;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:75:" Flume is reliable, fault tolerant, scalable, manageable, and customizable.";}i:2;i:1489;}i:56;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1564;}i:57;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1564;}i:58;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:1564;}i:59;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1566;}i:60;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:17:"Features of Flume";i:1;i:3;i:2;i:1566;}i:2;i:1566;}i:61;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:1566;}i:62;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1566;}i:63;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:53:"Some of the notable features of Flume are as follows:";}i:2;i:1595;}i:64;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1649;}i:65;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:1649;}i:66;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1649;}i:67;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1649;}i:68;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:101:" Flume ingests log data from multiple web servers into a centralized store (HDFS, HBase) efficiently.";}i:2;i:1653;}i:69;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1754;}i:70;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1754;}i:71;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1754;}i:72;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1754;}i:73;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:80:" Using Flume, we can get the data from multiple servers immediately into Hadoop.";}i:2;i:1758;}i:74;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1838;}i:75;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1838;}i:76;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1838;}i:77;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1838;}i:78;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:195:" Along with the log files, Flume is also used to import huge volumes of event data produced by social networking sites like Facebook and Twitter, and e-commerce websites like Amazon and Flipkart.";}i:2;i:1842;}i:79;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2037;}i:80;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2037;}i:81;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2037;}i:82;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2037;}i:83;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:62:" Flume supports a large set of sources and destinations types.";}i:2;i:2041;}i:84;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2103;}i:85;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2103;}i:86;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2103;}i:87;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2103;}i:88;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:79:" Flume supports multi-hop flows, fan-in fan-out flows, contextual routing, etc.";}i:2;i:2107;}i:89;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2186;}i:90;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2186;}i:91;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2186;}i:92;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2186;}i:93;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:34:" Flume can be scaled horizontally.";}i:2;i:2190;}i:94;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2224;}i:95;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2224;}i:96;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:2224;}i:97;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2226;}i:98;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:20:"Key concept of Flume";i:1;i:2;i:2;i:2226;}i:2;i:2226;}i:99;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:2226;}i:100;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2226;}i:101;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:23:"Flume has three layer :";}i:2;i:2260;}i:102;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2283;}i:103;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:2283;}i:104;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2283;}i:105;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2283;}i:106;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:" agent ";}i:2;i:2287;}i:107;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"->";}i:2;i:2294;}i:108;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:146:" An agent is an independent process (JVM) in Flume.It collects data from clients or other agents and send them to next destination(sink or agent).";}i:2;i:2296;}i:109;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2442;}i:110;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2442;}i:111;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2442;}i:112;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2442;}i:113;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:" collector ";}i:2;i:2446;}i:114;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"->";}i:2;i:2457;}i:115;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:75:" Collector can combine data from one or many agents, and send it to storage";}i:2;i:2459;}i:116;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2534;}i:117;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2534;}i:118;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2534;}i:119;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2534;}i:120;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:9:" storage ";}i:2;i:2538;}i:121;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"->";}i:2;i:2547;}i:122;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:47:" Storage can be a file, hdfs, Hive, HBase, etc.";}i:2;i:2549;}i:123;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2596;}i:124;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2596;}i:125;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:2596;}i:126;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2598;}i:127;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:25:"Basic components of Flume";i:1;i:3;i:2;i:2598;}i:2;i:2598;}i:128;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:2598;}i:129;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2598;}i:130;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:50:"In one agent, you have the following key concepts.";}i:2;i:2635;}i:131;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2686;}i:132;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:2686;}i:133;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2686;}i:134;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2686;}i:135;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:" Event ";}i:2;i:2690;}i:136;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"->";}i:2;i:2697;}i:137;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:274:" An event is the basic unit of the data transported inside Flume. It contains a payload of byte array that is to be transported from the source to the destination accompanied by optional headers. A typical Flume event would have the following structure (Header+Byte_Payload)";}i:2;i:2699;}i:138;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2973;}i:139;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2973;}i:140;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2973;}i:141;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2973;}i:142;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:" Source ";}i:2;i:2977;}i:143;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"->";}i:2;i:2985;}i:144;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:318:" A source is the component of an Agent which receives data from the data generators and transfers it to one or more channels in the form of Flume events. Apache Flume supports several types of sources and each source receives events from a specified data generator. (e.g. Avro source, Thrift source, twitter 1% source)";}i:2;i:2987;}i:145;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:3305;}i:146;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:3305;}i:147;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:3305;}i:148;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:3305;}i:149;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:9:" Channel ";}i:2;i:3309;}i:150;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"->";}i:2;i:3318;}i:151;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:336:" A channel is a transient store which receives the events from the source and buffers them till they are consumed by sinks. It acts as a bridge between the sources and the sinks. These channels are fully transactional and they can work with any number of sources and sinks. (e.g. JDBC channel, File system channel, Memory channel, etc.)";}i:2;i:3320;}i:152;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:3656;}i:153;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:3656;}i:154;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:3656;}i:155;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:3656;}i:156;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:" Sink ";}i:2;i:3660;}i:157;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"->";}i:2;i:3666;}i:158;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:243:" A sink stores the data into centralized stores like HBase and HDFS. It consumes the data (events) from the channels and delivers it to the destination. The destination of the sink might be another agent or the central stores. (e.g. HDFS sink)";}i:2;i:3668;}i:159;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:3911;}i:160;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:3911;}i:161;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:3911;}i:162;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:3914;}i:163;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:36:"Additional Components of Flume agent";i:1;i:3;i:2;i:3914;}i:2;i:3914;}i:164;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:3914;}i:165;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3914;}i:166;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:223:"What we have discussed above are the primitive components of the agent. In addition to this, we have a few more components that play a vital role in transferring the events from the data generator to the centralized stores.";}i:2;i:3962;}i:167;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4185;}i:168;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4187;}i:169;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:11:"Interceptor";i:1;i:4;i:2;i:4187;}i:2;i:4187;}i:170;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:4187;}i:171;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4187;}i:172;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:101:"Interceptors are used to alter/inspect flume events which are transferred between source and channel.";}i:2;i:4207;}i:173;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4308;}i:174;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4310;}i:175;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:17:"Channel Selectors";i:1;i:4;i:2;i:4310;}i:2;i:4310;}i:176;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:4310;}i:177;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4310;}i:178;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:149:"These are used to determine which channel is to be opted to transfer the data in case of multiple channels. There are two types of channel selectors ";}i:2;i:4337;}i:179;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4487;}i:180;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:4487;}i:181;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4487;}i:182;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4487;}i:183;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:4491;}i:184;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:4492;}i:185;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:25:"Default channel selectors";}i:2;i:4494;}i:186;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:4519;}i:187;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:106:" − These are also known as replicating channel selectors they replicates all the events in each channel.";}i:2;i:4521;}i:188;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4627;}i:189;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4627;}i:190;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4627;}i:191;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4627;}i:192;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:4631;}i:193;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:4632;}i:194;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:30:"Multiplexing channel selectors";}i:2;i:4634;}i:195;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:4664;}i:196;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:97:" − These decides the channel to send an event based on the address in the header of that event.";}i:2;i:4666;}i:197;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4763;}i:198;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4763;}i:199;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:4763;}i:200;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4765;}i:201;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:15:"Sink Processors";i:1;i:4;i:2;i:4765;}i:2;i:4765;}i:202;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:4765;}i:203;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4765;}i:204;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:192:"These are used to invoke a particular sink from the selected group of sinks. These are used to create failover paths for your sinks or load balance events across multiple sinks from a channel.";}i:2;i:4790;}i:205;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4982;}i:206;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4986;}i:207;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:13:"Install flume";i:1;i:2;i:2;i:4986;}i:2;i:4986;}i:208;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:4986;}i:209;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4986;}i:210;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:52:"1. Download the flume tar ball from the flume site (";}i:2;i:5013;}i:211;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:41:"https://www.apache.org/dist/flume/stable/";i:1;N;}i:2;i:5065;}i:212;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:").";}i:2;i:5106;}i:213;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5108;}i:214;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5108;}i:215;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:40:"The current stable version is flume 1.8.";}i:2;i:5111;}i:216;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5151;}i:217;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5151;}i:218;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:38:"Put the unziped flume under /opt/flume";}i:2;i:5153;}i:219;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5197;}i:220;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:521:"
#flume home path
[hadoop@localhost flume-1.8.0]$ ls
bin        conf      doap_Flume.rdf  lib      NOTICE     RELEASE-NOTES
CHANGELOG  DEVNOTES  docs            LICENSE  README.md  tools
[hadoop@localhost flume-1.8.0]$ pwd
/opt/flume/flume-1.8.0

#add the flume home to the path
vim /etc/profile.d/flume.sh

export FLUME_HOME=/opt/flume/flume-1.8.0
export PATH=$PATH:$FLUME_HOME/bin

# check the flume home
[root@localhost profile.d]# source flume.sh 
[root@localhost profile.d]# echo $FLUME_HOME
/opt/flume/flume-1.8.0

";i:1;N;i:2;N;}i:2;i:5197;}i:221;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:5728;}i:222;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:15:"Configure flume";i:1;i:2;i:2;i:5728;}i:2;i:5728;}i:223;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:5728;}i:224;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:1094:"
[hadoop@localhost conf]$ cp flume-env.sh.template flume-env.sh
[hadoop@localhost conf]$ vim flume-env.sh

#add the export java home
export JAVA_HOME=/opt/JAVA/jdk1.8.0_144

# Check the flume version
[hadoop@localhost flume-1.8.0]$ sh $FLUME_HOME/bin/flume-ng version 
Error: Could not find or load main class org.apache.flume.tools.GetJavaProperty
Flume 1.8.0
Source code repository: https://git-wip-us.apache.org/repos/asf/flume.git
Revision: 99f591994468633fc6f8701c5fc53e0214b6da4f
Compiled by denes on Fri Sep 15 14:58:00 CEST 2017
From source with checksum fbb44c8c8fb63a49be0a59e27316833d

# The Error is caused by HBAse, to get rid of it, you need to modify the 
# hbase-env.sh.

#The simple way is to comment the line 
##export HBASE_CLASSPATH 

#now rerun the command
[hadoop@localhost flume-1.8.0]$ sh $FLUME_HOME/bin/flume-ng version 
Flume 1.8.0
Source code repository: https://git-wip-us.apache.org/repos/asf/flume.git
Revision: 99f591994468633fc6f8701c5fc53e0214b6da4f
Compiled by denes on Fri Sep 15 14:58:00 CEST 2017
From source with checksum fbb44c8c8fb63a49be0a59e27316833d
";i:1;N;i:2;N;}i:2;i:5762;}i:225;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:6866;}i:226;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:39:"Test your flume with different scenario";i:1;i:2;i:2;i:6866;}i:2;i:6866;}i:227;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:6866;}i:228;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6866;}i:229;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:205:"For each data flow in Flume, we need to define a flume agent which contains: sources, channels, sinks. In the following examples, we will demonstrate how to configure different sources, channels and sinks.";}i:2;i:6920;}i:230;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7125;}i:231;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:7127;}i:232;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:10:"Avro agent";i:1;i:3;i:2;i:7127;}i:2;i:7127;}i:233;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:7127;}i:234;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7127;}i:235;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:420:"Avro is a remote procedure call and data serialization framework developed within Apache's Hadoop project. It uses JSON for defining data types and protocols, and serializes data in a compact binary format. Its primary use is in Apache Hadoop, where it can provide both a serialization format for persistent data, and a wire format for communication between Hadoop nodes, and from client programs to the Hadoop services.";}i:2;i:7149;}i:236;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7569;}i:237;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7569;}i:238;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:171:"It is similar to Thrift and Protocol Buffers, but does not require running a code-generation program when a schema changes (unless desired for statically-typed languages).";}i:2;i:7572;}i:239;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7743;}i:240;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7743;}i:241;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:50:"Apache Spark SQL can access Avro as a data source.";}i:2;i:7746;}i:242;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7796;}i:243;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:7798;}i:244;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:25:"Edit avro agent conf file";i:1;i:4;i:2;i:7798;}i:2;i:7798;}i:245;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:7798;}i:246;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7798;}i:247;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:107:"You can put the flume agent file anywhere. In this example, I put them under $FLUME_HOME/conf/agent-example";}i:2;i:7832;}i:248;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7945;}i:249;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:1148:"
vim /opt/flume/flume-1.8.0/conf/agent-example/avro.conf

#Put the following lines
# the name of this avro agent is avroAgent.
# it has one sources localAvroClient, sinks stdLogger, channels memoryChannel.
# Part 1. Define the name of sources, sinks, channels 
  avroAgent.sources = localAvroClient
  avroAgent.sinks = stdLogger
  avroAgent.channels = memoryChannel
 
# Part 2. Describe/configure the source
  avroAgent.sources.localAvroClient.type = avro
  avroAgent.sources.localAvroClient.channels = memoryChannel
# this source bind on every available network interface on this server at port 4141
  avroAgent.sources.localAvroClient.bind = 0.0.0.0
  avroAgent.sources.localAvroClient.port = 4141
 
# Part 3. Describe the sink
  avroAgent.sinks.stdLogger.type = logger
 
# Part 4. Use a channel which buffers events in memory
  avroAgent.channels.memoryChannel.type = memory
  avroAgent.channels.memoryChannel.capacity = 1000
  avroAgent.channels.memoryChannel.transactionCapacity = 100
 
# Bind the source and sink to the channel
  avroAgent.sources.localAvroClient.channels = memoryChannel
  avroAgent.sinks.stdLogger.channel = memoryChannel

";i:1;N;i:2;N;}i:2;i:7945;}i:250;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7945;}i:251;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:82:"You can notice that, one agent must have a comple conf of source, sink and channel";}i:2;i:9103;}i:252;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9185;}i:253;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:9187;}i:254;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:15:"Run flume agent";i:1;i:4;i:2;i:9187;}i:2;i:9187;}i:255;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:9187;}i:256;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9187;}i:257;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:17:"To run the agent,";}i:2;i:9212;}i:258;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9229;}i:259;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:535:"
$ bin/flume-ng agent --conf ./conf/ -f /opt/flume/flume-1.8.0/conf/agent-example/avro.conf -n avroAgent -Dflume.root.logger=INFO,console

#agent -> start a flume agent
#--conf/-c <dir path>-> Use configuration file in the conf directory
#-f <file path> -> Specifies a config file path, if missing
#--name, -n <agent name> -> Name of the agent in the conf file 
# for example, if you put -n a1. WARN node.AbstractConfigurationProvider: No configuration found for this host:a1
#-Dproperty = value -> Sets a Java system property value


";i:1;N;i:2;N;}i:2;i:9236;}i:260;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:9782;}i:261;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:44:"Run avro client to send flume event to agent";i:1;i:4;i:2;i:9782;}i:2;i:9782;}i:262;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:9782;}i:263;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9782;}i:264;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:52:"In this example, we use the flume native avro-client";}i:2;i:9836;}i:265;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9894;}i:266;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:233:"
#As the above agent listen to all available network interface, 
#so we need only send the content of text.txt to localhost on port 4141 ( port number defined in avro.conf file)
flume-ng avro-client -H localhost -p 4141 -F test.txt 
";i:1;N;i:2;N;}i:2;i:9894;}i:267;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9894;}i:268;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:35:"Suppose the contenx of test.txt is ";}i:2;i:10136;}i:269;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10177;}i:270;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:22:"
real

toto
titi
tata
";i:1;N;i:2;N;}i:2;i:10177;}i:271;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10177;}i:272;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:35:"You should see the following result";}i:2;i:10208;}i:273;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10249;}i:274;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:1366:"
18/01/22 10:43:44 INFO source.AvroSource: Avro source localAvroClient started.
18/01/22 10:43:53 INFO ipc.NettyServer: [id: 0x408ccd0a, /127.0.0.1:49466 => /127.0.0.1:4141] OPEN
18/01/22 10:43:53 INFO ipc.NettyServer: [id: 0x408ccd0a, /127.0.0.1:49466 => /127.0.0.1:4141] BOUND: /127.0.0.1:4141
18/01/22 10:43:53 INFO ipc.NettyServer: [id: 0x408ccd0a, /127.0.0.1:49466 => /127.0.0.1:4141] CONNECTED: /127.0.0.1:49466
18/01/22 10:43:53 INFO sink.LoggerSink: Event: { headers:{} body: 72 65 61 6C                                     real }
18/01/22 10:43:53 INFO sink.LoggerSink: Event: { headers:{} body: }
18/01/22 10:43:53 INFO sink.LoggerSink: Event: { headers:{} body: 74 6F 74 6F                                     toto }
18/01/22 10:43:53 INFO sink.LoggerSink: Event: { headers:{} body: 74 69 74 69                                     titi }
18/01/22 10:43:53 INFO sink.LoggerSink: Event: { headers:{} body: 74 61 74 61                                     tata }
18/01/22 10:43:53 INFO ipc.NettyServer: [id: 0x408ccd0a, /127.0.0.1:49466 :> /127.0.0.1:4141] DISCONNECTED
18/01/22 10:43:53 INFO ipc.NettyServer: [id: 0x408ccd0a, /127.0.0.1:49466 :> /127.0.0.1:4141] UNBOUND
18/01/22 10:43:53 INFO ipc.NettyServer: [id: 0x408ccd0a, /127.0.0.1:49466 :> /127.0.0.1:4141] CLOSED
18/01/22 10:43:53 INFO ipc.NettyServer: Connection to /127.0.0.1:49466 disconnected.

";i:1;N;i:2;N;}i:2;i:10249;}i:275;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10249;}i:276;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:80:"You can notice that, flume consider one line as a event, even the line is empty.";}i:2;i:11625;}i:277;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:11706;}i:278;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:11706;}i:279;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:19:"Netcat source agent";i:1;i:3;i:2;i:11706;}i:2;i:11706;}i:280;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:11706;}i:281;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:11737;}i:282;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:23:"Flume netcat agent conf";i:1;i:4;i:2;i:11737;}i:2;i:11737;}i:283;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:11737;}i:284;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:945:"
#name the components on this agent  
    netcatAgent.sources = localSocket  
    netcatAgent.sinks = stdLogger  
    netcatAgent.channels = memoryChannel  
 
    # Describe/configure the source  
    netcatAgent.sources.localSocket.type = netcat  
    netcatAgent.sources.localSocket.bind = localhost  
    netcatAgent.sources.localSocket.port = 8888 
     
 
    # Describe the sink  
    netcatAgent.sinks.stdLogger.type = logger  
 
    # Use a channel which buffers events in memory  
    netcatAgent.channels.memoryChannel.type = memory  
    netcatAgent.channels.memoryChannel.capacity = 10000  
    netcatAgent.channels.memoryChannel.transactionCapacity = 1000  
 
    # Bind the source and sink to the channel  
    netcatAgent.sources.localSocket.channels = memoryChannel  
    netcatAgent.sinks.stdLogger.channel = memoryChannel

   # set the line length of event 
   netcatAgent.sources.localSocket.deserializer.maxLineLength=10000 
";i:1;N;i:2;N;}i:2;i:11775;}i:285;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:12730;}i:286;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:13:"run the agent";i:1;i:4;i:2;i:12730;}i:2;i:12730;}i:287;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:12730;}i:288;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:121:"
flume-ng agent -f /opt/flume/flume-1.8.0/conf/agent-example/netcat.conf -n netcatAgent -Dflume.root.logger=INFO,console
";i:1;N;i:2;N;}i:2;i:12758;}i:289;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:12888;}i:290;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:14:"run the client";i:1;i:4;i:2;i:12888;}i:2;i:12888;}i:291;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:12888;}i:292;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:47:"
[hadoop@localhost log]$ telnet localhost 8888
";i:1;N;i:2;N;}i:2;i:12917;}i:293;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:12975;}i:294;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:12975;}}