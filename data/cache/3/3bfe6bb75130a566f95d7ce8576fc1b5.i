a:156:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:33:"Hive Internal and External tables";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1;}i:4;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:50:"Hive has two types of tables which are as follows:";}i:2;i:50;}i:5;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:101;}i:6;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:101;}i:7;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:101;}i:8;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:101;}i:9;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:31:" Managed Table (Internal Table)";}i:2;i:105;}i:10;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:136;}i:11;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:136;}i:12;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:136;}i:13;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:136;}i:14;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:15:" External Table";}i:2;i:140;}i:15;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:155;}i:16;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:155;}i:17;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:155;}i:18;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:162;}i:19;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:67:"Featured Difference between Hive Internal Tables vs External Tables";i:1;i:2;i:2;i:162;}i:2;i:162;}i:20;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:162;}i:21;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:162;}i:22;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:75:"Let’s now discuss the Hive Internal tables vs External tables comparison.";}i:2;i:244;}i:23;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:319;}i:24;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:321;}i:25;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:19:"Hive Managed Tables";i:1;i:3;i:2;i:321;}i:2;i:321;}i:26;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:321;}i:27;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:321;}i:28;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:164:"It is also know an internal table. When we create a table in Hive, it by default manages the data. This means that Hive moves the data into its warehouse directory.";}i:2;i:353;}i:29;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:517;}i:30;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:517;}i:31;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:107:"Managed Tables  When we load data into a Managed table, then Hive moves data into Hive warehouse directory.";}i:2;i:519;}i:32;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:626;}i:33;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:626;}i:34;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:12:"For example:";}i:2;i:628;}i:35;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:640;}i:36;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:108:"
CREATE TABLE managed_table (dummy STRING);
LOAD DATA INPATH '/user/tom/data.txt' INTO table managed_table;
";i:1;N;i:2;N;}i:2;i:647;}i:37;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:647;}i:38;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:25:"This moves the file hdfs:";}i:2;i:765;}i:39;a:3:{i:0;s:13:"emphasis_open";i:1;a:0:{}i:2;i:790;}i:40;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:95:"user/tom/data.txt into Hive’s warehouse directory for the managed_table table, which is hdfs:";}i:2;i:792;}i:41;a:3:{i:0;s:14:"emphasis_close";i:1;a:0:{}i:2;i:887;}i:42;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:34:"user/hive/warehouse/managed_table.";}i:2;i:889;}i:43;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:923;}i:44;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:923;}i:45;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:37:"Further, if we drop the table using: ";}i:2;i:925;}i:46;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:968;}i:47;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:26:"
DROP TABLE managed_table
";i:1;N;i:2;N;}i:2;i:968;}i:48;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:968;}i:49;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:147:"Then this will delete the table metadata including its data. The data no longer exists anywhere. This is what it means for HIVE to manage the data.";}i:2;i:1004;}i:50;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1151;}i:51;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1154;}i:52;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:7:"Example";i:1;i:4;i:2;i:1154;}i:2;i:1154;}i:53;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:1154;}i:54;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1154;}i:55;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:64:"For example, we want to insert the above csv file into the Hive ";}i:2;i:1171;}i:56;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1235;}i:57;a:3:{i:0;s:4:"file";i:1;a:3:{i:0;s:103:"
id,sex,age,infected
1001,Male,1,Yes
1002,Female,2,No
1003,Male,3,Yes
1004,Female,4,Yes
1005,Male,5,No
";i:1;s:3:"csv";i:2;s:15:"rabbit_demo.csv";}i:2;i:1242;}i:58;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:1550:"
# mosaic is the database name in which you want to insert rabbits table
# Without skip header line, you will see hive will load also the header as data. Note that, we define the header 
# is the first line, if you want to remove the first two or three lines. It's possible too.
CREATE TABLE IF NOT EXISTS mosaic.rabbits ( rid int, sex String,age int, infected String) COMMENT 'rabbit t virus infection' ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' STORED AS TEXTFILE tblproperties ("skip.header.line.count"="1");

# load data to table, if your data is no your local file system.
# Beware if you run this in Beeline, make sure the user in beeline has the right to read rabbit_demo.csv
LOAD DATA LOCAL INPATH '/tmp/rabbit_demo.csv' OVERWRITE INTO TABLE rabbits;

# If your data is on GPFS
$ hdfs dfs -put /tmp/rabbit_demo.csv /usr/hadoop/. 
# make sure hive has the right to read the data, otherwise you will see empty table
$ hdfs dfs -chown hive:hdfs /usr/hadoop/rabbit_demo.csv

LOAD DATA INPATH '/usr/hadoop/rabbit_demo.csv' OVERWRITE INTO TABLE rabbits;
# Note that, after this command the csv will be moved to the hive warehouse, so you won't find it in /usr/hadoop/ anymore.

# You can also include data location in one line
CREATE TABLE IF NOT EXISTS mosaic.rabbits ( rid int, sex String,age int, infected String) COMMENT 'rabbit t virus infection' ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' STORED AS TEXTFILE LOCATION '/tmp/rabbit_demo.csv' tblproperties ("skip.header.line.count"="1");
";i:1;N;i:2;N;}i:2;i:1382;}i:59;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2944;}i:60;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:20:"Hive External Tables";i:1;i:3;i:2;i:2944;}i:2;i:2944;}i:61;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:2944;}i:62;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2944;}i:63;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:137:"We can also create an external table. It tells Hive to refer to the data that is at an existing location outside the warehouse directory.";}i:2;i:2977;}i:64;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3114;}i:65;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3114;}i:66;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:128:"we can control the creation and deletion of the data. The location of the external data is specified at the table creation time:";}i:2;i:3116;}i:67;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3244;}i:68;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:154:"
CREATE EXTERNAL TABLE external_table(dummy STRING)
LOCATION '/user/tom/external_table';
LOAD DATA INPATH '/user/tom/data.txt' INTO TABLE external_table;
";i:1;N;i:2;N;}i:2;i:3251;}i:69;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3251;}i:70;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:318:"Now, with the EXTERNAL keyword, Apache Hive knows that it is not managing the data. So it doesn’t move data to its warehouse directory. It does not even check whether the external location exists at the time it is defined. This very useful feature because it means we create the data lazily after creating the table.";}i:2;i:3415;}i:71;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3733;}i:72;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3733;}i:73;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:134:"The important thing to notice is that when we drop an external table, Hive will leave the data untouched and only delete the metadata.";}i:2;i:3735;}i:74;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3869;}i:75;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:3871;}i:76;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:7:"Example";i:1;i:4;i:2;i:3871;}i:2;i:3871;}i:77;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:3871;}i:78;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3871;}i:79;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:79:"We can retake the example of the internal hive table, just add keyword external";}i:2;i:3888;}i:80;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3967;}i:81;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:271:"
CREATE EXTERNAL TABLE IF NOT EXISTS mosaic.rabbits ( rid int, sex String,age int, infected String) COMMENT 'rabbit t virus infection' ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' STORED AS TEXTFILE tblproperties ("skip.header.line.count"="1");
";i:1;N;i:2;N;}i:2;i:3974;}i:82;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4257;}i:83;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:8:"Security";i:1;i:2;i:2;i:4257;}i:2;i:4257;}i:84;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:4257;}i:85;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:4278;}i:86;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4278;}i:87;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4278;}i:88;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:4282;}i:89;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:4283;}i:90;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:14:"Managed Tables";}i:2;i:4285;}i:91;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:4299;}i:92;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:149:"  Hive solely controls the Managed table security. Within Hive, security needs to be managed; probably at the schema level (depends on organization).";}i:2;i:4301;}i:93;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4450;}i:94;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4450;}i:95;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4450;}i:96;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4450;}i:97;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:4454;}i:98;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:4455;}i:99;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:15:"External Tables";}i:2;i:4457;}i:100;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:4472;}i:101;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:150:"  These tables’ files are accessible to anyone who has access to HDFS file structure. So, it needs to manage security at the HDFS file/folder level.";}i:2;i:4474;}i:102;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4624;}i:103;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4624;}i:104;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:4624;}i:105;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4626;}i:106;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:38:"When to use Managed and external table";i:1;i:2;i:2;i:4626;}i:2;i:4626;}i:107;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:4626;}i:108;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4678;}i:109;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:22:"Use Managed table when";i:1;i:3;i:2;i:4678;}i:2;i:4678;}i:110;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:4678;}i:111;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:4711;}i:112;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4711;}i:113;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4711;}i:114;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:71:" We want Hive to completely manage the lifecycle of the data and table.";}i:2;i:4716;}i:115;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4787;}i:116;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4787;}i:117;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4787;}i:118;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4787;}i:119;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:18:" Data is temporary";}i:2;i:4791;}i:120;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4809;}i:121;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4809;}i:122;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:4809;}i:123;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4811;}i:124;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:23:"Use External table when";i:1;i:3;i:2;i:4811;}i:2;i:4811;}i:125;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:4811;}i:126;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:4847;}i:127;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4847;}i:128;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4847;}i:129;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:134:" Data is used outside of Hive. For example, the data files are read and processed by an existing program that does not lock the files.";}i:2;i:4851;}i:130;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4985;}i:131;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4985;}i:132;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4985;}i:133;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4985;}i:134;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:57:" We are not creating a table based on the existing table.";}i:2;i:4989;}i:135;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:5046;}i:136;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:5046;}i:137;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:5046;}i:138;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:5046;}i:139;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:148:" We need data to remain in the underlying location even after a DROP TABLE. This may apply if we are pointing multiple schemas at a single data set.";}i:2;i:5050;}i:140;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:5198;}i:141;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:5198;}i:142;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:5198;}i:143;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:5198;}i:144;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:136:" The hive shouldn’t own data and control settings, directories etc., we may have another program or process that will do these things.";}i:2;i:5202;}i:145;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:5338;}i:146;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:5338;}i:147;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:5338;}i:148;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:5340;}i:149;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:10:"Conclusion";i:1;i:2;i:2;i:5340;}i:2;i:5340;}i:150;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:5340;}i:151;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5340;}i:152;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:265:"In conclusion, Managed tables are like normal database table in which we can store data and query on. On dropping Managed tables, the data stored in them is also deleted and data is lost forever. While dropping External tables will delete metadata but not the data.";}i:2;i:5364;}i:153;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5629;}i:154;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:5630;}i:155;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:5630;}}