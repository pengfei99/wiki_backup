a:117:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:14:"Spark doc list";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:31;}i:4;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:60:"Lessons for spark introduction, key components and internals";i:1;i:2;i:2;i:31;}i:2;i:31;}i:5;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:31;}i:6;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:31;}i:7;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:58:"employes:pengfei.liu:big_data:spark:l01_spark_introduction";i:1;s:22:"Lesson01: Spark basics";}i:2;i:104;}i:8;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:189;}i:9;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:189;}i:10;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:51:"employes:pengfei.liu:big_data:spark:l02_spark_stack";i:1;s:47:"Lesson02: Spark unified stack and applicatioins";}i:2;i:191;}i:11;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:294;}i:12;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:294;}i:13;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:51:"employes:pengfei.liu:big_data:spark:l03_spark_shell";i:1;s:50:"Lesson03: Introduction of spark shell and spark UI";}i:2;i:296;}i:14;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:402;}i:15;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:402;}i:16;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:55:"spark user define fonction use in sql and dataframe : 
";}i:2;i:404;}i:17;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:45:"employes:pengfei.liu:big_data:spark:spark_udf";i:1;s:26:"Spark user define function";}i:2;i:459;}i:18;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:535;}i:19;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:537;}i:20;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:19:"Spark infratructure";i:1;i:2;i:2;i:537;}i:2;i:537;}i:21;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:537;}i:22;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:537;}i:23;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:60:"employes:pengfei.liu:big_data:spark:spark_multi_node_cluster";i:1;s:32:"Install spark on multi node mode";}i:2;i:570;}i:24;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:667;}i:25;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:667;}i:26;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:57:"employes:pengfei.liu:big_data:spark:spark_dev_environment";i:1;s:43:"Install a devlopment envirionment for spark";}i:2;i:670;}i:27;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:775;}i:28;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:777;}i:29;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:20:"Spark data structure";i:1;i:2;i:2;i:777;}i:2;i:777;}i:30;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:777;}i:31;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:777;}i:32;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:36:"1. Overview of spark data structure ";}i:2;i:811;}i:33;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:59:"employes:pengfei.liu:big_data:spark:data_structure_overview";i:1;s:23:"Data structure overview";}i:2;i:847;}i:34;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:934;}i:35;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:934;}i:36;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:"2. Spark RDD ";}i:2;i:936;}i:37;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:45:"employes:pengfei.liu:big_data:spark:spark_rdd";i:1;s:9:"Spark RDD";}i:2;i:949;}i:38;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1008;}i:39;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1008;}i:40;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:19:"3. Spark dataframe ";}i:2;i:1010;}i:41;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:51:"employes:pengfei.liu:big_data:spark:spark_dataframe";i:1;s:27:"DataFrame in SPARK (vs RDD)";}i:2;i:1029;}i:42;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1112;}i:43;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1112;}i:44;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:18:"4. Spark datasets ";}i:2;i:1114;}i:45;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:49:"employes:pengfei.liu:big_data:spark:spark_dataset";i:1;s:13:"Spark dataset";}i:2;i:1132;}i:46;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1199;}i:47;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1199;}i:48;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:25:"5. Spark data partitions ";}i:2;i:1201;}i:49;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:52:"employes:pengfei.liu:big_data:spark:spark_partitions";i:1;s:16:"Spark Partitions";}i:2;i:1226;}i:50;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1299;}i:51;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1302;}i:52;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:8:"Spark IO";i:1;i:2;i:2;i:1302;}i:2;i:1302;}i:53;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:1302;}i:54;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1302;}i:55;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:9:"File IO: ";}i:2;i:1323;}i:56;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:49:"employes:pengfei.liu:big_data:spark:spark_file_io";i:1;s:27:"Spark file input and output";}i:2;i:1332;}i:57;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1413;}i:58;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1413;}i:59;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:"PARQUET IO : ";}i:2;i:1415;}i:60;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:51:"employes:pengfei.liu:big_data:spark:spark_parquetio";i:1;s:43:"Spark read and write parquet in file system";}i:2;i:1428;}i:61;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1527;}i:62;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1527;}i:63;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:27:"IO with external data base:";}i:2;i:1529;}i:64;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1556;}i:65;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:1556;}i:66;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1556;}i:67;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1556;}i:68;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:1561;}i:69;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:50:"employes:pengfei.liu:big_data:spark:spark_hbase_io";i:1;s:38:"Use spark to get and set data in HBase";}i:2;i:1562;}i:70;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1655;}i:71;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1655;}i:72;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1655;}i:73;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1655;}i:74;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:1659;}i:75;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:49:"employes:pengfei.liu:big_data:spark:spark_jdbc_io";i:1;s:24:"Read write data via jdbc";}i:2;i:1660;}i:76;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1738;}i:77;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1738;}i:78;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:1738;}i:79;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1740;}i:80;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:15:"Spark streaming";i:1;i:2;i:2;i:1740;}i:2;i:1740;}i:81;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:1740;}i:82;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1740;}i:83;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:17:"File streaming : ";}i:2;i:1769;}i:84;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:66:"employes:pengfei.liu:big_data:spark:spark_streaming:file_streaming";i:1;s:20:"Spark file Streaming";}i:2;i:1786;}i:85;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1877;}i:86;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1877;}i:87;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:19:"Socket streaming : ";}i:2;i:1879;}i:88;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:68:"employes:pengfei.liu:big_data:spark:spark_streaming:socket_streaming";i:1;s:22:"Spark socket streaming";}i:2;i:1898;}i:89;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1993;}i:90;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1993;}i:91;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:59:"RDD flux streaming: It's normally for testing or debugging.";}i:2;i:1995;}i:92;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2054;}i:93;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2054;}i:94;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"kafka spark streaming : ";}i:2;i:2056;}i:95;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:67:"employes:pengfei.liu:big_data:spark:spark_streaming:kafka_streaming";i:1;s:28:"Apache Kafka spark streaming";}i:2;i:2080;}i:96;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2180;}i:97;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2180;}i:98;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"flume spark streaming : ";}i:2;i:2182;}i:99;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:67:"employes:pengfei.liu:big_data:spark:spark_streaming:flume_streaming";i:1;s:21:"Flume spark streaming";}i:2;i:2206;}i:100;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:0:"";}i:2;i:2299;}i:101;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2300;}i:102;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2300;}i:103;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:25:"Spark application example";i:1;i:2;i:2;i:2300;}i:2;i:2300;}i:104;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:2300;}i:105;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2300;}i:106;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:62:"employes:pengfei.liu:big_data:spark:spark_usecase:sf_fire_call";i:1;s:35:"Spark analyse 911 fire service call";}i:2;i:2339;}i:107;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2441;}i:108;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2441;}i:109;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:72:"employes:pengfei.liu:big_data:spark:spark_usecase:sf_client_satisfaction";i:1;s:15:"Happy customers";}i:2;i:2443;}i:110;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2535;}i:111;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2535;}i:112;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"Inverted index of files ";}i:2;i:2537;}i:113;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:70:"employes:pengfei.liu:big_data:spark:spark_usecase:inverted_index_shake";i:1;s:46:"Inverted index of files of Shakespeare's works";}i:2;i:2561;}i:114;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2682;}i:115;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2684;}i:116;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:2684;}}