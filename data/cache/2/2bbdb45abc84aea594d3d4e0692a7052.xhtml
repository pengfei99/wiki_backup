
<h1 class="sectionedit1" id="install_and_configure_elasticsearch_and_kibana">Install and configure elasticsearch and kibana</h1>
<div class="level1">

</div>
<!-- EDIT1 SECTION "Install and configure elasticsearch and kibana" [1-62] -->
<h2 class="sectionedit2" id="what_is_elasticsearch">What is ElasticSearch</h2>
<div class="level2">

<p>
Initially released in 2010, Elasticsearch is a modern search and analytics engine which is based on <strong>Apache Lucene</strong>. Completely open source and built with Java, Elasticsearch is categorized as a <strong>NoSQL database</strong>. That means it stores data in an unstructured way and that you cannot use SQL to query it.
</p>

<p>
Unlike most NoSQL databases, though, Elasticsearch has a strong focus on search capabilities and features  so much so, in fact, that the easiest way to get data from Elasticsearch is to search for it using its extensive <strong>REST <abbr title="Application Programming Interface">API</abbr></strong>.
</p>

</div>
<!-- EDIT2 SECTION "What is ElasticSearch" [63-641] -->
<h2 class="sectionedit3" id="elasticsearch_general_feautres">ElasticSearch General feautres</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> Elasticsearch is scalable up to petabytes of structured and unstructured data.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch can be used as a replacement of document stores like MongoDB and RavenDB.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch uses denormalization to improve the search performance.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch is one of the popular enterprise search engines, which is currently being used by many big organizations like Wikipedia, The Guardian, StackOverflow, GitHub etc.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch is open source and available under the Apache license version 2.0.</div>
</li>
</ul>

</div>
<!-- EDIT3 SECTION "ElasticSearch General feautres" [642-1200] -->
<h2 class="sectionedit4" id="key_concepts">Key concepts</h2>
<div class="level2">
<ul>
<li class="level1"><div class="li"> <strong>Node</strong> − It refers to a single running instance of Elasticsearch. Single physical and virtual server accommodates multiple nodes depending upon the capabilities of their physical resources like RAM, storage and processing power.</div>
</li>
<li class="level1"><div class="li"> <strong>Cluster</strong> − It is a collection of one or more nodes. Cluster provides collective indexing and search capabilities across all the nodes for entire data.</div>
</li>
<li class="level1"><div class="li"> <strong>Index</strong> − It is a collection of different type of documents and document properties. Index also uses the concept of shards to improve the performance. For example, a set of document contains data of a social networking application.</div>
</li>
<li class="level1"><div class="li"> <strong>Type/Mapping</strong> − It is a collection of documents sharing a set of common fields present in the same index. For example, an Index contains data of a social networking application, and then there can be a specific type for user profile data, another type for messaging data and another for comments data.</div>
</li>
<li class="level1"><div class="li"> <strong>Document</strong> − It is a collection of fields in a specific manner defined in JSON format. Every document belongs to a type and resides inside an index. Every document is associated with a unique identifier, called the UID.</div>
</li>
<li class="level1"><div class="li"> <strong>Shard</strong> − Indexes are horizontally subdivided into shards. This means each shard contains all the properties of document, but contains less number of JSON objects than index. The horizontal separation makes shard an independent node, which can be store in any node. Primary shard is the original horizontal part of an index and then these primary shards are replicated into replica shards.</div>
</li>
<li class="level1"><div class="li"> <strong>Replicas</strong> − Elasticsearch allows a user to create replicas of their indexes and shards. Replication not only helps in increasing the availability of data in case of failure, but also improves the performance of searching by carrying out a parallel search operation in these replicas.</div>
</li>
</ul>

</div>
<!-- EDIT4 SECTION "Key concepts" [1201-3094] -->
<h2 class="sectionedit5" id="advantage_and_disadvantage">Advantage and disadvantage</h2>
<div class="level2">

<p>
Advantage :
</p>
<ul>
<li class="level1"><div class="li"> Elasticsearch is developed on Java, which makes it compatible on almost every platform.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch is real time, in other words after one second the added document is searchable in this engine.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch is distributed, which makes it easy to scale and integrate in any big organization.</div>
</li>
<li class="level1"><div class="li"> Creating full backups are easy by using the concept of gateway, which is present in Elasticsearch.</div>
</li>
<li class="level1"><div class="li"> Handling multi-tenancy is very easy in Elasticsearch when compared to Apache Solr.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch uses JSON objects as responses, which makes it possible to invoke the Elasticsearch server with a large number of different programming languages.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch supports almost every document type except those that do not support text rendering.</div>
</li>
</ul>

<p>
Disadvantage : 
</p>
<ul>
<li class="level1"><div class="li"> Elasticsearch does not have multi-language support in terms of handling request and response data (only possible in JSON) unlike in Apache Solr, where it is possible in CSV, XML and JSON formats.</div>
</li>
<li class="level1"><div class="li"> Elasticsearch also have a problem of Split brain situations, but in rare cases.</div>
</li>
</ul>

</div>
<!-- EDIT5 SECTION "Advantage and disadvantage" [3095-4215] -->
<h2 class="sectionedit6" id="comparison_between_elasticsearch_and_rdbms">Comparison between ElasticSearch and RDBMS</h2>
<div class="level2">
<div class="table sectionedit7"><table class="inline">
	<thead>
	<tr class="row0">
		<th class="col0 leftalign">Elasticsearch	</th><th class="col1">RDBMS </th>
	</tr>
	</thead>
	<tr class="row1">
		<td class="col0 leftalign">Index	</td><td class="col1">Database </td>
	</tr>
	<tr class="row2">
		<td class="col0 leftalign">Shard	</td><td class="col1">Shard </td>
	</tr>
	<tr class="row3">
		<td class="col0">Mapping</td><td class="col1">Table </td>
	</tr>
	<tr class="row4">
		<td class="col0 leftalign">Field	</td><td class="col1">Field </td>
	</tr>
	<tr class="row5">
		<td class="col0 leftalign">JSON Object	</td><td class="col1">Tuple </td>
	</tr>
</table></div>
<!-- EDIT7 TABLE [4272-4385] -->
</div>
<!-- EDIT6 SECTION "Comparison between ElasticSearch and RDBMS" [4216-4386] -->
<h2 class="sectionedit8" id="install_elasticsearch">Install elasticsearch</h2>
<div class="level2">

<p>
All the following installation guide is tested on centos7.
</p>

<p>
Pre-requise : JDK 1.8 +. Folllow this tutorial to install JDK : <a href="/doku.php?id=employes:pengfei.liu:java:install_jdk" class="wikilink1" title="employes:pengfei.liu:java:install_jdk">Install oracle jdk on ubuntu 16.04</a>
</p>

<p>
You have many option to install it, Please go see here : <a href="https://www.elastic.co/downloads/elasticsearch" class="urlextern" title="https://www.elastic.co/downloads/elasticsearch" rel="nofollow">https://www.elastic.co/downloads/elasticsearch</a>
</p>

<p>
In a prod environment, it&#039;s better to use rpm to install it.
</p>

<p>
In our case, we just use the tar ball of the current stable version (elasticsearch-6.1.3.tar.gz). 
</p>

<p>
Download elasticsearch tar ball and put it in /opt/elasticsearch/ and unzip it.
</p>

<p>
After you finish this, it should looks like this.
</p>
<pre class="code">[root@localhost elasticsearch-6.1.3]# pwd
/opt/elasticsearch/elasticsearch-6.1.3
[root@localhost elasticsearch-6.1.3]# ls
bin  config  lib  LICENSE.txt  logs  modules  NOTICE.txt  plugins  README.textile</pre>

</div>
<!-- EDIT8 SECTION "Install elasticsearch" [4387-5242] -->
<h2 class="sectionedit9" id="configure_elasticsearch">Configure ElasticSearch</h2>
<div class="level2">

<p>
Elasticsearch configurations are done using a configuration file that is located in different locations depending on your operating system. There are too main config files, <strong>elasticsearch.yml</strong> and <strong>jvm.options</strong>. In elasticsearch.yml, you can configure general settings (e.g. node name), as well as network settings (e.g. host and port), where data is stored. In jvm.options you can configure jvm heap memory and more.
</p>

<p>
For development and testing purposes, the default settings will suffice yet it is recommended you do some research into what settings can be manually defined before going into production.
</p>

</div>
<!-- EDIT9 SECTION "Configure ElasticSearch" [5243-5893] -->
<h3 class="sectionedit10" id="single_node_elasticsearch_config">Single node  ElasticSearch config</h3>
<div class="level3">

<p>
For example, and especially if installing Elasticsearch on the cloud, it is a good practice to bind Elasticsearch to either a private IP or localhost:
</p>

<p>
The following elasticsearch.yml is an example
</p>
<pre class="code"># ---------------------------------- Cluster -----------------------------------
#
# Use a descriptive name for your cluster:
#
cluster.name: hdfs_elastic
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
#
node.name: node-1
#
# Add custom attributes to the node:
#
node.attr.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
path.data: /tmp/elastic/data
#
# Path to log files:
#
path.logs: /tmp/elastic/logs
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
#bootstrap.memory_lock: true
#
# Make sure that the heap size is set to about half the memory available
# on the system and that the owner of the process is allowed to use this
# limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
</pre>

</div>
<!-- EDIT10 SECTION "Single node  ElasticSearch config" [5894-7142] -->
<h3 class="sectionedit11" id="run_the_elasticsearch_service">Run the elasticsearch service</h3>
<div class="level3">

<p>
If you install it via tar bar as I do. go to elastic home, (/opt/elasticsearch/elasticsearch-6.1.3/), and run
</p>
<pre class="code">./bin/elasticsearch</pre>

</div>

<h4 id="common_problems_of_installation">Common problems of installation</h4>
<div class="level4">

</div>

<h5 id="file_descriptors_limitation">File descriptors limitation</h5>
<div class="level5">

<p>
After run the elasticsearch, if you see the following errors
</p>
<pre class="code">ERROR: [1] bootstrap checks failed
[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]</pre>

<p>
you need to reset the process open file limitation at /etc/security/limits.conf. The default value depends on your linux distribution (e.g. centos7 4096, ubuntu 65536)
</p>
<pre class="code"># a woring example 
# * means for everyone, if you want to set limit for a user just put uid (e.g. pliu)
# if you want to set limit for a group just put @gid(e.g. @hadoop)
#        - &quot;soft&quot; for enforcing the soft limits
#        - &quot;hard&quot; for enforcing hard limits
# nofile - number of file

* hard nofile 65536
* soft nofile 65536</pre>

<p>
Check the maximum open files
</p>
<pre class="code">#1. get the elastic process id
ps -u elasticsearch
#output:
PID TTY          TIME CMD
11708 ?        00:00:10 java

#2. get the max open file numbers
cat /proc/11708/limits | grep &#039;Max open files&#039;

#output: 
Max open files            65535                65535                files</pre>

</div>

<h5 id="max_virtual_memory_areas">max virtual memory areas</h5>
<div class="level5">

<p>
if you see the following errors 
</p>
<pre class="code">[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</pre>

<p>
You need to do reset the max virtual memory areas
</p>
<pre class="code">sysctl -w vm.max_map_count=262144</pre>

</div>
<!-- EDIT11 SECTION "Run the elasticsearch service" [7143-8741] -->
<h3 class="sectionedit12" id="multi_node_elasticsearch_cluster_config">Multi node ElasticSearch cluster config</h3>
<div class="level3">

<p>
Elastic search has build in cluster mode. So it&#039;s really easy to build to elastic search cluster
</p>

<p>
In this example, we suppose we have 3 server cluster
</p>
<div class="table sectionedit13"><table class="inline">
	<thead>
	<tr class="row0">
		<th class="col0">IP</th><th class="col1"><abbr title="Uniform Resource Identifier">URI</abbr></th><th class="col2"> elastic_node_name </th>
	</tr>
	</thead>
	<tr class="row1">
		<td class="col0">10.70.3.48 </td><td class="col1"> hadoop-nn.bioaster.org </td><td class="col2"> node-1</td>
	</tr>
	<tr class="row2">
		<td class="col0">10.70.3.49 </td><td class="col1"> hadoop-dn1.bioaster.org </td><td class="col2"> node-2 </td>
	</tr>
	<tr class="row3">
		<td class="col0">10.70.3.50 </td><td class="col1"> hadoop-dn2.bioaster.org </td><td class="col2"> node-3 </td>
	</tr>
</table></div>
<!-- EDIT13 TABLE [8946-9119] -->
<p>
Install the elasticsearch tar ball as above. Configure the elasticsearch.yml for each node
</p>
<pre class="code"># ---------------------------------- Cluster -----------------------------------
#
# Use a descriptive name for your cluster: 
# It must be the same for the 3 node
cluster.name: hdfs_elastic
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
# node name must be unique inside the cluster
# in our example, it will be node-1, node-2, node-3
node.name: node-1
#
# Add custom attributes to the node:
#
#node.attr.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
path.data: /tmp/elastic/data
#
# Path to log files:
#
path.logs: /tmp/elastic/logs
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
#bootstrap.memory_lock: true
#
# Make sure that the heap size is set to about half the memory available
# on the system and that the owner of the process is allowed to use this
# limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
#
# ---------------------------------- Network -----------------------------------
#
# Set the bind address to a specific IP (IPv4 or IPv6):
# The network host should be the ip address or uri of the node
# This will force elastic search only answer request from this uri or ip address
# This is also security concern. the elasticsearch is completely
# driven by rest api without any security. The ip address must be protected (private ip or vpn ) 
# which can be accessed only by trusted people and service
# Do not bind Elasticsearch to a public or shared private network IP address!
# Note the addition of &quot;_local_&quot;, which configures Elasticsearch to also listen on all loopback devices
# such as localhost or 127.0.0.1
network.host: [10.70.3.48,_local_]
#
# Set a custom port for HTTP:
#
http.port: 9200
#
# For more information, consult the network module documentation.
#
# --------------------------------- Discovery ----------------------------------
#
# Pass an initial list of hosts to perform discovery when new node is started:
# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]
# In this line we put uri or ip address of all the nodes in the elastic cluster.
discovery.zen.ping.unicast.hosts: [&quot;hadoop-nn.bioaster.org&quot;, &quot;hadoop-dn1.bioaster.org&quot;,&quot;hadoop-dn2.bioaster.org&quot;]
#
# Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):
#
#discovery.zen.minimum_master_nodes: 
#
# For more information, consult the zen discovery module documentation.
</pre>

</div>

<h4 id="dedicated_master_nodes_and_data_nodes">Dedicated Master nodes and data nodes</h4>
<div class="level4">

<p>
There are two common types of Elasticsearch nodes: master and data. Master nodes perform cluster-wide actions, such as managing indices and determining which data nodes should store particular data shards. Data nodes hold shards of your indexed documents, and handle CRUD, search, and aggregation operations. As a general rule, data nodes consume a significant amount of CPU, memory, and I/O.
</p>

<p>
By default, every Elasticsearch node is configured to be a “master-eligible” data node, which means they store data (and perform resource-intensive operations) and have the potential to be elected as a master node. For a small cluster, this is usually fine; a large Elasticsearch cluster, however, should be configured with dedicated master nodes so that the master node&#039;s stability can&#039;t be compromised by intensive data node work.
</p>

</div>

<h5 id="how_to_configure_dedicated_master_nodes">How to Configure Dedicated Master Nodes</h5>
<div class="level5">

<p>
Before configuring dedicated master nodes, ensure that your cluster will have at least 3 master-eligible nodes. This is important to avoid a split-brain situation, which can cause inconsistencies in your data in the event of a network failure.
</p>
<pre class="code">#For master node, edit the elasticsearch.yml
node.master: true 
node.data: false

#for data node 
node.master: false 
node.data: true</pre>

</div>

<h5 id="configure_minimum_master_nodes">Configure Minimum Master Nodes</h5>
<div class="level5">

<p>
When running an Elasticsearch cluster, it is important to set the minimum number of master-eligible nodes that need to be running for the cluster to function normally, which is sometimes referred to as quorum. This is to ensure data consistency in the event that one or more nodes lose connectivity to the rest of the cluster, preventing what is known as a “split-brain” situation.
</p>

<p>
To calculate the number of minimum master nodes your cluster should have, calculate n / 2 + 1, where n is the total number of “master-eligible” nodes in your healthy cluster, then round the result down to the nearest integer. For example, for a 3-node cluster, the quorum is 2.
</p>

<p>
<strong>Note:</strong> Be sure to include all master-eligible nodes in your quorum calculation, including any data nodes that are master-eligible (default setting).
</p>

<p>
The minimum master nodes setting can be set dynamically, through the Elasticsearch HTTP <abbr title="Application Programming Interface">API</abbr>. To do so, run this command on any node (replace the highlighted number with your quorum):
</p>
<pre class="code"># use curl to request rest api
curl -XPUT localhost:9200/_cluster/settings?pretty -d &#039;{
    &quot;persistent&quot; : {
        &quot;discovery.zen.minimum_master_nodes&quot; : 2
    }
}&#039;

#output

{
  &quot;acknowledged&quot; : true,
  &quot;persistent&quot; : {
    &quot;discovery&quot; : {
      &quot;zen&quot; : {
        &quot;minimum_master_nodes&quot; : &quot;2&quot;
      }
    }
  },
  &quot;transient&quot; : { }
}</pre>

</div>

<h4 id="enable_memory_locking">Enable Memory Locking</h4>
<div class="level4">

<p>
Elastic recommends to avoid swapping the Elasticsearch process at all costs, due to its negative effects on performance and stability. One way avoid excessive swapping is to configure Elasticsearch to lock the memory that it needs.
</p>

<p>
Complete this step on all of your Elasticsearch servers.
</p>
<pre class="code">sudo vim elasticsearch.yml

bootstrap.mlockall: true

sudo vim jvm.options 

# Xms represents the initial size of total heap space
# Xmx represents the maximum size of total heap space

-Xms2g
-Xmx4g
</pre>

</div>

<h4 id="verify_the_memory_lock_status">Verify the memory lock status</h4>
<div class="level4">
<pre class="code">curl http://localhost:9200/_nodes/process?pretty

#output
&quot;nodes&quot; : {
    &quot;kQgZZUXATkSpduZxNwHfYQ&quot; : {
      &quot;name&quot; : &quot;node-1&quot;,
      &quot;transport_address&quot; : &quot;10.70.3.48:9300&quot;,
      &quot;host&quot; : &quot;10.70.3.48&quot;,
      &quot;ip&quot; : &quot;10.70.3.48&quot;,
      &quot;version&quot; : &quot;2.2.0&quot;,
      &quot;build&quot; : &quot;8ff36d1&quot;,
      &quot;http_address&quot; : &quot;10.70.3.48:9200&quot;,
      &quot;process&quot; : {
        &quot;refresh_interval_in_millis&quot; : 1000,
        &quot;id&quot; : 1650,
        &quot;mlockall&quot; : true
      }
</pre>

</div>
<!-- EDIT12 SECTION "Multi node ElasticSearch cluster config" [8742-15617] -->
<h3 class="sectionedit14" id="run_the_cluster">Run the cluster</h3>
<div class="level3">

<p>
You need to start the elastic deamon or do ./bin/elasticsearch on all your nodes in the cluster
</p>

</div>
<!-- EDIT14 SECTION "Run the cluster" [15618-15740] -->
<h3 class="sectionedit15" id="test_the_status_of_cluster">Test the status of cluster</h3>
<div class="level3">

<p>
Test the status of the elastic cluster.
</p>
<pre class="code">[hadoop@CCLinDataWHD01 pliu]$ curl -XGET &#039;http://localhost:9200/_cluster/state?pretty&#039;
{
  &quot;cluster_name&quot; : &quot;hdfs_elastic&quot;,
  &quot;compressed_size_in_bytes&quot; : 334,
  &quot;version&quot; : 4,
  &quot;state_uuid&quot; : &quot;5HNWvEDMSlyeG2yZ92acUQ&quot;,
  &quot;master_node&quot; : &quot;F-aJixNFSIiSYp5N_IAeLQ&quot;,
  &quot;blocks&quot; : { },
  &quot;nodes&quot; : {
    &quot;7j1T8NMSTque9lBcE1Pd-Q&quot; : {
      &quot;name&quot; : &quot;node-2&quot;,
      &quot;ephemeral_id&quot; : &quot;ai9NiqoRQSaU1qa8UfMufQ&quot;,
      &quot;transport_address&quot; : &quot;10.70.3.49:9300&quot;,
      &quot;attributes&quot; : { }
    },
    &quot;F-aJixNFSIiSYp5N_IAeLQ&quot; : {
      &quot;name&quot; : &quot;node-1&quot;,
      &quot;ephemeral_id&quot; : &quot;qs5yizBvSOaec-SBcSrO7Q&quot;,
      &quot;transport_address&quot; : &quot;10.70.3.48:9300&quot;,
      &quot;attributes&quot; : { }
    },
    &quot;t6U8Kf_NSQSnsmY4tmNWKA&quot; : {
      &quot;name&quot; : &quot;node-3&quot;,
      &quot;ephemeral_id&quot; : &quot;_okE5-fzRyK8VXlhSxwLIQ&quot;,
      &quot;transport_address&quot; : &quot;10.70.3.50:9300&quot;,
      &quot;attributes&quot; : { }
    }
  },
  &quot;metadata&quot; : {
    &quot;cluster_uuid&quot; : &quot;Sono_FJpRM6Q4T31H6qKDg&quot;,
    &quot;templates&quot; : { },
    &quot;indices&quot; : { },
    &quot;index-graveyard&quot; : {
      &quot;tombstones&quot; : [ ]
    }
  },
  &quot;routing_table&quot; : {
    &quot;indices&quot; : { }
  },
  &quot;routing_nodes&quot; : {
    &quot;unassigned&quot; : [ ],
    &quot;nodes&quot; : {
      &quot;t6U8Kf_NSQSnsmY4tmNWKA&quot; : [ ],
      &quot;F-aJixNFSIiSYp5N_IAeLQ&quot; : [ ],
      &quot;7j1T8NMSTque9lBcE1Pd-Q&quot; : [ ]
    }
  },
  &quot;snapshot_deletions&quot; : {
    &quot;snapshot_deletions&quot; : [ ]
  },
  &quot;snapshots&quot; : {
    &quot;snapshots&quot; : [ ]
  },
  &quot;restore&quot; : {
    &quot;snapshots&quot; : [ ]
  }
}
</pre>

</div>
<!-- EDIT15 SECTION "Test the status of cluster" [15741-] -->