a:281:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:41:"Install and configure Hortonworks sandbox";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1;}i:4;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:36:"Full official tutorial can be found ";}i:2;i:58;}i:5;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:85:"https://www.cloudera.com/tutorials/learning-the-ropes-of-the-hortonworks-sandbox.html";i:1;N;}i:2;i:94;}i:6;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:179;}i:7;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:182;}i:8;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:28:"1.Deploy Hortonworks sandbox";i:1;i:2;i:2;i:182;}i:2;i:182;}i:9;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:182;}i:10;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:182;}i:11;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:53:"Hortonworks sandbox provides three ways to deploy it:";}i:2;i:224;}i:12;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:277;}i:13;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:277;}i:14;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:277;}i:15;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:277;}i:16;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:" vmware image";}i:2;i:281;}i:17;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:294;}i:18;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:294;}i:19;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:294;}i:20;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:294;}i:21;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:18:" virtual box image";}i:2;i:298;}i:22;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:316;}i:23;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:316;}i:24;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:316;}i:25;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:316;}i:26;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:12:" docker file";}i:2;i:320;}i:27;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:332;}i:28;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:332;}i:29;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:332;}i:30;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:332;}i:31;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:179:"To deploy the vmware and virtual box image, it's quite easy, just create a vm based on the image. Then follow the configuration instruction which we will show in the next section.";}i:2;i:334;}i:32;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:513;}i:33;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:513;}i:34;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:63:"Run docker file in a docker container, you will need more works";}i:2;i:515;}i:35;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:578;}i:36;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:580;}i:37;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:44:"1.1 Deploy Hortonworks in a docker container";i:1;i:3;i:2;i:580;}i:2;i:580;}i:38;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:580;}i:39;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:635;}i:40;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:635;}i:41;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:635;}i:42;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:29:" Install and run docker (See ";}i:2;i:639;}i:43;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:57:"employes:pengfei.liu:admin_system:container:docker:1setup";i:1;s:29:"Part1 : Orientation and setup";}i:2;i:668;}i:44;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:25:" for docker installation)";}i:2;i:759;}i:45;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:784;}i:46;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:784;}i:47;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:784;}i:48;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:784;}i:49;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:35:" Downlaod the docker file for HDP (";}i:2;i:788;}i:50;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:88:"https://www.cloudera.com/downloads/hortonworks-sandbox/hdp.html?utm_source=mktg-tutorial";i:1;N;}i:2;i:823;}i:51;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:")";}i:2;i:911;}i:52;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:912;}i:53;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:912;}i:54;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:912;}i:55;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:912;}i:56;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:44:" Unzip the file, it should contain one file ";}i:2;i:916;}i:57;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:960;}i:58;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:22:"docker-deploy-hdp30.sh";}i:2;i:962;}i:59;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:984;}i:60;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:17:" and a directory ";}i:2;i:986;}i:61;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:1003;}i:62;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"assets";}i:2;i:1005;}i:63;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:1011;}i:64;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:".";}i:2;i:1013;}i:65;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1014;}i:66;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1014;}i:67;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1014;}i:68;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1014;}i:69;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:30:" Run sh docker-deploy-hdp30.sh";}i:2;i:1018;}i:70;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1048;}i:71;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1048;}i:72;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1048;}i:73;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1048;}i:74;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:35:" Check the docker process docker ps";}i:2;i:1052;}i:75;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1087;}i:76;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1087;}i:77;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1087;}i:78;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1087;}i:79;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:30:" Manage the HDP docker process";}i:2;i:1091;}i:80;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1121;}i:81;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1121;}i:82;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:1121;}i:83;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:699:"
# When you want to stop/shutdown your HDP sandbox, run the following commands:
docker stop sandbox-hdp
docker stop sandbox-proxy

# When you want to re-start your sandbox, run the following commands:
docker start sandbox-hdp
docker start sandbox-proxy

# If you want to remove sandbox containers. A container is an instance of the Sandbox image. You must stop 
# container dependencies before removing it. Issue the following commands:
docker stop sandbox-hdp
docker stop sandbox-proxy
docker rm sandbox-hdp
docker rm sandbox-proxy

# If you want to remove the HDP Sandbox image, issue the following command after stopping and removing the containers:
docker rmi hortonworks/sandbox-hdp:{release}

";i:1;N;i:2;N;}i:2;i:1129;}i:84;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1838;}i:85;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:33:"2. Configure sandbox VM/Container";i:1;i:2;i:2;i:1838;}i:2;i:1838;}i:86;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:1838;}i:87;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1885;}i:88;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:51:"2.1 Set up IP hostname mapping in your host machine";i:1;i:3;i:2;i:1885;}i:2;i:1885;}i:89;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:1885;}i:90;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1885;}i:91;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:129:"When you open your sandbox services in your host machine browsers, based on your installation, the IP address could be different.";}i:2;i:1948;}i:92;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2078;}i:93;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:2078;}i:94;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2078;}i:95;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2078;}i:96;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:31:" Docker: IP Address = 127.0.0.1";}i:2;i:2082;}i:97;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2113;}i:98;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2113;}i:99;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2113;}i:100;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2113;}i:101;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:35:" VirtualBox: IP Address = 127.0.0.1";}i:2;i:2117;}i:102;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2152;}i:103;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2152;}i:104;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2152;}i:105;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2152;}i:106;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:33:" VMWare: IP Address = 192.168.x.x";}i:2;i:2156;}i:107;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2189;}i:108;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2189;}i:109;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:2189;}i:110;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:369:"
# You need to modify the IP address accordingly
echo '<IP> sandbox-hdp.hortonworks.com sandbox-hdf.hortonworks.com' | sudo tee -a /etc/hosts

# In windows
# 1. Run Notepad as administrator.
# 2. Open hosts file located in: c:\Windows\System32\drivers\etc\hosts
# 3. Add {IP-Address} localhost sandbox-hdp.hortonworks.com sandbox-hdf.hortonworks.com
# 4. Save the file
";i:1;N;i:2;N;}i:2;i:2196;}i:111;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2575;}i:112;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:22:"2.2 Connect to your VM";i:1;i:3;i:2;i:2575;}i:2;i:2575;}i:113;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:2575;}i:114;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:294:"
# The sandbox does not use the port 22 for ssh, it uses 2222 instead
ssh root@sandbox-hdp.hortonworks.com -p 2222

# If you did not do the IP hostname mapping step, you need to replace the hostname by the IP address
# For the first connection, the password: **hadoop**, you need to modify it.
";i:1;N;i:2;N;}i:2;i:2615;}i:115;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2919;}i:116;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:50:"2.3 File transfer between sandbox and host machine";i:1;i:3;i:2;i:2919;}i:2;i:2919;}i:117;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:2919;}i:118;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:233:"
# Send file from host to sandbox
scp -P 2222 /tmp/toto.txt root@sandbox-hdp.hortonworks.com:/home/pliu/.

# Send file from sandbox to host
scp -P 2222 root@sandbox-hdp.hortonworks.com:<sandbox_directory_file> <local_directory_file>
";i:1;N;i:2;N;}i:2;i:2986;}i:119;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:3230;}i:120;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:31:"2.4 Reset ambari admin password";i:1;i:3;i:2;i:3230;}i:2;i:3230;}i:121;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:3230;}i:122;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3230;}i:123;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:51:"Ambari Dashboard runs on port: 8080. For example,Â ";}i:2;i:3273;}i:124;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:39:"http://sandbox-hdp.hortonworks.com:8080";i:1;N;}i:2;i:3324;}i:125;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:47:". Or Replace url by the real ip address. (e.g. ";}i:2;i:3363;}i:126;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:44:"http://192.168.184.129:8080/#/main/dashboard";i:1;N;}i:2;i:3410;}i:127;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:55:" ). You can use the following login to access the page:";}i:2;i:3454;}i:128;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3510;}i:129;a:3:{i:0;s:10:"table_open";i:1;a:3:{i:0;i:4;i:1;i:5;i:2;i:3511;}i:2;i:3510;}i:130;a:3:{i:0;s:15:"tablethead_open";i:1;a:0:{}i:2;i:3510;}i:131;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:3510;}i:132;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3510;}i:133;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:5:"login";}i:2;i:3512;}i:134;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:3517;}i:135;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3517;}i:136;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:4:" pwd";}i:2;i:3518;}i:137;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:3522;}i:138;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3522;}i:139;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:" role ";}i:2;i:3523;}i:140;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:3529;}i:141;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3529;}i:142;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"Tool access";}i:2;i:3530;}i:143;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:3541;}i:144;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:3543;}i:145;a:3:{i:0;s:16:"tablethead_close";i:1;a:0:{}i:2;i:3543;}i:146;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:3543;}i:147;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3543;}i:148;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:9:"maria_dev";}i:2;i:3545;}i:149;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3554;}i:150;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3554;}i:151;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:" maria_dev ";}i:2;i:3555;}i:152;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3566;}i:153;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3566;}i:154;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:25:" Spark and SQL Developer ";}i:2;i:3567;}i:155;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3592;}i:156;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3592;}i:157;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:97:" Hive, Zeppelin, MapReduce/Tez/Spark, Pig, Solr, HBase/Phoenix, Sqoop, NiFi, Storm, Kafka, Flume ";}i:2;i:3593;}i:158;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3690;}i:159;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:3691;}i:160;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:3691;}i:161;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3691;}i:162;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"raj_ops";}i:2;i:3693;}i:163;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3700;}i:164;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3700;}i:165;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:9:" raj_ops ";}i:2;i:3701;}i:166;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3710;}i:167;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3710;}i:168;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:27:" Hadoop Warehouse Operator ";}i:2;i:3711;}i:169;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3738;}i:170;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3738;}i:171;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:63:" Hive/Tez, Ranger, Falcon, Knox, Sqoop, Oozie, Flume, Zookeeper";}i:2;i:3739;}i:172;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3802;}i:173;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:3804;}i:174;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:3804;}i:175;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3804;}i:176;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"holger_gov";}i:2;i:3806;}i:177;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3816;}i:178;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3816;}i:179;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:12:" holger_gov ";}i:2;i:3817;}i:180;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3829;}i:181;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3829;}i:182;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:14:" Data Steward ";}i:2;i:3830;}i:183;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3844;}i:184;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3844;}i:185;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:" Atlas";}i:2;i:3845;}i:186;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3851;}i:187;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:3852;}i:188;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:3852;}i:189;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3852;}i:190;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"amy_ds";}i:2;i:3854;}i:191;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3860;}i:192;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3860;}i:193;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:" amy_ds";}i:2;i:3861;}i:194;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3868;}i:195;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3868;}i:196;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:16:" Data Scientist ";}i:2;i:3869;}i:197;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3885;}i:198;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:3885;}i:199;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:31:" Spark, Hive, R, Python, Scala ";}i:2;i:3886;}i:200;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:3917;}i:201;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:3918;}i:202;a:3:{i:0;s:11:"table_close";i:1;a:1:{i:0;i:3918;}i:2;i:3918;}i:203;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3918;}i:204;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:70:"If you want to login as admin, you need to initiate the admin password";}i:2;i:3921;}i:205;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3991;}i:206;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:101:"
# You need to ssh into the sandbox vm and type the following command
$ ambari-admin-password-reset 
";i:1;N;i:2;N;}i:2;i:3998;}i:207;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4110;}i:208;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:25:"2.5 Change Atlas password";i:1;i:3;i:2;i:4110;}i:2;i:4110;}i:209;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:4110;}i:210;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:577:"
# Change admin password
# 1. Open config GUI of atlas via ambari. 
# 2. In clause advanced atlas-env, you can change the admin password. 

# If you want to add a new user, you need to go to your sandbox vm 
# 1. Generate the hash of your password
$ echo -n "Password" | sha256sum
# 2. Open file /etc/atlas/conf/users-credentials.properties with vim
$ vim /etc/atlas/conf/users-credentials.properties
# 3. add a line like this: pliu=ROLE_ADMIN::b012da22fa1439aacbe02971d7321e56a82ad75da84bc6e27358f3593e5b9b24 
in the file.
# 4. Restart the atlas service to make it available.
";i:1;N;i:2;N;}i:2;i:4152;}i:211;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4739;}i:212;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:37:"2.6 change mysql server root password";i:1;i:3;i:2;i:4739;}i:2;i:4739;}i:213;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:4739;}i:214;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4739;}i:215;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:141:"Hortonworks sandbox uses a mysql server to store the configuration infomation, hive metastore, etc. In some version the password for root is ";}i:2;i:4788;}i:216;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:4929;}i:217;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"hadoop";}i:2;i:4931;}i:218;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:4937;}i:219;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:42:". In some version, the password is empty. ";}i:2;i:4939;}i:220;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4981;}i:221;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4981;}i:222;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:119:"But if you can't login with mysql -u root -p, you need to follow the following instructions to reset the root password.";}i:2;i:4983;}i:223;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5102;}i:224;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:5104;}i:225;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:18:"3. Common problems";i:1;i:2;i:2;i:5104;}i:2;i:5104;}i:226;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:5104;}i:227;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:5136;}i:228;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:46:"3.1 Docker container sandbox-proxy can't start";i:1;i:3;i:2;i:5136;}i:2;i:5136;}i:229;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:5136;}i:230;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5136;}i:231;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:241:"Command: Docker start sandbox-proxy
Error: Error response from daemon: driver failed programming external connectivity on endpoint sandbox-proxy (8f1dc79b789604e45f88cb15045d8dfc6d8f11f9d195ccd2765a03758759ea94):  (iptables failed: iptables ";}i:2;i:5195;}i:232;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"--";}i:2;i:5436;}i:233;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:36:"wait -t nat -A DOCKER -p tcp -d 0/0 ";}i:2;i:5438;}i:234;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"--";}i:2;i:5474;}i:235;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"dport 61888 -j DNAT ";}i:2;i:5476;}i:236;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"--";}i:2;i:5496;}i:237;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:99:"to-destination 172.18.0.3:61888 ! -i br-7e3d72e7f4ac: iptables: No chain/target/match by that name.";}i:2;i:5498;}i:238;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5597;}i:239;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5597;}i:240;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:61:"Solution: To correct this, you need to restart docker daemon ";}i:2;i:5599;}i:241;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:5660;}i:242;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"Systemctl restart docker";}i:2;i:5662;}i:243;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:5686;}i:244;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5688;}i:245;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:5690;}i:246;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:39:"3.2 Ambari can't start the hdp services";i:1;i:3;i:2;i:5690;}i:2;i:5690;}i:247;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:5690;}i:248;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5690;}i:249;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:513:"Command: Ambari start all services
Error: Mysqld daemon can't start, raise error
2019-09-20T14:09:43.429317Z 0 [ERROR] InnoDB: Ignoring the redo log due to missing MLOG_CHECKPOINT between the checkpoint 19668090 and the end 19669084.
2019-09-20T14:09:43.429326Z 0 [ERROR] InnoDB: Plugin initialization aborted with error Generic error
2019-09-20T14:09:44.029878Z 0 [ERROR] Plugin 'InnoDB' init function returned error.
2019-09-20T14:09:44.029892Z 0 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.";}i:2;i:5741;}i:250;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:6254;}i:251;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6254;}i:252;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:65:"Solution: To correct this, you need to clean the InnoDB log file ";}i:2;i:6256;}i:253;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:6321;}i:254;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:32:"rm -rf /var/lib/mysql/ib_logfile";}i:2;i:6323;}i:255;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:6355;}i:256;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:6357;}i:257;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:6360;}i:258;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:46:"3.3 Atlas add classification permission denied";i:1;i:3;i:2;i:6360;}i:2;i:6360;}i:259;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:6360;}i:260;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6360;}i:261;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:63:"Command: Add classification/term, etc.
Error: Permission denied";}i:2;i:6418;}i:262;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:6481;}i:263;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6481;}i:264;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:261:"Solution: Atlas needs to write in HBASE, In a cluster managed by ambari, we use Knox (Provides a single point of authentication and access for Apache Hadoop services in a cluster) to make the authentication and access control possible. So before running Atlas, ";}i:2;i:6483;}i:265;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:6744;}i:266;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:29:"start Knox, HBase, Solr first";}i:2;i:6746;}i:267;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:6775;}i:268;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:". ";}i:2;i:6777;}i:269;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:6779;}i:270;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:6783;}i:271;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:49:"3.4 Load hdfs data into hive table pemission deny";i:1;i:3;i:2;i:6783;}i:2;i:6783;}i:272;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:6783;}i:273;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6783;}i:274;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:62:"Command: hive load data to hive table
Error: Permission denied";}i:2;i:6844;}i:275;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:6906;}i:276;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6906;}i:277;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:232:"Solution: When load data into hive table, hive will move the data from the hdfs source location to hive data warehouse (also a hdfs path). The user who launch this command must make sure he has the right to write in both locations. ";}i:2;i:6908;}i:278;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7140;}i:279;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:7141;}i:280;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:7141;}}