
<h1 class="sectionedit1" id="flume_spark_streaming">Flume spark streaming</h1>
<div class="level1">

<p>
Flume is a very popular log collection framework. In this example, we use Flume to read data from local socket 8888, and output to local socket 6666. Then we use DStream to treat data from local socket 6666
</p>

</div>
<!-- EDIT1 SECTION "Flume spark streaming" [1-246] -->
<h2 class="sectionedit2" id="flume_configuration">Flume configuration</h2>
<div class="level2">

<p>
You can find the full flume installation and configuartion doc here : <a href="/doku.php?id=employes:pengfei.liu:data_science:flume:installation_configuration" class="wikilink1" title="employes:pengfei.liu:data_science:flume:installation_configuration">Flume installation and configuration</a>
</p>

</div>
<!-- EDIT2 SECTION "Flume configuration" [247-458] -->
<h3 class="sectionedit3" id="flume_to_spark_agent_conf">Flume to spark agent conf</h3>
<div class="level3">
<pre class="code">        #flume-to-spark.conf: A single-node Flume configuration
        # Name the components on this agent
        a1.sources = r1
        a1.sinks = k1
        a1.channels = c1

        # Describe/configure the source
        # flume read data from local socket on port 8888
        a1.sources.r1.type = netcat
        a1.sources.r1.bind = localhost
        a1.sources.r1.port = 8888

        # Describe the sink
        # flume output data to local socket on port 6666
        a1.sinks.k1.type = avro
        a1.sinks.k1.hostname = localhost
        a1.sinks.k1.port =6666

        # Use a channel which buffers events in memory
        a1.channels.c1.type = memory
        a1.channels.c1.capacity = 1000000
        a1.channels.c1.transactionCapacity = 1000000

        # Bind the source and sink to the channel
        a1.sources.r1.channels = c1
        a1.sinks.k1.channel = c1
</pre>

</div>
<!-- EDIT3 SECTION "Flume to spark agent conf" [459-1396] -->
<h3 class="sectionedit4" id="run_the_flume_agent">Run the flume agent</h3>
<div class="level3">

<p>
When you run the following agent, you may receive errors. because the avro sink write to local socket which no one listen to ever before. So it may show avro sink unable to connect to localhost on 6666
</p>
<pre class="code">flume-ng agent -f /opt/flume/flume-1.8.0/conf/agent-example/flume-to-spark.conf -n a1 -Dflume.root.logger=INFO,console
</pre>

</div>
<!-- EDIT4 SECTION "Run the flume agent" [1397-1765] -->
<h2 class="sectionedit5" id="prepare_spark_scala_script">Prepare spark scala script</h2>
<div class="level2">

<p>
The spark flume streaming is not included in the spark core. So we need to add a new dependency in the pom file
</p>
<pre class="code">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;org.pengfei&lt;/groupId&gt;
    &lt;artifactId&gt;WordCount&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;spark.version&gt;2.1.0&lt;/spark.version&gt;
        &lt;scala.version&gt;2.11&lt;/scala.version&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;

    &lt;/properties&gt;



    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-core_${scala.version}&lt;/artifactId&gt;
            &lt;version&gt;${spark.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!--dependencies for spark streaming--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-streaming_${scala.version}&lt;/artifactId&gt;
            &lt;version&gt;${spark.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!--dependencies for spark kafaka--&gt;
        &lt;dependency&gt;

            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-streaming-kafka_2.11&lt;/artifactId&gt;
        &lt;version&gt;1.6.3&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!--dependencies for flume--&gt;
        &lt;dependency&gt;

            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-streaming-flume_2.11&lt;/artifactId&gt;
            &lt;version&gt;2.2.0&lt;/version&gt;
        &lt;/dependency&gt;


        &lt;!--dependencies for kinesis--&gt;
        &lt;!--&lt;dependency&gt;

            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-streaming-kinesis-asl_2.11&lt;/artifactId&gt;
        &lt;/dependency&gt;--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-sql_${scala.version}&lt;/artifactId&gt;
            &lt;version&gt;${spark.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-hive_${scala.version}&lt;/artifactId&gt;
            &lt;version&gt;${spark.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-mllib_${scala.version}&lt;/artifactId&gt;
            &lt;version&gt;${spark.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
            &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;
            &lt;version&gt;1.2.4&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
&lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
&lt;artifactId&gt;hbase-server&lt;/artifactId&gt;
            &lt;version&gt;1.2.4&lt;/version&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;

            &lt;plugin&gt;
                &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;
                &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;
                &lt;version&gt;2.15.2&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;compile&lt;/goal&gt;
                            &lt;goal&gt;testCompile&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

            &lt;plugin&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.6.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;

            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
                &lt;version&gt;2.19&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;skip&gt;true&lt;/skip&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;

        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</pre>

<p>
Now let&#039;s see the spark scala script
</p>
<dl class="file">
<dt><a href="/doku.php?do=export_code&amp;id=employes:pengfei.liu:big_data:spark:spark_streaming:flume_streaming&amp;codeblock=3" title="Download Snippet" class="mediafile mf_scala">FlumeEventCount.scala</a></dt>
<dd><pre class="code file scala"><a href="http://scala-lang.org"><span class="kw1">package</span></a> org.<span class="me1">pengfei</span>.<span class="me1">spark</span>.<span class="me1">streaming</span>.<span class="me1">flume</span>
&nbsp;
<a href="http://scala-lang.org"><span class="kw1">import</span></a> org.<span class="me1">apache</span>.<span class="me1">spark</span>.<span class="me1">SparkConf</span>
<a href="http://scala-lang.org"><span class="kw1">import</span></a> org.<span class="me1">apache</span>.<span class="me1">spark</span>.<span class="me1">storage</span>.<span class="me1">StorageLevel</span>
<a href="http://scala-lang.org"><span class="kw1">import</span></a> org.<span class="me1">apache</span>.<span class="me1">spark</span>.<span class="me1">streaming</span>.<span class="sy0">_</span>
<a href="http://scala-lang.org"><span class="kw1">import</span></a> org.<span class="me1">apache</span>.<span class="me1">spark</span>.<span class="me1">streaming</span>.<span class="me1">flume</span>.<span class="sy0">_</span>
<a href="http://scala-lang.org"><span class="kw1">import</span></a> org.<span class="me1">apache</span>.<span class="me1">spark</span>.<span class="me1">util</span>.<span class="me1">IntParam</span>
<a href="http://scala-lang.org"><span class="kw1">object</span></a> FlumeEventCount <span class="br0">&#123;</span>
  <a href="http://scala-lang.org"><span class="kw1">def</span></a> main<span class="br0">&#40;</span>args<span class="sy0">:</span> Array<span class="br0">&#91;</span>String<span class="br0">&#93;</span><span class="br0">&#41;</span> <span class="br0">&#123;</span>
&nbsp;
&nbsp;
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> host<span class="sy0">=</span><span class="st0">&quot;127.0.0.1&quot;</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> port<span class="sy0">=</span><span class="nu0">6666</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> batchInterval <span class="sy0">=</span> Milliseconds<span class="br0">&#40;</span><span class="nu0">2000</span><span class="br0">&#41;</span>
    <span class="co1">// Create the context and set the batch size</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> sparkConf <span class="sy0">=</span> <a href="http://scala-lang.org"><span class="kw1">new</span></a> SparkConf<span class="br0">&#40;</span><span class="br0">&#41;</span>.<span class="me1">setAppName</span><span class="br0">&#40;</span><span class="st0">&quot;FlumeEventCount&quot;</span><span class="br0">&#41;</span>.<span class="me1">setMaster</span><span class="br0">&#40;</span><span class="st0">&quot;local[2]&quot;</span><span class="br0">&#41;</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> ssc <span class="sy0">=</span> <a href="http://scala-lang.org"><span class="kw1">new</span></a> StreamingContext<span class="br0">&#40;</span>sparkConf, batchInterval<span class="br0">&#41;</span>
    <span class="co1">// Create a flume stream listen to 127.0.0.1 on port 6666</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> stream <span class="sy0">=</span> FlumeUtils.<span class="me1">createStream</span><span class="br0">&#40;</span>ssc, host, port, StorageLevel.<span class="me1">MEMORY_ONLY_SER_2</span><span class="br0">&#41;</span>
    <span class="co1">// Print out the count of events received from this server in each batch</span>
&nbsp;
    stream.<span class="me1">count</span><span class="br0">&#40;</span><span class="br0">&#41;</span>.<span class="me1">map</span><span class="br0">&#40;</span>cnt <span class="sy0">=&gt;</span> <span class="st0">&quot;Received &quot;</span> + cnt + <span class="st0">&quot; flume events.&quot;</span> <span class="br0">&#41;</span>.<span class="me1">print</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
&nbsp;
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> mappedlines <span class="sy0">=</span> stream.<span class="me1">map</span><span class="br0">&#123;</span>sparkFlumeEvent <span class="sy0">=&gt;</span>
      <a href="http://scala-lang.org"><span class="kw1">val</span></a> event <span class="sy0">=</span> sparkFlumeEvent.<span class="me1">event</span>
      println<span class="br0">&#40;</span><span class="st0">&quot;Value of event &quot;</span> + event<span class="br0">&#41;</span>
      println<span class="br0">&#40;</span><span class="st0">&quot;Value of event Header &quot;</span> + event.<span class="me1">getHeaders</span><span class="br0">&#41;</span>
      println<span class="br0">&#40;</span><span class="st0">&quot;Value of event Schema &quot;</span> + event.<span class="me1">getSchema</span><span class="br0">&#41;</span>
      <a href="http://scala-lang.org"><span class="kw1">val</span></a> messageBody <span class="sy0">=</span> <a href="http://scala-lang.org"><span class="kw1">new</span></a> String<span class="br0">&#40;</span>event.<span class="me1">getBody</span>.<span class="me1">array</span><span class="br0">&#40;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      println<span class="br0">&#40;</span><span class="st0">&quot;Value of event Body &quot;</span> + messageBody<span class="br0">&#41;</span>
      messageBody<span class="br0">&#125;</span>.<span class="me1">print</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
    ssc.<span class="me1">start</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
    ssc.<span class="me1">awaitTermination</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
  <span class="br0">&#125;</span>
<span class="br0">&#125;</span></pre>
</dd></dl>

</div>
<!-- EDIT5 SECTION "Prepare spark scala script" [1766-7330] -->
<h2 class="sectionedit6" id="test_the_example">Test the example</h2>
<div class="level2">

<p>
1. run the FlumeEventCount.scala on your IDE (eclipse or Intellij).
2. run the flume agent
3. telnet 127.0.0.1 8888 and write <code>Is this line too long to be shown in flume or not</code>
</p>

<p>
You should see the following output 
</p>
<pre class="code">
-------------------------------------------
Time: 1516618084000 ms
-------------------------------------------
Received 1 flume events.

(estimated size 1211.0 B, free 1415.8 MB)
...
18/01/22 11:48:04 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks
18/01/22 11:48:04 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 108, localhost, executor driver, partition 0, ANY, 6517 bytes)
&quot;}}
Value of event Header {}
Value of event Schema {&quot;type&quot;:&quot;record&quot;,&quot;name&quot;:&quot;AvroFlumeEvent&quot;,&quot;namespace&quot;:&quot;org.apache.flume.source.avro&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;headers&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;map&quot;,&quot;values&quot;:&quot;string&quot;}},{&quot;name&quot;:&quot;body&quot;,&quot;type&quot;:&quot;bytes&quot;}]}
Value of event Body Is this line too long to be shown in flume or not
-------------------------------------------
Time: 1516618084000 ms
-------------------------------------------
Is this line too long to be shown in flume or not</pre>

</div>
<!-- EDIT6 SECTION "Test the example" [7331-] -->