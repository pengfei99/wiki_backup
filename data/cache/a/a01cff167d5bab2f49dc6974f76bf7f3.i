a:245:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:13:"Install Hbase";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1;}i:4;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:78:"Apache HBase is the Hadoop database, a distributed, scalable, big data store. ";}i:2;i:30;}i:5;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:108;}i:6;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:108;}i:7;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:476:"HBase is a column-oriented database management system that runs on top of HDFS and Hadoop. It is well suited for sparse data sets, which are common in many big data use cases. Unlike relational database systems, HBase does not support a structured query language like SQL; in fact, HBase isnâ€™t a relational data store at all. HBase applications are written in Java much like a typical MapReduce application. HBase does support writing applications in Avro, REST, and Thrift.";}i:2;i:110;}i:8;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:586;}i:9;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:586;}i:10;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:385:"Just as HDFS(Hadoop distributed File System) has a NameNode and slave nodes, HBase is built on similar concepts. In HBase a master node manages the cluster and region servers store portions of the tables and perform the work on the data. In the same way HDFS has some enterprise concerns due to the availability of the NameNode , HBase is also sensitive to the loss of its master node.";}i:2;i:589;}i:11;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:974;}i:12;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:974;}i:13;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:976;}i:14;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"Features";}i:2;i:978;}i:15;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:986;}i:16;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:0:"";}i:2;i:988;}i:17;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:989;}i:18;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:989;}i:19;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:989;}i:20;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:989;}i:21;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:32:" Linear and modular scalability.";}i:2;i:997;}i:22;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1029;}i:23;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1029;}i:24;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1029;}i:25;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1029;}i:26;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:38:" Strictly consistent reads and writes.";}i:2;i:1037;}i:27;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1075;}i:28;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1075;}i:29;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1075;}i:30;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1075;}i:31;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:46:" Automatic and configurable sharding of tables";}i:2;i:1083;}i:32;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1129;}i:33;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1129;}i:34;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1129;}i:35;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1129;}i:36;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:50:" Automatic failover support between RegionServers.";}i:2;i:1137;}i:37;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1187;}i:38;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1187;}i:39;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1187;}i:40;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1187;}i:41;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:84:" Convenient base classes for backing Hadoop MapReduce jobs with Apache HBase tables.";}i:2;i:1195;}i:42;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1279;}i:43;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1279;}i:44;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1279;}i:45;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1279;}i:46;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:18:" Easy to use Java ";}i:2;i:1287;}i:47;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:1305;}i:48;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:19:" for client access.";}i:2;i:1308;}i:49;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1327;}i:50;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1327;}i:51;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1327;}i:52;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1327;}i:53;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:53:" Block cache and Bloom Filters for real-time queries.";}i:2;i:1335;}i:54;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1388;}i:55;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1388;}i:56;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1388;}i:57;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1388;}i:58;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:50:" Query predicate push down via server side Filters";}i:2;i:1396;}i:59;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1446;}i:60;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1446;}i:61;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1446;}i:62;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1446;}i:63;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:104:" Thrift gateway and a REST-ful Web service that supports XML, Protobuf, and binary data encoding options";}i:2;i:1454;}i:64;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1558;}i:65;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1558;}i:66;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1558;}i:67;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1558;}i:68;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:36:" Extensible jruby-based (JIRB) shell";}i:2;i:1566;}i:69;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1602;}i:70;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1602;}i:71;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:3;}i:2;i:1602;}i:72;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1602;}i:73;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:95:" Support for exporting metrics via the Hadoop metrics subsystem to files or Ganglia; or via JMX";}i:2;i:1610;}i:74;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1705;}i:75;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1705;}i:76;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:1705;}i:77;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1708;}i:78;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:27:"Install and configure HBASE";i:1;i:2;i:2;i:1708;}i:2;i:1708;}i:79;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:1708;}i:80;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1749;}i:81;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:11:"Pre-requise";i:1;i:3;i:2;i:1749;}i:2;i:1749;}i:82;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:1749;}i:83;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1749;}i:84;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:31:"HBase requires JAVA and hadoop.";}i:2;i:1772;}i:85;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1803;}i:86;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1803;}i:87;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:23:"To install them go see ";}i:2;i:1805;}i:88;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:58:"employes:pengfei.liu:big_data:hadoop:install_config_hadoop";i:1;s:34:"Install hdfs on multi node cluster";}i:2;i:1828;}i:89;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:5:" and ";}i:2;i:1925;}i:90;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:37:"employes:pengfei.liu:java:install_jdk";i:1;s:34:"Install oracle jdk on ubuntu 16.04";}i:2;i:1930;}i:91;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2006;}i:92;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2008;}i:93;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:33:"Download  the current stabe HBase";i:1;i:3;i:2;i:2008;}i:2;i:2008;}i:94;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:2008;}i:95;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2008;}i:96;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"The HBase official site ";}i:2;i:2052;}i:97;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:25:"https://hbase.apache.org/";i:1;N;}i:2;i:2076;}i:98;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:37:". The current stable version is 1.2.6";}i:2;i:2101;}i:99;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2138;}i:100;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2138;}i:101;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:41:"Download it and place it under /opt/hbase";}i:2;i:2140;}i:102;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2181;}i:103;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:111:"
mkdir -p /opt/hbase

cd /opt/hbase

cp ~/Download/hbase-1.2.6-bin.tar.gz .

tar -xzvf hbase-1.2.6-bin.tar.gz

";i:1;N;i:2;N;}i:2;i:2188;}i:104;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2309;}i:105;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:22:"Add hbase home to path";i:1;i:3;i:2;i:2309;}i:2;i:2309;}i:106;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:2309;}i:107;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:139:"
sudo vim /etc/profile.d/hbase.sh

#add the following two line
export HBASE_HOME=/opt/hbase/hbase-1.2.6
export PATH=$PATH:$HBASE_HOME/bin

";i:1;N;i:2;N;}i:2;i:2349;}i:108;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2349;}i:109;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:28:"Check you hbase installation";}i:2;i:2498;}i:110;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2526;}i:111;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:274:"
[root@localhost profile.d]# hbase version
HBase 1.2.6
Source code repository file:///home/busbey/projects/hbase/hbase-assembly/target/hbase-1.2.6 revision=Unknown
Compiled by busbey on Mon May 29 02:25:32 CDT 2017
From source with checksum 7e8ce83a648e252758e9dae1fbe779c9
";i:1;N;i:2;N;}i:2;i:2533;}i:112;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2817;}i:113;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:35:"Configure HBase on stand along mode";i:1;i:2;i:2;i:2817;}i:2;i:2817;}i:114;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:2817;}i:115;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2817;}i:116;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"1. Edit the hbase-env.sh";}i:2;i:2866;}i:117;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2890;}i:118;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2890;}i:119;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:223:"A distributed Apache HBase (TM) installation depends on a running ZooKeeper cluster. All participating nodes and clients need to be able to access the running ZooKeeper ensemble. Apache HBase by default manages a ZooKeeper ";}i:2;i:2892;}i:120;a:3:{i:0;s:18:"doublequoteopening";i:1;a:0:{}i:2;i:3115;}i:121;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"cluster";}i:2;i:3116;}i:122;a:3:{i:0;s:18:"doublequoteclosing";i:1;a:0:{}i:2;i:3123;}i:123;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:441:" for you. It will start and stop the ZooKeeper ensemble as part of the HBase start/stop process. You can also manage the ZooKeeper ensemble independent of HBase and just point HBase at the cluster it should use. To toggle HBase management of ZooKeeper, use the HBASE_MANAGES_ZK variable in conf/hbase-env.sh. This variable, which defaults to true, tells HBase whether to start/stop the ZooKeeper ensemble servers as part of HBase start/stop.";}i:2;i:3124;}i:124;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3565;}i:125;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:150:"
vim hbase-env.sh

export JAVA_HOME=/opt/JAVA/jdk1.8.0_144

# This line means the hbase use his own zookeeper "cluster"
export HBASE_MANAGES_ZK=true 
";i:1;N;i:2;N;}i:2;i:3572;}i:126;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3572;}i:127;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:26:"2. Edit the hbase-site.xml";}i:2;i:3732;}i:128;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3758;}i:129;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3758;}i:130;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:180:"To store the data of hbase, we need to specify a hbase.rootdir, if you specify nothing, the default value will be /tmp/hbase-${user.name}. after restart, you will lose all the data";}i:2;i:3760;}i:131;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3940;}i:132;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:220:"
vim hbase-site.xml

#add the following xml

<configuration>
        <property>
                <name>hbase.rootdir</name>
                <value>file:///opt/hbase/hbase-tmp</value>
        </property>
</configuration>

";i:1;N;i:2;N;}i:2;i:3947;}i:133;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3947;}i:134;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:197:"3. Start and check hbase daemon
If you enconter error messages during the running of the daemon, you can check the log file for more information. Hbase logs is stored ${HBASE_HOME}/logs by default.";}i:2;i:4178;}i:135;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4375;}i:136;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:1140:"
#start the daemon
[hadoop@localhost hbase-1.2.6]$ sh bin/start-hbase.sh 
starting master, logging to /opt/hbase/hbase-1.2.6/bin/../logs/hbase-hadoop-master-localhost.localdomain.out
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0


#start the hbase shell
[hadoop@localhost hbase-1.2.6]$ hbase shell
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hbase/hbase-1.2.6/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
HBase Shell; enter 'help<RETURN>' for list of supported commands.
Type "exit<RETURN>" to leave the HBase Shell
Version 1.2.6, rUnknown, Mon May 29 02:25:32 CDT 2017

hbase(main):001:0> 
hbase(main):002:0> exit
";i:1;N;i:2;N;}i:2;i:4382;}i:137;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:5531;}i:138;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:32:"Configure HBase on top of Hadoop";i:1;i:2;i:2;i:5531;}i:2;i:5531;}i:139;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:5531;}i:140;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5531;}i:141;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:43:"In this mode, we run HBASE on top of Hadoop";}i:2;i:5577;}i:142;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5620;}i:143;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5620;}i:144;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"1. edit hbase-env.sh";}i:2;i:5622;}i:145;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5642;}i:146;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:193:"
vim hbase-env.sh

#
export JAVA_HOME=/opt/JAVA/jdk1.8.0_144
#You need to give the hadoop conf path in this server
export HBASE_CLASSPATH=${HADOOP_HOME}/etc/hadoop
export HBASE_MANAGES_ZK=true
";i:1;N;i:2;N;}i:2;i:5649;}i:147;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5649;}i:148;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:22:"2. Edit hbase-site.xml";}i:2;i:5852;}i:149;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5874;}i:150;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:307:"
<configuration>
        <property>
                <name>hbase.rootdir</name>
                <value>hdfs://localhost:9000/hbase</value>
        </property>

        <property>
                <name>hbase.cluster.distributed</name>
                <value>true</value>
        </property>
</configuration>

";i:1;N;i:2;N;}i:2;i:5881;}i:151;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:6198;}i:152;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:25:"HBase basic shell command";i:1;i:2;i:2;i:6198;}i:2;i:6198;}i:153;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:6198;}i:154;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:6237;}i:155;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:27:"List all tables in database";i:1;i:3;i:2;i:6237;}i:2;i:6237;}i:156;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:6237;}i:157;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:937:"
hbase(main):001:0> list
TABLE                                                                                                                                                                                                              
Score                                                                                                                                                                                                              
student                                                                                                                                                                                                            
teacher                                                                                                                                                                                                            
3 row(s) in 0.4140 seconds

=> ["Score", "student", "teacher"]

";i:1;N;i:2;N;}i:2;i:6281;}i:158;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:7227;}i:159;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:12:"Create table";i:1;i:3;i:2;i:7227;}i:2;i:7227;}i:160;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:7227;}i:161;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7227;}i:162;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:72:"Create a table called student, with params Sname,Ssex,Sage,Sdept,course.";}i:2;i:7251;}i:163;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7323;}i:164;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:2069:"
hbase(main):001:0> create 'student','Sname','Ssex','Sage','Sdept','course'
0 row(s) in 2.8300 seconds

=> Hbase::Table - student

hbase(main):002:0> describe 'student'
Table student is ENABLED                                                                               
student                                                                                                
COLUMN FAMILIES DESCRIPTION                                                                            
{NAME => 'Sage', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FA
LSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOC
KCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}                                      
{NAME => 'Sdept', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'F
ALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLO
CKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}                                     
{NAME => 'Sname', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'F
ALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLO
CKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}                                     
{NAME => 'Ssex', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FA
LSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOC
KCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}                                      
{NAME => 'course', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => '
FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BL
OCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}                                    
5 row(s) in 0.2530 seconds

";i:1;N;i:2;N;}i:2;i:7330;}i:165;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:9409;}i:166;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:30:"Insert a new record into table";i:1;i:3;i:2;i:9409;}i:2;i:9409;}i:167;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:9409;}i:168;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9409;}i:169;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:83:"Now we have our table student, we want to insert a new student pengfei in the table";}i:2;i:9451;}i:170;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9534;}i:171;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9534;}i:172;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:45:"Add a student with id 88888, and name pengfei";}i:2;i:9536;}i:173;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9581;}i:174;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:365:"
hbase(main):003:0> put 'student','88888','Sname','Pengfei'
0 row(s) in 0.2400 seconds

hbase(main):004:0> get 'student','88888'
COLUMN                     CELL                                                                        
 Sname:                    timestamp=1515158173790, value=Pengfei                                      
1 row(s) in 0.1360 seconds

";i:1;N;i:2;N;}i:2;i:9588;}i:175;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9588;}i:176;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:28:"add a note 80 to course math";}i:2;i:9963;}i:177;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9991;}i:178;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:469:"
hbase(main):005:0> put 'student','88888','course:math','80'
0 row(s) in 0.0730 seconds

hbase(main):006:0> get 'student','88888'
COLUMN                     CELL                                                                        
 Sname:                    timestamp=1515158173790, value=Pengfei                                      
 course:math               timestamp=1515158494491, value=80                                           
2 row(s) in 0.0720 seconds
";i:1;N;i:2;N;}i:2;i:9998;}i:179;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9998;}i:180;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:22:"Add sex and department";}i:2;i:10477;}i:181;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10499;}i:182;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:859:"
hbase(main):009:0> put 'student','88888','Sage','28'
0 row(s) in 0.0500 seconds

hbase(main):010:0> put 'student','88888','Sdept','Lyon'
0 row(s) in 0.0100 seconds

hbase(main):011:0> get 'student','88888'
COLUMN                     CELL                                                                        
 Sage:                     timestamp=1515159007446, value=28                                           
 Sdept:                    timestamp=1515159016684, value=Lyon                                         
 Sname:                    timestamp=1515158173790, value=Pengfei                                      
 Ssex:                     timestamp=1515158943452, value=M                                            
 course:math               timestamp=1515158494491, value=80                                           
5 row(s) in 0.0480 seconds

";i:1;N;i:2;N;}i:2;i:10506;}i:183;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:11375;}i:184;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:30:"delete a parameter of a record";i:1;i:3;i:2;i:11375;}i:2;i:11375;}i:185;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:11375;}i:186;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:11375;}i:187;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:87:"In no sql data base ,we can delete one parameter of a record without delete the record.";}i:2;i:11417;}i:188;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:11504;}i:189;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:669:"
hbase(main):012:0> delete 'student','88888','Ssex'
0 row(s) in 0.0680 seconds

hbase(main):013:0> get 'student','88888'
COLUMN                     CELL                                                                        
 Sage:                     timestamp=1515159007446, value=28                                           
 Sdept:                    timestamp=1515159016684, value=Lyon                                         
 Sname:                    timestamp=1515158173790, value=Pengfei                                      
 course:math               timestamp=1515158494491, value=80                                           
4 row(s) in 0.0450 seconds

";i:1;N;i:2;N;}i:2;i:11511;}i:190;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:11511;}i:191;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:71:"If you want to delete the record, you need to use the deleteall command";}i:2;i:12190;}i:192;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:12261;}i:193;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:242:"
hbase(main):014:0> deleteall 'student','88888'
0 row(s) in 0.0370 seconds

hbase(main):015:0> scan 'student'
ROW                        COLUMN+CELL                                                                 
0 row(s) in 0.0940 seconds

";i:1;N;i:2;N;}i:2;i:12268;}i:194;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:12520;}i:195;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:17:"Data Visulization";i:1;i:3;i:2;i:12520;}i:2;i:12520;}i:196;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:12520;}i:197;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:1239:"
#view all data in table student
hbase(main):006:0> scan 'student'
ROW                        COLUMN+CELL                                                                 
 88888                     column=Sage:, timestamp=1515161801042, value=28                             
 88888                     column=Sdept:, timestamp=1515161812185, value=Lyon                          
 88888                     column=Sname:, timestamp=1515161773546, value=Pengfei                       
 88888                     column=course:math, timestamp=1515161789105, value=80                       
1 row(s) in 0.1150 seconds

# view data with specific row key
hbase(main):007:0> get 'student', '88888'
COLUMN                     CELL                                                                        
 Sage:                     timestamp=1515161801042, value=28                                           
 Sdept:                    timestamp=1515161812185, value=Lyon                                         
 Sname:                    timestamp=1515161773546, value=Pengfei                                      
 course:math               timestamp=1515161789105, value=80                                           
4 row(s) in 0.0830 seconds

";i:1;N;i:2;N;}i:2;i:12555;}i:198;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:13804;}i:199;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:10:"Drop table";i:1;i:3;i:2;i:13804;}i:2;i:13804;}i:200;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:13804;}i:201;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:13804;}i:202;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:40:"To drop a table, you need to do two step";}i:2;i:13826;}i:203;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:13866;}i:204;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:13866;}i:205;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:13866;}i:206;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:13866;}i:207;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:14:" disable table";}i:2;i:13870;}i:208;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:13884;}i:209;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:13884;}i:210;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:13884;}i:211;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:13884;}i:212;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:" drop table";}i:2;i:13888;}i:213;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:13899;}i:214;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:13899;}i:215;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:13899;}i:216;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:13899;}i:217;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:54:"A table can be disabled and enabled. It's revers-able.";}i:2;i:13901;}i:218;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:13961;}i:219;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:881:"
hbase(main):011:0> disable 'student'
0 row(s) in 2.3430 seconds

hbase(main):012:0> scan 'student'
ROW                        COLUMN+CELL                                                                 

ERROR: student is disabled.


hbase(main):009:0> enable 'student'
0 row(s) in 1.3950 seconds

hbase(main):010:0> scan 'student'
ROW                        COLUMN+CELL                                                                 
 88888                     column=Sage:, timestamp=1515161801042, value=28                             
 88888                     column=Sdept:, timestamp=1515161812185, value=Lyon                          
 88888                     column=Sname:, timestamp=1515161773546, value=Pengfei                       
 88888                     column=course:math, timestamp=1515161789105, value=80                       
1 row(s) in 0.1190 seconds

";i:1;N;i:2;N;}i:2;i:13961;}i:220;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:13961;}i:221;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:71:"The drop table command is persistent, which means you lose data forever";}i:2;i:14852;}i:222;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:14929;}i:223;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:233:"
hbase(main):013:0> drop 'student'
0 row(s) in 1.3630 seconds

hbase(main):014:0> scan 'student'
ROW                        COLUMN+CELL                                                                 

ERROR: Unknown table student!

";i:1;N;i:2;N;}i:2;i:14929;}i:224;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:15172;}i:225;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:33:"Create table with version control";i:1;i:3;i:2;i:15172;}i:2;i:15172;}i:226;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:15172;}i:227;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:15172;}i:228;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:248:"When you create a table, you can specify how many version you want to persist in you database
For example, if you put version=5, it will save 5 values for the same key, if you put 6th value in the same key, the first valut will be eraced by the 6th";}i:2;i:15217;}i:229;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:15471;}i:230;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:1359:"
 hbase(main):015:0> create 'teacher',{NAME=>'username',VERSIONS=>5}
0 row(s) in 2.3150 seconds

=> Hbase::Table - teacher
hbase(main):016:0> put 'teacher','91001','username','pengfei'
0 row(s) in 0.1080 seconds

hbase(main):017:0> put 'teacher','91001','username','1'
0 row(s) in 0.0350 seconds

hbase(main):018:0> put 'teacher','91001','username','2'
0 row(s) in 0.0640 seconds

hbase(main):019:0> put 'teacher','91001','username','3'
0 row(s) in 0.0180 seconds

hbase(main):020:0> put 'teacher','91001','username','4'
0 row(s) in 0.0220 seconds

hbase(main):021:0> put 'teacher','91001','username','5'
0 row(s) in 0.0170 seconds

hbase(main):022:0> get 'teacher','91001',{COLUMN=>'username',VERSIONS=>5}
COLUMN                     CELL                                                                        
 username:                 timestamp=1515162517842, value=5                                            
 username:                 timestamp=1515162514178, value=4                                            
 username:                 timestamp=1515162511459, value=3                                            
 username:                 timestamp=1515162507599, value=2                                            
 username:                 timestamp=1515162505028, value=1                                            
5 row(s) in 0.0550 seconds

";i:1;N;i:2;N;}i:2;i:15471;}i:231;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:15471;}i:232;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:93:"You could notice that the first username is pengfei, it's been erased by 6th username value 5";}i:2;i:16840;}i:233;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:16933;}i:234;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:16935;}i:235;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:10:"exit shell";i:1;i:3;i:2;i:16935;}i:2;i:16935;}i:236;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:16935;}i:237;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:59:"
hbase(main):023:0> exit
[hadoop@localhost hbase-1.2.6]$ 

";i:1;N;i:2;N;}i:2;i:16962;}i:238;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:17031;}i:239;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:8:"JAVA API";i:1;i:2;i:2;i:17031;}i:2;i:17031;}i:240;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:17031;}i:241;a:3:{i:0;s:4:"file";i:1;a:3:{i:0;s:2988:"

<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>org.pengfei</groupId>
    <artifactId>hbase</artifactId>
    <version>1.0-SNAPSHOT</version>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>

<dependencies>
       

        <!-- hbase client dependencies -->
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-client</artifactId>
            <version>1.2.4</version>
        </dependency>

    </dependencies>
    
    <build>
        <plugins>
        <!-- jar plugin defines the manifest properties of the resultant jar. 
        For example, in our example org.pengfei.hbase.ExampleForHbase is mentioned as the 
        class containing main() method of the java project which need to be executed 
        when the jar is executed. Following is the plugin which defines the jar manifest properties: -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <configuration>
                <archive>
                 <manifest>
                 <addClasspath>true</addClasspath>
                <classpathPrefix>lib/</classpathPrefix>
                <mainClass>org.pengfei.hbase.ExampleForHbase</mainClass>
                 </manifest>
                </archive>
                </configuration>
            </plugin>

            <plugin>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.6.0</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                </configuration>
            </plugin>
<!--
The depenency plugin defines what to do with the dependencies during the different types of maven executions.
For example, the following properties make sure that all the dependies are copied to the lib folder in the jar while executing the install maven command.
-->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-dependency-plugin</artifactId>
                <executions>
                    <execution>
                        <id>copy</id>
                        <phase>install</phase>
                        <goals>
                            <goal>copy-dependencies</goal>
                        </goals>
                        <configuration>
                            <outputDirectory>${project.build.directory}/lib</outputDirectory>
                        </configuration>
                    </execution>
                </executions>
            </plugin>

        </plugins>
    </build>
</project>
";i:1;s:3:"xml";i:2;s:7:"pom.xml";}i:2;i:17058;}i:242;a:3:{i:0;s:4:"file";i:1;a:3:{i:0;s:7423:"
package org.pengfei.hbase

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import java.io.IOException;

public class ExampleForHbase {
    public static Configuration configuration;
    public static Connection connect;
    public static Admin admin;

    public static void main(String[] args) throws IOException {
        //equivalent shell command: create 'Score','sname','course'
        //createTable("Score",new String[]{"sname","course"});
        //Insert a row into table Score with row key value 95001, the column family is sname, the value is Mary
        //Because sname column family does not have any child, so col parameter is empty
        // equivalent shell command put 'Score','95001','sname','Mary'
        insertRow("Score", "95001", "sname", "", "Mary");
        //Insert a row with row key 95001, column Math of column family course (course:Math), the row value is 88
        //equivalent shell command put 'Score','95001','score:Math','88'
        insertRow("Score", "95001", "course", "Math", "88");

        //Insert another row as put 'Score','95001','score:English','85'
        insertRow("Score", "95001", "course", "English", "85");

        //1 delete row of column score:Math with rowkey 95001
        //equivalent shell command delete 'Score','95001','score:Math'
        deleteRow("Score", "95002", "course", "Math");

        //2 delete row of column family course, the column(e.g. math, english) under column family course will be all deleted
        //equivalent shell command delete 'Score','95001','course'
        //deleteRow("Score", "95001", "course", "");

        //3 delete row with row key 95001 (all column family data will be removed)
        //eqivalent command in shell deleteall 'Score','95001'
        //deleteRow("Score", "95001", "", "");

        //get data of row with row key 95001 of the column course:Math
        //getData("Score", "95001", "course", "Math");
        //get data of row with row key 95001 of column family sname
        //getData("Score", "95001", "sname", "");

        //delete table
        //deleteTable("Score");

        
    }
    /**
* Create a table in the HBase server
* @param tableName is the name of the table you are creating
* @param colFamily is a list of column families names
* @throws IOException
* */
    private static void createTable(String tableName, String[] colFamily) throws IOException {
        init();
        TableName tabName = TableName.valueOf(tableName);
        if(admin.tableExists(tabName)){
            System.out.println("Table name already exists");
        }else{
            //The constructor with String as table name is deprecated
            HTableDescriptor hTableDescriptor = new HTableDescriptor(tabName);
        for (String str:colFamily){
            HColumnDescriptor hColumnDescriptor=new HColumnDescriptor(tableName);
            hTableDescriptor.addFamily(hColumnDescriptor);
        }
        admin.createTable(hTableDescriptor);
            System.out.println("Create table success");
        }
    }

    //This method set up a connection to Hbase server
    private static void init(){
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.rootdir","hdfs://localhost:9000/hbase");

        try {
            connect=ConnectionFactory.createConnection(configuration);
            admin = connect.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }

    }

    //This method close the connection to Hbase server
    private static void close(){
        try{
            if(admin != null){
                admin.close();
            }
            if(null != connect){
                connect.close();
            }
        }catch (IOException e){
            e.printStackTrace();
        }
    }

    /**
     * This method deletes a table with the given name
     * @param tableName
     * @throws IOException
     */
    public static void deleteTable(String tableName) throws IOException {
        init();
        TableName tn = TableName.valueOf(tableName);
        if (admin.tableExists(tn)) {
            admin.disableTable(tn);
            admin.deleteTable(tn);
        }
        close();
    }

    /**
     * show existing table
     * @throws IOException
     */
    public static void listTables() throws IOException {
        init();
        HTableDescriptor hTableDescriptors[] = admin.listTables();
        for(HTableDescriptor hTableDescriptor :hTableDescriptors){
            System.out.println(hTableDescriptor.getNameAsString());
        }
        close();
    }
    /**
     * insert a row into a column of a columnFamily with given table name
     * @param tableName specify which table you want to insert the row
     * @param rowKey specify the key id of a row
     * @param colFamily column family name
     * @param col column name, it can be empty if the colFamily doesn't have any column
     * @param val row value which we want to insert.
     * @throws IOException
     */
    public static void insertRow(String tableName,String rowKey,String colFamily,String col,String val) throws IOException {
        init();
        Table table = connect.getTable(TableName.valueOf(tableName));
        Put put = new Put(rowKey.getBytes());
        put.addColumn(colFamily.getBytes(), col.getBytes(), val.getBytes());
        table.put(put);
        table.close();
        close();
    }

    /**
     * delete a row value of a column in a column family
     * @param tableName
     * @param rowKey
     * @param colFamily
     * @param col
     * @throws IOException
     */
    public static void deleteRow(String tableName,String rowKey,String colFamily,String col) throws IOException {
        init();
        Table table = connect.getTable(TableName.valueOf(tableName));
        Delete delete = new Delete(rowKey.getBytes());
        //delete all data in one column family
        delete.addFamily(colFamily.getBytes());
        //delete all data in one column of one column family
        delete.addColumn(colFamily.getBytes(), col.getBytes());

        table.delete(delete);
        table.close();
        close();
    }
    /**
     * get value of one row based on its row key
     * @param tableName
     * @param rowKey
     * @param colFamily
     * @param col
     * @throws IOException
     */
    public static void getData(String tableName,String rowKey,String colFamily,String col)throws  IOException{
        init();
        Table table = connect.getTable(TableName.valueOf(tableName));
        Get get = new Get(rowKey.getBytes());
        get.addColumn(colFamily.getBytes(),col.getBytes());
        Result result = table.get(get);
        showCell(result);
        table.close();
        close();
    }
    /**
     *
     * @param result
     */
    public static void showCell(Result result){
        Cell[] cells = result.rawCells();
        for(Cell cell:cells){
            System.out.println("RowName:"+new String(CellUtil.cloneRow(cell))+" ");
            System.out.println("Timetamp:"+cell.getTimestamp()+" ");
            System.out.println("column Family:"+new String(CellUtil.cloneFamily(cell))+" ");
            System.out.println("column Name:"+new String(CellUtil.cloneQualifier(cell))+" ");
            System.out.println("value:"+new String(CellUtil.cloneValue(cell))+" ");
        }
    }
}

";i:1;s:4:"java";i:2;s:20:"ExampleForHbase.java";}i:2;i:20073;}i:243;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:27532;}i:244;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:27532;}}