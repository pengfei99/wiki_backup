a:27:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:22:"Spark socket streaming";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1;}i:4;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:45:"Spark socket streaming can listen to a socket";}i:2;i:40;}i:5;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:85;}i:6;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:87;}i:7;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:14:"Simple example";i:1;i:2;i:2;i:87;}i:2;i:87;}i:8;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:87;}i:9;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:87;}i:10;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:110:"In this example, we just listen to a socket (localhost, port 8888)and count all the words send to this socket.";}i:2;i:115;}i:11;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:225;}i:12;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:227;}i:13;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:25:"start the spark streaming";i:1;i:3;i:2;i:227;}i:2;i:227;}i:14;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:227;}i:15;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:433:"
scala> import org.apache.spark.streaming._
scala> import org.apache.spark._
scala> import org.apache.spark.storage.StorageLevel
scala> val ssc = new StreamingContext(sc,Seconds(60))
scala> val lines = ssc.socketTextStream("localhost",8888,StorageLevel.MEMORY_AND_DISK_SER)
scala> val words = lines.flatMap(_.split(" "))
scala> val wordCounts = words.map(x => (x, 1)).reduceByKey(_ + _)
scala> wordCounts.print()
scala> ssc.start()

";i:1;N;i:2;N;}i:2;i:269;}i:16;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:712;}i:17;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:40:"Send message to socket 8888 on localhost";i:1;i:3;i:2;i:712;}i:2;i:712;}i:18;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:712;}i:19;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:61:"
[root@localhost log]# nc -lk 8888
hello
my name is pengfei

";i:1;N;i:2;N;}i:2;i:768;}i:20;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:839;}i:21;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:29:"Result of the spark streaming";i:1;i:3;i:2;i:839;}i:2;i:839;}i:22;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:839;}i:23;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:293:"
-------------------------------------------
Time: 1516100520000 ms
-------------------------------------------
(hello,1)

-------------------------------------------
Time: 1516100580000 ms
-------------------------------------------
(is,2)
(,1)
(my,1)
(what,1)
(pengfei,1)
(name,2)
(your,1)

";i:1;N;i:2;N;}i:2;i:886;}i:24;a:3:{i:0;s:4:"file";i:1;a:3:{i:0;s:1165:"
package org.pengfei.spark

import org.apache.spark.SparkConf
import org.apache.spark.storage.StorageLevel
import org.apache.spark.streaming.{Seconds, StreamingContext}

object SparkSocketStreaming {
  def main(args: Array[String]) {
    /*if (args.length < 2) {
      System.err.println("Usage: NetworkWordCount <hostname> <port>")
      System.exit(1)
    }*/

    //StreamingExamples.setStreamingLogLevels()

    // Create the context with a 1 second batch size
    val sparkConf = new SparkConf().setAppName("NetworkWordCount").setMaster("local")
    val ssc = new StreamingContext(sparkConf, Seconds(10))

    // Create a socket stream on target ip:port and count the
    // words in input stream of \n delimited text (eg. generated by 'nc')
    // Note that no duplication in storage level only for running locally.
    // Replication necessary in distributed scenario for fault tolerance.
    val lines = ssc.socketTextStream("localhost", 8888, StorageLevel.MEMORY_AND_DISK_SER)
    val words = lines.flatMap(_.split(" "))
    val wordCounts = words.map(x => (x, 1)).reduceByKey(_ + _)
    wordCounts.print()
    ssc.start()
    ssc.awaitTermination()
  }
}
";i:1;s:5:"scala";i:2;s:26:"SparkSocketStreaming.scala";}i:2;i:1194;}i:25;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2400;}i:26;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:2400;}}