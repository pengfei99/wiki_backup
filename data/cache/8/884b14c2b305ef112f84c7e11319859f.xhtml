
<h1 class="sectionedit1" id="lesson3handle_unstructured_data">Lesson3: Handle unstructured data</h1>
<div class="level1">

<p>
In this tutorial, we will learn how to use spark to read unstructured data and convert them to structure data.
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Lesson3: Handle unstructured data&quot;,&quot;hid&quot;:&quot;lesson3handle_unstructured_data&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:1,&quot;range&quot;:&quot;1-161&quot;} -->
<h2 class="sectionedit2" id="data_source">3.1 Data source</h2>
<div class="level2">

<p>
The source data is generated by an apache web server, which is the access log of a web site. The following shows the first five lines of the file.
</p>
<pre class="code">79.133.215.123 - - [14/Jun/2014:10:30:13 -0400] &quot;GET /home HTTP/1.1&quot; 200 1671 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36&quot;                                                                                                            

162.235.161.200 - - [14/Jun/2014:10:30:13 -0400] &quot;GET /department/apparel/category/featured%20shops/product/adidas%20Kids&#039;%20RG%20III%20Mid%20Football%20Cleat HTTP/1.1&quot; 200 1175 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.76.4 (KHTML, like Gecko) Version/7.0.4 Safari/537.76.4&quot;|

39.244.91.133 - - [14/Jun/2014:10:30:14 -0400] &quot;GET /department/fitness HTTP/1.1&quot; 200 1435 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36&quot;                                                                                    

150.47.54.136 - - [14/Jun/2014:10:30:14 -0400] &quot;GET /department/fan%20shop/category/water%20sports/product/Pelican%20Sunstream%20100%20Kayak/add_to_cart HTTP/1.1&quot; 200 1932 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36&quot;

217.89.36.129 - - [14/Jun/2014:10:30:14 -0400] &quot;GET /view_cart HTTP/1.1&quot; 200 1401 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0&quot; </pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;3.1 Data source&quot;,&quot;hid&quot;:&quot;data_source&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:2,&quot;range&quot;:&quot;162-1726&quot;} -->
<h2 class="sectionedit3" id="read_the_log_file_and_give_it_a_schema">3.2 Read the log file and give it a schema</h2>
<div class="level2">
<pre class="code scala"><span class="co1">// Read raw data</span>
<a href="http://scala-lang.org"><span class="kw1">val</span></a> filePath <span class="sy0">=</span> s<span class="st0">&quot;${path}/access.log.2&quot;</span>
<a href="http://scala-lang.org"><span class="kw1">val</span></a> rawDf <span class="sy0">=</span> spark.<span class="me1">read</span>.<span class="me1">text</span><span class="br0">&#40;</span>filePath<span class="br0">&#41;</span>
&nbsp;
<span class="co1">// split raw data into a token list</span>
<a href="http://scala-lang.org"><span class="kw1">val</span></a> splitDf <span class="sy0">=</span> rawDf.<span class="me1">select</span><span class="br0">&#40;</span>split<span class="br0">&#40;</span>col<span class="br0">&#40;</span><span class="st0">&quot;value&quot;</span><span class="br0">&#41;</span>, <span class="st0">&quot; &quot;</span><span class="br0">&#41;</span>.<span class="me1">as</span><span class="br0">&#40;</span><span class="st0">&quot;tokenList&quot;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
&nbsp;
<span class="co1">// transform token list into dataframe</span>
<a href="http://scala-lang.org"><span class="kw1">val</span></a> tokenizedDf <span class="sy0">=</span> splitDf.<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;host&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">0</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;rfc931&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">1</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;authuser&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">2</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;date&quot;</span>, concat<span class="br0">&#40;</span>$<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">3</span><span class="br0">&#41;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">4</span><span class="br0">&#41;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;request&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">6</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;status&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">8</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;bytes&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">9</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">drop</span><span class="br0">&#40;</span><span class="st0">&quot;tokenList&quot;</span><span class="br0">&#41;</span>
&nbsp;
tokenizedDf.<span class="me1">show</span><span class="br0">&#40;</span><span class="nu0">5</span>, <a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span></pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;3.2 Read the log file and give it a schema&quot;,&quot;hid&quot;:&quot;read_the_log_file_and_give_it_a_schema&quot;,&quot;codeblockOffset&quot;:1,&quot;secid&quot;:3,&quot;range&quot;:&quot;1727-2519&quot;} -->
<h2 class="sectionedit4" id="analyze_the_data">3.3 Analyze the data</h2>
<div class="level2">
<pre class="code scala"><span class="co1">//get all the response status of the request</span>
tokenizedDf.<span class="me1">select</span><span class="br0">&#40;</span><span class="st0">&quot;status&quot;</span><span class="br0">&#41;</span>.<span class="me1">distinct</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
&nbsp;
<span class="co1">// get the top ten most visit product</span>
 <a href="http://scala-lang.org"><span class="kw1">val</span></a> mostViewedPage <span class="sy0">=</span> tokenizedDf.<span class="me1">filter</span><span class="br0">&#40;</span>$<span class="st0">&quot;request&quot;</span>.<span class="me1">contains</span><span class="br0">&#40;</span><span class="st0">&quot;product&quot;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>.<span class="me1">groupBy</span><span class="br0">&#40;</span>$<span class="st0">&quot;request&quot;</span><span class="br0">&#41;</span>.<span class="me1">count</span><span class="br0">&#40;</span><span class="br0">&#41;</span>.<span class="me1">orderBy</span><span class="br0">&#40;</span>$<span class="st0">&quot;count&quot;</span>.<span class="me1">desc</span><span class="br0">&#41;</span></pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;3.3 Analyze the data&quot;,&quot;hid&quot;:&quot;analyze_the_data&quot;,&quot;codeblockOffset&quot;:2,&quot;secid&quot;:4,&quot;range&quot;:&quot;2520-2823&quot;} -->
<h2 class="sectionedit5" id="clean_the_data">3.4 Clean the data</h2>
<div class="level2">

<p>
In the previous step, we have the top 10 most visit product, but they are not clean, we want to keep only 
the product name and the visit count
</p>
<pre class="code scala"> <span class="coMULTI">/* If we want to replace the 20% by space in the request, we can use the regexp_replace*/</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> betterView <span class="sy0">=</span> mostViewedPage.<span class="me1">select</span><span class="br0">&#40;</span>regexp<span class="sy0">_</span>replace<span class="br0">&#40;</span>$<span class="st0">&quot;request&quot;</span>, <span class="st0">&quot;%20&quot;</span>, <span class="st0">&quot; &quot;</span><span class="br0">&#41;</span>.<span class="me1">alias</span><span class="br0">&#40;</span><span class="st0">&quot;request&quot;</span><span class="br0">&#41;</span>, $<span class="st0">&quot;count&quot;</span><span class="br0">&#41;</span>
&nbsp;
     <span class="coMULTI">/* refine data frame, only keep product name, and rename column name*/</span>
&nbsp;
    <span class="coMULTI">/*Here we use a interesting spark sql function substring_index to get the product name
    * substring_index(str, delim, count) : Returns the substring from str before count occurrences of the delimiter
    *          delim. If count is positive, everything to the left of the final delimiter (counting from the left) is
    *          returned. If count is negative, everything to the right of the final delimiter (counting from the right)
    *          is returned.
    *
    * For example, if we want to keep the head of the string(www), then we do the following
    * SELECT substring_index('www.apache.org', '.', 1);
    * If we want to keep the tail of the string(org), then we do the following
    * SELECT substring_index('www.apache.org', '.', -1);
    * */</span>
   <span class="coMULTI">/* After analysis, we found we have false data in access log, so we want to remove all lines which has &quot;add_to_cart&quot;
    * as product_name, we use filter() which takes boolean expression as argument, notice we can't use ! for negation
    * here, we need to use not()
    * */</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> productVisitNumber <span class="sy0">=</span> betterView
        .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;product_name&quot;</span>,substring<span class="sy0">_</span>index<span class="br0">&#40;</span>col<span class="br0">&#40;</span><span class="st0">&quot;request&quot;</span><span class="br0">&#41;</span>,<span class="st0">&quot;/&quot;</span>,-<span class="nu0">1</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
        .<span class="me1">withColumnRenamed</span><span class="br0">&#40;</span><span class="st0">&quot;count&quot;</span>,<span class="st0">&quot;view_number&quot;</span><span class="br0">&#41;</span>
        .<span class="me1">drop</span><span class="br0">&#40;</span><span class="st0">&quot;request&quot;</span><span class="br0">&#41;</span>
        .<span class="me1">filter</span><span class="br0">&#40;</span>not<span class="br0">&#40;</span>$<span class="st0">&quot;product_name&quot;</span>.<span class="me1">contains</span><span class="br0">&#40;</span><span class="st0">&quot;add_to_cart&quot;</span><span class="br0">&#41;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
        .<span class="me1">select</span><span class="br0">&#40;</span><span class="st0">&quot;product_name&quot;</span>,<span class="st0">&quot;view_number&quot;</span><span class="br0">&#41;</span></pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;3.4 Clean the data&quot;,&quot;hid&quot;:&quot;clean_the_data&quot;,&quot;codeblockOffset&quot;:3,&quot;secid&quot;:5,&quot;range&quot;:&quot;2824-4655&quot;} -->
<h2 class="sectionedit6" id="save_the_result_to_hive">3.5 Save the result to hive</h2>
<div class="level2">

<p>
In HDP 3.0 and later, Spark and Hive use independent catalogs for accessing SparkSQL or Hive tables on the same or different platforms. A table created by Spark resides in the Spark catalog. A table created by Hive resides in the Hive catalog. Databases fall under the catalog namespace, similar to how tables belong to a database namespace. Although independent, these tables interoperate and you can see Spark tables in the Hive catalog, but only when using the Hive Warehouse Connector.
</p>

<p>
You can use the Hive Warehouse Connector (HWC) <abbr title="Application Programming Interface">API</abbr> to access any type of table in the Hive catalog from Spark. When you use SparkSQL, standard Spark APIs access tables in the Spark catalog.
</p>

<p>
Using HWC, you can export tables and extracts from the Spark catalog to Hive and from the Hive catalog to Spark. You export tables and extracts from the Spark catalog to Hive by reading them using Spark APIs and writing them to the Hive catalog using the HWC. You must use low-latency analytical processing (LLAP) in HiveServer Interactive to read ACID, or other Hive-managed tables, from Spark. You do not need LLAP to write to ACID, or other managed tables, from Spark. You do not need HWC to access external tables from Spark.
</p>

<p>
Using the HWC, you can read and write Apache Spark DataFrames and Streaming DataFrames. Apache Ranger and the HiveWarehouseConnector library provide row and column, fine-grained access to the data.
</p>

<p>
Limitations
</p>
<ul>
<li class="level1"><div class="li"> HWC supports tables in ORC format only.</div>
</li>
<li class="level1"><div class="li"> The spark thrift server is not supported.</div>
</li>
</ul>

<p>
Check <a href="https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.4/integrating-hive/content/hive_hivewarehouseconnector_for_handling_apache_spark_data.html" class="urlextern" title="https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.4/integrating-hive/content/hive_hivewarehouseconnector_for_handling_apache_spark_data.html" rel="nofollow">https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.4/integrating-hive/content/hive_hivewarehouseconnector_for_handling_apache_spark_data.html</a>
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;3.5 Save the result to hive&quot;,&quot;hid&quot;:&quot;save_the_result_to_hive&quot;,&quot;codeblockOffset&quot;:4,&quot;secid&quot;:6,&quot;range&quot;:&quot;4656-6361&quot;} -->
<h3 class="sectionedit7" id="write_data_frame_as_hive_table_in_spark_catalog">Write data frame as hive table in spark catalog</h3>
<div class="level3">
<pre class="code scala"><span class="co1">// list data base and table in spark catalog</span>
spark.<span class="me1">catalog</span>.<span class="me1">listDatabases</span><span class="br0">&#40;</span><span class="br0">&#41;</span>.<span class="me1">show</span><span class="br0">&#40;</span><a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span>
spark.<span class="me1">catalog</span>.<span class="me1">listTables</span><span class="br0">&#40;</span><span class="br0">&#41;</span>.<span class="me1">show</span><span class="br0">&#40;</span><a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span>
&nbsp;
<span class="co1">//create table </span>
spark.<span class="me1">sql</span><span class="br0">&#40;</span><span class="st0">&quot;CREATE TABLE product_visit_number (product_name String, view_number Int)&quot;</span><span class="br0">&#41;</span>
&nbsp;
<span class="co1">//write data frame to table</span>
productVisitNumber.<span class="me1">write</span>.<span class="me1">mode</span><span class="br0">&#40;</span>SaveMode.<span class="me1">Overwrite</span><span class="br0">&#41;</span>.<span class="me1">saveAsTable</span><span class="br0">&#40;</span><span class="st0">&quot;product_visit_number&quot;</span><span class="br0">&#41;</span>
&nbsp;
<span class="co1">//show data in the table</span>
spark.<span class="me1">sql</span><span class="br0">&#40;</span><span class="st0">&quot;select * from product_visit_number limit 10&quot;</span><span class="br0">&#41;</span>.<span class="me1">show</span><span class="br0">&#40;</span><span class="br0">&#41;</span></pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Write data frame as hive table in spark catalog&quot;,&quot;hid&quot;:&quot;write_data_frame_as_hive_table_in_spark_catalog&quot;,&quot;codeblockOffset&quot;:4,&quot;secid&quot;:7,&quot;range&quot;:&quot;6362-6876&quot;} -->
<h3 class="sectionedit8" id="export_csv_and_load_to_hive_catalog">Export csv and load to hive catalog</h3>
<div class="level3">

<p>
The other workaround is export data frame to CSV and loads CSV with the following process
</p>

<p>
Step1: Export data as csv
</p>
<pre class="code scala"><span class="co1">// function to write data in hdfs</span>
<a href="http://scala-lang.org"><span class="kw1">def</span></a> WriteDataToDisk<span class="br0">&#40;</span>df<span class="sy0">:</span>DataFrame,outputPath<span class="sy0">:</span>String,fileName<span class="sy0">:</span>String<span class="br0">&#41;</span><span class="sy0">:</span> Unit <span class="sy0">=</span><span class="br0">&#123;</span>
    df.<span class="me1">coalesce</span><span class="br0">&#40;</span><span class="nu0">1</span><span class="br0">&#41;</span>.<span class="me1">write</span>.<span class="me1">mode</span><span class="br0">&#40;</span>SaveMode.<span class="me1">Overwrite</span><span class="br0">&#41;</span>
      .<span class="me1">option</span><span class="br0">&#40;</span><span class="st0">&quot;header&quot;</span>,<span class="st0">&quot;true&quot;</span><span class="br0">&#41;</span>
      .<span class="me1">option</span><span class="br0">&#40;</span><span class="st0">&quot;mapreduce.fileoutputcommitter.marksuccessfuljobs&quot;</span>,<span class="st0">&quot;false&quot;</span><span class="br0">&#41;</span> <span class="co1">//Avoid creating of crc files</span>
      .<span class="me1">option</span><span class="br0">&#40;</span><span class="st0">&quot;encoding&quot;</span>, <span class="st0">&quot;UTF-8&quot;</span><span class="br0">&#41;</span>
      .<span class="me1">option</span><span class="br0">&#40;</span><span class="st0">&quot;delimiter&quot;</span>, <span class="st0">&quot;,&quot;</span><span class="br0">&#41;</span> 
      .<span class="me1">csv</span><span class="br0">&#40;</span>outputPath+<span class="st0">&quot;/&quot;</span>+fileName<span class="br0">&#41;</span>
  <span class="br0">&#125;</span>
&nbsp;
<span class="co1">// call function</span>
WriteDataToDisk<span class="br0">&#40;</span>productVisitNumber,<span class="st0">&quot;/tmp/demo_data&quot;</span>,<span class="st0">&quot;product_visit_number&quot;</span><span class="br0">&#41;</span>  </pre>

<p>
Step2: Create a table inside the hive
</p>
<pre class="code"># The table must use STORED AS TEXTFILE, by default in hive table is stored as orc.
# But we can&#039;t load csv data into orc table 
CREATE TABLE product_visit_number(product_name STRING, view_number INT) row format delimited fields terminated BY &#039;,&#039; lines terminated BY &#039;\n&#039; STORED AS TEXTFILE tblproperties(&quot;skip.header.line.count&quot;=&quot;1&quot;); 
</pre>

<p>
Step3: load data into the table
</p>
<pre class="code">LOAD DATA INPATH &quot;/tmp/demo_data/product_visit_number/data.csv&quot; OVERWRITE INTO TABLE product_visit_number;
</pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Export csv and load to hive catalog&quot;,&quot;hid&quot;:&quot;export_csv_and_load_to_hive_catalog&quot;,&quot;codeblockOffset&quot;:5,&quot;secid&quot;:8,&quot;range&quot;:&quot;6877-8113&quot;} -->
<h2 class="sectionedit9" id="full_code_for_creating_the_product_visit_number_dataframe">3.6 Full code for creating the product visit number dataframe</h2>
<div class="level2">
<dl class="file">
<dt><a href="/doku.php?do=export_code&amp;id=employes:pengfei.liu:big_data:hdp:lesson3&amp;codeblock=8" title="Download Snippet" class="mediafile mf_scala">AccessLog.scala</a></dt>
<dd><pre class="code file scala"><a href="http://scala-lang.org"><span class="kw1">import</span></a> com.<span class="me1">typesafe</span>.<span class="me1">config</span>.<span class="me1">ConfigFactory</span>
<a href="http://scala-lang.org"><span class="kw1">import</span></a> org.<span class="me1">apache</span>.<span class="me1">log4j</span>.<span class="br0">&#123;</span>Level, Logger<span class="br0">&#125;</span>
<a href="http://scala-lang.org"><span class="kw1">import</span></a> org.<span class="me1">apache</span>.<span class="me1">spark</span>.<span class="me1">sql</span>.<span class="me1">SparkSession</span>
<a href="http://scala-lang.org"><span class="kw1">import</span></a> org.<span class="me1">apache</span>.<span class="me1">spark</span>.<span class="me1">sql</span>.<span class="me1">functions</span>.<span class="sy0">_</span>
&nbsp;
<a href="http://scala-lang.org"><span class="kw1">object</span></a> AccessLog <span class="br0">&#123;</span>
&nbsp;
  <a href="http://scala-lang.org"><span class="kw1">def</span></a> main<span class="br0">&#40;</span>args<span class="sy0">:</span> Array<span class="br0">&#91;</span>String<span class="br0">&#93;</span><span class="br0">&#41;</span><span class="sy0">:</span> Unit <span class="sy0">=</span> <span class="br0">&#123;</span>
    Logger.<span class="me1">getLogger</span><span class="br0">&#40;</span><span class="st0">&quot;org&quot;</span><span class="br0">&#41;</span>.<span class="me1">setLevel</span><span class="br0">&#40;</span>Level.<span class="me1">OFF</span><span class="br0">&#41;</span>
    Logger.<span class="me1">getLogger</span><span class="br0">&#40;</span><span class="st0">&quot;akka&quot;</span><span class="br0">&#41;</span>.<span class="me1">setLevel</span><span class="br0">&#40;</span>Level.<span class="me1">OFF</span><span class="br0">&#41;</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> spark <span class="sy0">=</span> SparkSession.<span class="me1">builder</span><span class="br0">&#40;</span><span class="br0">&#41;</span>.<span class="me1">master</span><span class="br0">&#40;</span><span class="st0">&quot;local[2]&quot;</span><span class="br0">&#41;</span>.<span class="me1">appName</span><span class="br0">&#40;</span><span class="st0">&quot;Lesson4_Exec04_Parse_Apache_Access_Log&quot;</span><span class="br0">&#41;</span>.<span class="me1">getOrCreate</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
&nbsp;
    <a href="http://scala-lang.org"><span class="kw1">import</span></a> spark.<span class="me1">implicits</span>.<span class="sy0">_</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> sparkConfig <span class="sy0">=</span> ConfigFactory.<span class="me1">load</span><span class="br0">&#40;</span><span class="st0">&quot;application.conf&quot;</span><span class="br0">&#41;</span>.<span class="me1">getConfig</span><span class="br0">&#40;</span><span class="st0">&quot;spark&quot;</span><span class="br0">&#41;</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> path <span class="sy0">=</span> sparkConfig.<span class="me1">getString</span><span class="br0">&#40;</span><span class="st0">&quot;sourceDataPath&quot;</span><span class="br0">&#41;</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> filePath <span class="sy0">=</span> s<span class="st0">&quot;${path}/spark_lessons/Lesson04_Spark_SQL/access.log.2&quot;</span>
    <span class="co1">// Read raw data</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> rawDf <span class="sy0">=</span> spark.<span class="me1">read</span>.<span class="me1">text</span><span class="br0">&#40;</span>filePath<span class="br0">&#41;</span>
&nbsp;
    rawDf.<span class="me1">cache</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
    rawDf.<span class="me1">show</span><span class="br0">&#40;</span><span class="nu0">5</span>, <a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span>
    rawDf.<span class="me1">count</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
&nbsp;
    <span class="co1">// split raw data into token list</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> splitDf <span class="sy0">=</span> rawDf.<span class="me1">select</span><span class="br0">&#40;</span>split<span class="br0">&#40;</span>col<span class="br0">&#40;</span><span class="st0">&quot;value&quot;</span><span class="br0">&#41;</span>, <span class="st0">&quot; &quot;</span><span class="br0">&#41;</span>.<span class="me1">as</span><span class="br0">&#40;</span><span class="st0">&quot;tokenList&quot;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
    splitDf.<span class="me1">show</span><span class="br0">&#40;</span><span class="nu0">5</span>, <a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span>
&nbsp;
    <span class="co1">// transform token list into dataframe</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> tokenizedDf <span class="sy0">=</span> splitDf.<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;host&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">0</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;rfc931&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">1</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;authuser&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">2</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;date&quot;</span>, concat<span class="br0">&#40;</span>$<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">3</span><span class="br0">&#41;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">4</span><span class="br0">&#41;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;request&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">6</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;status&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">8</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;bytes&quot;</span>, $<span class="st0">&quot;tokenList&quot;</span>.<span class="me1">getItem</span><span class="br0">&#40;</span><span class="nu0">9</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
      .<span class="me1">drop</span><span class="br0">&#40;</span><span class="st0">&quot;tokenList&quot;</span><span class="br0">&#41;</span>
&nbsp;
    tokenizedDf.<span class="me1">show</span><span class="br0">&#40;</span><span class="nu0">5</span>, <a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span>
&nbsp;
    tokenizedDf.<span class="me1">select</span><span class="br0">&#40;</span><span class="st0">&quot;status&quot;</span><span class="br0">&#41;</span>.<span class="me1">distinct</span><span class="br0">&#40;</span><span class="br0">&#41;</span>
&nbsp;
    <span class="coMULTI">/* The following request give us the top ten most visited page. We could noticed that the second most viewed item is not in the top 10 sell list */</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> mostViewedPage <span class="sy0">=</span> tokenizedDf.<span class="me1">filter</span><span class="br0">&#40;</span>$<span class="st0">&quot;request&quot;</span>.<span class="me1">contains</span><span class="br0">&#40;</span><span class="st0">&quot;product&quot;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>.<span class="me1">groupBy</span><span class="br0">&#40;</span>$<span class="st0">&quot;request&quot;</span><span class="br0">&#41;</span>.<span class="me1">count</span><span class="br0">&#40;</span><span class="br0">&#41;</span>.<span class="me1">orderBy</span><span class="br0">&#40;</span>$<span class="st0">&quot;count&quot;</span>.<span class="me1">desc</span><span class="br0">&#41;</span>
&nbsp;
    mostViewedPage.<span class="me1">show</span><span class="br0">&#40;</span><span class="nu0">10</span>, <a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span>
&nbsp;
    <span class="coMULTI">/* If we want to replace the 20% by space in the request, we can use the regexp_replace*/</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> betterView <span class="sy0">=</span> mostViewedPage.<span class="me1">select</span><span class="br0">&#40;</span>regexp<span class="sy0">_</span>replace<span class="br0">&#40;</span>$<span class="st0">&quot;request&quot;</span>, <span class="st0">&quot;%20&quot;</span>, <span class="st0">&quot; &quot;</span><span class="br0">&#41;</span>.<span class="me1">alias</span><span class="br0">&#40;</span><span class="st0">&quot;request&quot;</span><span class="br0">&#41;</span>, $<span class="st0">&quot;count&quot;</span><span class="br0">&#41;</span>
    betterView.<span class="me1">show</span><span class="br0">&#40;</span><span class="nu0">10</span>, <a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span>
&nbsp;
    <span class="coMULTI">/* refine data frame, only keep product name, and rename column name*/</span>
&nbsp;
    <span class="coMULTI">/*Here we use a interesting spark sql function substring_index to get the product name
    * substring_index(str, delim, count) : Returns the substring from str before count occurrences of the delimiter
    *          delim. If count is positive, everything to the left of the final delimiter (counting from the left) is
    *          returned. If count is negative, everything to the right of the final delimiter (counting from the right)
    *          is returned.
    *
    * For example, if we want to keep the head of the string(www), then we do the following
    * SELECT substring_index('www.apache.org', '.', 1);
    * If we want to keep the tail of the string(org), then we do the following
    * SELECT substring_index('www.apache.org', '.', -1);
    * */</span>
   <span class="coMULTI">/* After analysis, we found we have false data in access log, so we want to remove all lines which has &quot;add_to_cart&quot;
    * as product_name, we use filter() which takes boolean expression as argument, notice we can't use ! for negation
    * here, we need to use not()
    * */</span>
    <a href="http://scala-lang.org"><span class="kw1">val</span></a> productVisitNumber <span class="sy0">=</span> betterView
        .<span class="me1">withColumn</span><span class="br0">&#40;</span><span class="st0">&quot;product_name&quot;</span>,substring<span class="sy0">_</span>index<span class="br0">&#40;</span>col<span class="br0">&#40;</span><span class="st0">&quot;request&quot;</span><span class="br0">&#41;</span>,<span class="st0">&quot;/&quot;</span>,-<span class="nu0">1</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
        .<span class="me1">withColumnRenamed</span><span class="br0">&#40;</span><span class="st0">&quot;count&quot;</span>,<span class="st0">&quot;view_number&quot;</span><span class="br0">&#41;</span>
        .<span class="me1">drop</span><span class="br0">&#40;</span><span class="st0">&quot;request&quot;</span><span class="br0">&#41;</span>
        .<span class="me1">filter</span><span class="br0">&#40;</span>not<span class="br0">&#40;</span>$<span class="st0">&quot;product_name&quot;</span>.<span class="me1">contains</span><span class="br0">&#40;</span><span class="st0">&quot;add_to_cart&quot;</span><span class="br0">&#41;</span><span class="br0">&#41;</span><span class="br0">&#41;</span>
        .<span class="me1">select</span><span class="br0">&#40;</span><span class="st0">&quot;product_name&quot;</span>,<span class="st0">&quot;view_number&quot;</span><span class="br0">&#41;</span>
&nbsp;
    productVisitNumber.<span class="me1">show</span><span class="br0">&#40;</span><span class="nu0">10</span>,<a href="http://scala-lang.org"><span class="kw1">false</span></a><span class="br0">&#41;</span>
&nbsp;
  <span class="br0">&#125;</span>
&nbsp;
&nbsp;
<span class="br0">&#125;</span></pre>
</dd></dl>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;3.6 Full code for creating the product visit number dataframe&quot;,&quot;hid&quot;:&quot;full_code_for_creating_the_product_visit_number_dataframe&quot;,&quot;codeblockOffset&quot;:8,&quot;secid&quot;:9,&quot;range&quot;:&quot;8114-11773&quot;} -->
<h2 class="sectionedit10" id="join_with_the_product_revenu_to_find_the_anomaly">3.7 Join with the product_revenu to find the anomaly</h2>
<div class="level2">

<p>
Here we will reuse the table products_revenue which we created in Lesson1. Normally, there is a positive between product visit number and product revenue. If not, we could say there is an anomaly.
</p>
<pre class="code">select pn.product_name as product_name, pn.view_number as view_number, pr.revenue as revenue 
from product_visit_number pn 
left join products_revenue pr on pn.product_name=pr.product_name
order by pn.view_number desc;
</pre>

<p>
We can also save the result as a table
</p>
<pre class="code">CREATE TABLE retail_db.product_anomaly STORED AS ORC AS select pn.product_name as product_name, pn.view_number as view_number, pr.revenue as revenue 
from product_visit_number pn 
left join products_revenue pr on pn.product_name=pr.product_name
order by pn.view_number desc;</pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;3.7 Join with the product_revenu to find the anomaly&quot;,&quot;hid&quot;:&quot;join_with_the_product_revenu_to_find_the_anomaly&quot;,&quot;codeblockOffset&quot;:9,&quot;secid&quot;:10,&quot;range&quot;:&quot;11774-12603&quot;} -->
<h1 class="sectionedit11" id="common_problems">Common problems</h1>
<div class="level1">

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Common problems&quot;,&quot;hid&quot;:&quot;common_problems&quot;,&quot;codeblockOffset&quot;:11,&quot;secid&quot;:11,&quot;range&quot;:&quot;12604-12634&quot;} -->
<h2 class="sectionedit12" id="file_format_does_not_match_when_load_data_into_hive_table">1.File format does not match when load data into hive table</h2>
<div class="level2">

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;1.File format does not match when load data into hive table&quot;,&quot;hid&quot;:&quot;file_format_does_not_match_when_load_data_into_hive_table&quot;,&quot;codeblockOffset&quot;:11,&quot;secid&quot;:12,&quot;range&quot;:&quot;12635-12707&quot;} -->
<h3 class="sectionedit13" id="symptom">Symptom</h3>
<div class="level3">

<p>
After creating a table, a user imports data to the table by running the Load command but encounters the following error:
</p>
<pre class="code">.......
&gt; LOAD DATA INPATH &#039;/user/tester1/hive-data/data.txt&#039; INTO TABLE employees_info;
Error: Error while compiling statement: FAILED: SemanticException Unable to load data to destination table. Error: The file that you are trying to load does not match the file format of the destination table. (state=42000,code=40000)
..........</pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Symptom&quot;,&quot;hid&quot;:&quot;symptom&quot;,&quot;codeblockOffset&quot;:11,&quot;secid&quot;:13,&quot;range&quot;:&quot;12708-13197&quot;} -->
<h3 class="sectionedit14" id="fault_locating">Fault locating</h3>
<div class="level3">
<ol>
<li class="level1"><div class="li"> The customer has not specified the storage format of data when creating the table. The default format for the hive table is RCFile.</div>
</li>
<li class="level1"><div class="li"> However, the loaded data is in TEXTFILE format.</div>
</li>
</ol>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Fault locating&quot;,&quot;hid&quot;:&quot;fault_locating&quot;,&quot;codeblockOffset&quot;:12,&quot;secid&quot;:14,&quot;range&quot;:&quot;13198-13412&quot;} -->
<h3 class="sectionedit15" id="solution">Solution</h3>
<div class="level3">

<p>
Two solutions are available and they both focus on the format consistency between data stored and data imported.
</p>

<p>
Method 1:
</p>

<p>
Specify the storage format at the time of table creation with <strong>STORED AS TEXTFILE</strong>. This allows data in the TEXTFILE format to be imported.
</p>

<p>
Method 2:
</p>

<p>
Import data in RCFile format.
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Solution&quot;,&quot;hid&quot;:&quot;solution&quot;,&quot;codeblockOffset&quot;:12,&quot;secid&quot;:15,&quot;range&quot;:&quot;13413-&quot;} -->