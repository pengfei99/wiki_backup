a:57:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:33:"Lesson1: Handling structured data";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1;}i:4;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:186:"In this Lesson, we will use sqoop to extract a database which is stored in a mysql server. Sqoop will inject this database into hive data warehouse. Then we will do some simple analysis.";}i:2;i:50;}i:5;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:236;}i:6;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:239;}i:7;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:32:"1. Connect to the mysql database";i:1;i:2;i:2;i:239;}i:2;i:239;}i:8;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:239;}i:9;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:203:"
# View database (retail_db) in the mysql database (pwd:hadoop)
mysql -u root -p retail_db

# check database tables 
show tables;

# show 10 distinct customers
select distinct * from customers limit 10;
";i:1;N;i:2;N;}i:2;i:290;}i:10;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:503;}i:11;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:31:"2. Use sqoop to import database";i:1;i:2;i:2;i:503;}i:2;i:503;}i:12;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:503;}i:13;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:503;}i:14;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:53:"For more information about sqoop on import data, see ";}i:2;i:548;}i:15;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:51:"employes:pengfei.liu:data_science:sqoop:import_data";i:1;s:25:"Sqoop import data from DB";}i:2;i:601;}i:16;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:682;}i:17;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:584:"
# 1. view the data in mysql server

# 2. create db in hive
$ create database retail_db

# 3. import data via sqoop
$ sqoop import-all-tables --connect jdbc:mysql://127.0.0.1:3306/retail_db --username=root -P --compression-codec=snappy --hive-overwrite --hive-import --hive-database retail_db 

# In our case, we can't use --direct, becasue mysqldump is not installed on the server. Note that with different DB, the --direct means different things. In mysql/mariadb, postgres, it means use mysqldump/pgdump to bypass jdbc. In oracle

# 4. login to beeline and view the imported data

";i:1;N;i:2;N;}i:2;i:690;}i:18;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1284;}i:19;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:27:"3. Use hive to analyse data";i:1;i:2;i:2;i:1284;}i:2;i:1284;}i:20;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:1284;}i:21;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:862:"
# 1. Top ten best seller
select c.category_name as category_name, count(order_item_quantity) as product_number
from order_items oi
inner join products p on oi.order_item_product_id = p.product_id
inner join categories c on c.category_id = p.product_category_id
group by c.category_name
order by product_number desc
limit 10;

# 2. top 10 revenue generating products, if you want more precision, you can change int to float
select p.product_name as product_name, r.revenue as revenue
from products p inner join
(select oi.order_item_product_id, sum(cast(oi.order_item_subtotal as int)) as revenue
from order_items oi inner join orders o
on oi.order_item_order_id = o.order_id
where o.order_status <> 'CANCELED'
and o.order_status <> 'SUSPECTED_FRAUD'
group by order_item_product_id) r
on p.product_id = r.order_item_product_id
order by r.revenue desc
limit 10;

";i:1;N;i:2;N;}i:2;i:1330;}i:22;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2202;}i:23;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:22:"4. Save result to hive";i:1;i:2;i:2;i:2202;}i:2;i:2202;}i:24;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:2202;}i:25;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:928:"
# save the best seller result to a new table
CREATE TABLE retail_db.best_seller STORED AS ORC AS select c.category_name as category_name, count(order_item_quantity) as product_number
from order_items oi
inner join products p on oi.order_item_product_id = p.product_id
inner join categories c on c.category_id = p.product_category_id
group by c.category_name
order by product_number desc;

# save the revenue value generated by each products
CREATE TABLE retail_db.products_revenue STORED AS ORC AS select p.product_name as product_name, r.revenue as revenue
from products p inner join
(select oi.order_item_product_id, sum(cast(oi.order_item_subtotal as float)) as revenue
from order_items oi inner join orders o
on oi.order_item_order_id = o.order_id
where o.order_status <> 'CANCELED'
and o.order_status <> 'SUSPECTED_FRAUD'
group by order_item_product_id) r
on p.product_id = r.order_item_product_id
order by r.revenue desc
";i:1;N;i:2;N;}i:2;i:2244;}i:26;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:3183;}i:27;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:15:"Common problems";i:1;i:2;i:2;i:3183;}i:2;i:3183;}i:28;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:3183;}i:29;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:3212;}i:30;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:69:"1. Transactional tables with Parquet format are not supported by Hive";i:1;i:3;i:2;i:3212;}i:2;i:3212;}i:31;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:3212;}i:32;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3212;}i:33;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:173:"In HDP 3, managed Hive tables must be transactional (hive.strict.managed.tables=true). Transactional tables with Parquet format are not supported by Hive. Hive imports with ";}i:2;i:3293;}i:34;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"--";}i:2;i:3466;}i:35;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:54:"as-parquetfile must use external tables by specifying ";}i:2;i:3468;}i:36;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"--";}i:2;i:3522;}i:37;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:19:"external-table-dir.";}i:2;i:3524;}i:38;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3543;}i:39;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3543;}i:40;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"Associated error message";}i:2;i:3545;}i:41;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3569;}i:42;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3569;}i:43;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:151:"Table db.table failed strict managed table checks due to the
following reason: Table is marked as a managed table but is not
transactional. 
Workaround";}i:2;i:3571;}i:44;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3722;}i:45;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3722;}i:46;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"When using ";}i:2;i:3724;}i:47;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"--";}i:2;i:3735;}i:48;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:17:"hive-import with ";}i:2;i:3737;}i:49;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"--";}i:2;i:3754;}i:50;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:40:"as-parquetfile, users must also provide ";}i:2;i:3756;}i:51;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:2:"--";}i:2;i:3796;}i:52;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:64:"external-table-dir with a fully qualified location of the table:";}i:2;i:3798;}i:53;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3868;}i:54;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:127:"
sqoop import ... --hive-import
                 --as-parquetfile 
                 --external-table-dir hdfs:///path/to/table
";i:1;N;i:2;N;}i:2;i:3868;}i:55;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4004;}i:56;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:4004;}}