a:55:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:13:"Spark dataset";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1;}i:4;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:25:"The Apache Spark Dataset ";}i:2;i:30;}i:5;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:55;}i:6;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:62:" provides a type-safe, object-oriented programming interface. ";}i:2;i:58;}i:7;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:120;}i:8;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:120;}i:9;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:22:"In Spark 2.0, Dataset ";}i:2;i:122;}i:10;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:144;}i:11;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:15:" and DataFrame ";}i:2;i:147;}i:12;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:162;}i:13;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:84:" are unified. In Scala, DataFrame becomes a type alias for Dataset[Row], while Java ";}i:2;i:165;}i:14;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:249;}i:15;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:964:" users must replace DataFrame with Dataset<Row>. Both the typed transformations (e.g., map, filter, and groupByKey) and untyped transformations (e.g., select and groupBy) are available on the Dataset class. Since compile-time type-safety in Python and R is not a language feature, the concept of Dataset does not apply to these languages’ APIs. Instead, DataFrame remains the primary programming abstraction, which is analogous to the single-node data frame notion in these languages. Like DataFrames, Datasets take advantage of Spark’s Catalyst optimizer by exposing expressions and data fields to a query planner. Beyond Catalyst’s optimizer, Datasets also leverage Tungsten’s fast in-memory encoding. They extend these benefits with compile-time type safetymeaning production applications can be checked for errors before they are ranand they also allow direct operations over user-defined classes, as you will see in a couple of simple examples below. ";}i:2;i:252;}i:16;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1216;}i:17;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1216;}i:18;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:58:"The dataset and dataFrame api have the following changes :";}i:2;i:1218;}i:19;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1276;}i:20;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:1276;}i:21;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1276;}i:22;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1276;}i:23;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:23:" Dataset and DataFrame ";}i:2;i:1280;}i:24;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:1303;}i:25;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:51:" unionAll has been deprecated and replaced by union";}i:2;i:1306;}i:26;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1357;}i:27;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1357;}i:28;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1357;}i:29;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1357;}i:30;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:23:" Dataset and DataFrame ";}i:2;i:1361;}i:31;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:1384;}i:32;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:91:" explode has been deprecated, alternatively, use functions.explode() with select or flatMap";}i:2;i:1387;}i:33;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1478;}i:34;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1478;}i:35;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1478;}i:36;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1478;}i:37;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:23:" Dataset and DataFrame ";}i:2;i:1482;}i:38;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:1505;}i:39;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:78:" registerTempTable has been deprecated and replaced by createOrReplaceTempView";}i:2;i:1508;}i:40;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1586;}i:41;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1586;}i:42;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:1586;}i:43;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1586;}i:44;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"Lastly, the Dataset ";}i:2;i:1589;}i:45;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:1609;}i:46;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:162:" offers a high-level domain specific language operations like sum(), avg(), join(), select(), groupBy(), making the code a lot easier to express, read, and write.";}i:2;i:1612;}i:47;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1774;}i:48;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1774;}i:49;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:215:"In this section, you will learn two ways to create Datasets: dynamically creating a data and reading from JSON file using Spark Session. Additionally, through simple and short examples, you will learn about Dataset ";}i:2;i:1776;}i:50;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"API";}i:2;i:1991;}i:51;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:123:" operations on the Dataset, issue SQL queries and visualize data. For learning purposes, we use a small IoT Device dataset.";}i:2;i:1994;}i:52;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2117;}i:53;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2120;}i:54;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:2120;}}