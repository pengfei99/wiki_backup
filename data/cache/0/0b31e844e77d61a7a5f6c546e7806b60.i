a:90:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:17:"Linear regression";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:34;}i:4;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:25:"What is linear regression";i:1;i:2;i:2;i:34;}i:2;i:34;}i:5;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:34;}i:6;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:34;}i:7;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:567:"Linear regression is a basic and commonly used type of predictive analysis.  The overall idea of regression is to examine two things: (1) does a set of predictor variables do a good job in predicting an outcome (dependent) variable?  (2) Which variables in particular are significant predictors of the outcome variable, and in what way do they indicated by the magnitude and sign of the beta estimates impact the outcome variable?  These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables.  ";}i:2;i:73;}i:8;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:640;}i:9;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:644;}i:10;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:32:"What is simple linear regression";i:1;i:3;i:2;i:644;}i:2;i:644;}i:11;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:644;}i:12;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:644;}i:13;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:149:"Simple linear regression is a statistical method that allows us to summarize and study relationships between two continuous (quantitative) variables:";}i:2;i:688;}i:14;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:837;}i:15;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:837;}i:16;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:66:"It can be defined by the formula y = c + b*x, where y = estimated ";}i:2;i:839;}i:17;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:905;}i:18;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:18:"dependent variable";}i:2;i:907;}i:19;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:925;}i:20;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:71:" score, c = constant, b = regression coefficient, and x = score on the ";}i:2;i:927;}i:21;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:998;}i:22;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"independent variable";}i:2;i:1000;}i:23;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:1020;}i:24;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:". ";}i:2;i:1022;}i:25;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1024;}i:26;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1024;}i:27;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:197:"We often call x as the predictor, explanatory, or independent variable. And y as the response, outcome, or dependent variable. Because the other terms are used less frequently today, we'll use the ";}i:2;i:1026;}i:28;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:1223;}i:29;a:3:{i:0;s:18:"doublequoteopening";i:1;a:0:{}i:2;i:1225;}i:30;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:9:"predictor";}i:2;i:1226;}i:31;a:3:{i:0;s:18:"doublequoteclosing";i:1;a:0:{}i:2;i:1235;}i:32;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:1236;}i:33;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:5:" and ";}i:2;i:1238;}i:34;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:1243;}i:35;a:3:{i:0;s:18:"doublequoteopening";i:1;a:0:{}i:2;i:1245;}i:36;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"response";}i:2;i:1246;}i:37;a:3:{i:0;s:18:"doublequoteclosing";i:1;a:0:{}i:2;i:1254;}i:38;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:1255;}i:39;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:61:" terms to refer to the variables encountered in this Lesson. ";}i:2;i:1257;}i:40;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1318;}i:41;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1318;}i:42;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:44:"Simple linear regression gets its adjective ";}i:2;i:1320;}i:43;a:3:{i:0;s:18:"doublequoteopening";i:1;a:0:{}i:2;i:1364;}i:44;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"simple,";}i:2;i:1365;}i:45;a:3:{i:0;s:18:"doublequoteclosing";i:1;a:0:{}i:2;i:1372;}i:46;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:160:" because it concerns the study of only one predictor variable. In contrast, multiple linear regression, which we study later in this course, gets its adjective ";}i:2;i:1373;}i:47;a:3:{i:0;s:18:"doublequoteopening";i:1;a:0:{}i:2;i:1533;}i:48;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:9:"multiple,";}i:2;i:1534;}i:49;a:3:{i:0;s:18:"doublequoteclosing";i:1;a:0:{}i:2;i:1543;}i:50;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:66:" because it concerns the study of two or more predictor variables.";}i:2;i:1544;}i:51;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1610;}i:52;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1612;}i:53;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:22:"Types of relationships";i:1;i:3;i:2;i:1612;}i:2;i:1612;}i:54;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:1612;}i:55;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1612;}i:56;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:44:"We can divide relationships types into two :";}i:2;i:1646;}i:57;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1690;}i:58;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:1690;}i:59;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1690;}i:60;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1690;}i:61;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:46:" Deterministic (or functional) relationships. ";}i:2;i:1694;}i:62;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1740;}i:63;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1740;}i:64;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1740;}i:65;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1740;}i:66;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:27:" Statistical relationships.";}i:2;i:1744;}i:67;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1771;}i:68;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1771;}i:69;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:1771;}i:70;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1771;}i:71;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:93:"If the value of y can be exactly calculated by c+b*x, we say the relation between x and y is ";}i:2;i:1773;}i:72;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:1866;}i:73;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:"deterministic";}i:2;i:1868;}i:74;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:1881;}i:75;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:257:". In a graph, the (x, y) data points fall directly on a line.For example, the relationship between degrees Fahrenheit and degrees Celsius is known to be: Fahr = 9/5*Cels+32. As a result, we can determine the exact value of Fahr, if I have the value of Cels.";}i:2;i:1883;}i:76;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2140;}i:77;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2140;}i:78;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:302:"If the value of y can't be calculated perfectly, we say the relation is statistical. For example, the height and weight of a man, as height increases, you'd expect weight to increase, but not perfectly. In a graph, the (x, y) data points will never fall on a line, they will be around the line y=c+b*x.";}i:2;i:2142;}i:79;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2444;}i:80;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2446;}i:81;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:28:"The best model(fitting line)";i:1;i:3;i:2;i:2446;}i:2;i:2446;}i:82;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:2446;}i:83;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2446;}i:84;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:161:"As in the simple linear regression, there are only two variables, so the regression model can be represented as a single line. By giving a set of variable x1,x2,";}i:2;i:2486;}i:85;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:3:"...";}i:2;i:2647;}i:86;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:243:", if the model can output y_predicted and the difference between y_predicted and y_real (we could call this value as mean absolute error) is smallest compare to other model(line). We could say this model is the best model or best fitting line.";}i:2;i:2650;}i:87;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2893;}i:88;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2908;}i:89;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:2908;}}