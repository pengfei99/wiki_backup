====== Install Apache Zeppelin on Centos 7 ======

===== What is Zeppelin =====

Apache Zeppelin is a web-based open source notebook and collaborative tool for interactive data ingestion, discovery, analytics, and visualization. Zeppelin supports 20+ languages including Apache Spark, SQL, R, Elasticsearch and many more. Apache Zeppelin allows you to create beautiful data-driven documents and see the results of your analytics.


===== Before install Zeppelin=====

  - Install jdk: Zeppelin is written in Java, so it requires JDK
  - Set JAVA_HOME and JRE_HOME 
  - check java with java -version and echo $JAVA_HOME.

===== Install Zeppelin =====

Get the latest Zeppelin from their site (https://zeppelin.apache.org/download.html).

In our example, we use the Zeppelin-0.7.3. I didn't create user zeppelin, I use user hadoop to run the zepplin daemon

The following command download unzip, then put zeppelin under /opt/zeppelin

<code>
sudo mkdir -p /opt/zeppelin/
cd /opt/zeppelin
wget <download-url>
tar -xzvf zeppelin-0.7.3-bin-all.tgz
mv zeppelin-0.7.3-bin-all zeppelin-0.7.3
chown -R hadoop:hadoop zeppelin-0.7.3

# after the above command, you should see the below info
[hadoop@CCLinDataWHD01 zeppelin-0.7.3]$ pwd
/opt/zeppelin/zeppelin-0.7.3

[hadoop@CCLinDataWHD01 zeppelin-0.7.3]$ ls
bin   interpreter  LICENSE   local-repo  notebook  README.md  zeppelin-web-0.7.3.war
conf  lib          licenses  logs        NOTICE    run

</code>



===== Configure systemd service =====

Create a new systemd service unit file

Then put the following lines in it.

<code>
[Unit]
Description=Zeppelin service
After=syslog.target network.target

[Service]
Type=forking
ExecStart=/opt/zeppelin/zeppelin-0.7.3/bin/zeppelin-daemon.sh start
ExecStop=/opt/zeppelin/zeppelin-0.7.3/bin/zeppelin-daemon.sh stop
ExecReload=/opt/zeppelin/zeppelin-0.7.3/bin/zeppelin-daemon.sh reload
User=hadoop
Group=hadoop
Restart=always

[Install]
WantedBy=multi-user.target
</code>

===== Configure zepplin spark interpreter =====

They are four mode for zepplin spark interpreter master configuration.

<code>
  * local[*] in local mode
  * spark://master:7077 in standalone cluster
  * yarn-client in Yarn client mode
  * mesos://host:5050 in Mesos cluster
</code>
==== Local mode ====

If you run your zeppelin on your local pc and you don't have a spark cluster in place. It's better you use the local mode. Zeppelin has embedded spark which will be used in this mode.

==== standalone spark cluster ====

If you have a spark cluster in place, and this cluster does not use yarn or mesos as resource manager. Then we call your spark cluster as a standalone spark cluster.

In your spark config spark-defaults.conf, you should find a line like this 
<code>
spark.master spark://hadoop-nn.bioaster.org:7077
</code>

==== spark yarn cluster  ====
If you have a spark cluster, and it uses yarn as resource manager. We cloud say you have a spark yarn cluster

In your spark config spark-defaults.conf, you should find a line like this **spark.master yarn**

==== spark mesos cluster ====
If you have a spark cluster, and it uses mesos as resource manager. We could say you have a spark mesos cluster.

In your spark config spark-defaults.conf, you should find a line like this
<code>
 spark.master  mesos://host:5050.  
# The mesos://host:5050 is the mesos master location.
</code>

In our example, we use spark standalone cluster.

To configure it, we need to do the following

<code>
cd /opt/zeppelin/zeppelin-0.7.3/conf
cp zeppelin-env.sh.template zeppelin-env.sh

vim zeppelin-env.sh
# add the following lines
# define java home
export JAVA_HOME=/opt/JAVA/jdk1.8.0_151
# define spark master location for the interpreter
export MASTER=spark://hadoop-nn.bioaster.org:7077
# define spark_home to avoid using zeppelin embedded spark
export SPARK_HOME=/opt/spark/spark-2.2.0
</code>

The above is the minimun setting to run spark standalone cluster via zeppelin. There are many options you can configure inside to tune the zeppelin performance. 


===== Disable Anonymous Access =====

The other important configuration file is zeppelin-site.xml
<code>
# if it doesnot exist yet
cp conf/zeppelin-site.xml.template conf/zeppelin-site.xml

# find the line in zeppelin-site.xml
<property>
  <name>zeppelin.anonymous.allowed</name>
  <value>true</value>
  <description>Anonymous user allowed by default</description>
</property>

# change the value from true to false
</code>

Then your have many choice, you can use a ldap or a local file to do the authentication

In this example, I will only show the local file authentication

Shiro Authentication, The complete doc is here https://shiro.apache.org/authorization.html
<code>
cp conf/shiro.ini.template conf/shiro.ini

vim shiro.ini

# modifier the user login and password line
[users]

admin = password1, admin
user1 = password2, role1, role2
user2 = password3, role3
user3 = password4, role2

</code>

user1 is the login, password2 is the password. The password can be plain text or a hash.
Shiro provides a password generator to generate the hash. You can get the tool from maven repo. Note it has many problems, so it may not work

<file xml shiro.xml>
 <dependency>
      <groupId>org.apache.shiro.tools</groupId>
      <artifactId>shiro-tools-hasher</artifactId>
      <classifier>cli</classifier>
      <version>1.4.1</version>
    </dependency>
</file>

You can also use directly the mvn cli

<code>
$ mvn dependency:get -DgroupId=org.apache.shiro.tools -DartifactId=shiro-tools-hasher -Dclassifier=cli -Dversion=X.X.X

# After this, you should get the jar file in ~/.m2/repository/org/apache/shiro/tools/shiro-tools-hasher/X.X.X/shiro-tools-hasher-X.X.X-cli.jar

# To generate the password hash
java -jar shiro-tools-hasher-X.X.X-cli.jar -p
</code>

For more info on pwd generation, go check https://shiro.apache.org/command-line-hasher.html


You can also use ldap for authentications, below is an example of ldap configuration in shiro.ini

<code>
### A sample for configuring LDAP Directory Realm
ldapRealm = org.apache.zeppelin.realm.LdapGroupRealm
## search base for ldap groups (only relevant for LdapGroupRealm):
ldapRealm.contextFactory.environment[ldap.searchBase] = dc=bioaster,dc=org
ldapRealm.contextFactory.url = ldap://10.70.3.118:389
ldapRealm.userDnTemplate = uid={0},ou=Users,dc=bioaster,dc=org
ldapRealm.contextFactory.authenticationMechanism = simple


# tell shiro to use ldapRealm
securityManager.realms = $ldapRealm

sessionManager = org.apache.shiro.web.session.mgt.DefaultWebSessionManager

### If caching of user is required then uncomment below lines
cacheManager = org.apache.shiro.cache.MemoryConstrainedCacheManager
securityManager.cacheManager = $cacheManager

securityManager.sessionManager = $sessionManager
# 86,400,000 milliseconds = 24 hour
securityManager.sessionManager.globalSessionTimeout = 86400000
shiro.loginUrl = /api/login

# comment anon to 
#/** = anon
/** = authc
</code>
===== Run Zeppelin =====

If you did not set up the systemd service unit as I showed above, you can start the daemon directly.

<code>
# we suppose the zeppelin installation path is /opt/zeppelin/zeppelin-0.7.3
sh /opt/zeppelin/zeppelin-0.7.3/bin/zeppelin-daemon.sh start
sh /opt/zeppelin/zeppelin-0.7.3/bin/zeppelin-daemon.sh stop
sh /opt/zeppelin/zeppelin-0.7.3/bin/zeppelin-daemon.sh reload
</code>

By default zeppelin runs on a jetty web server. 
You can access zeppelin via a web browser, for example if the server is located at 10.70.3.48 and zeppeling runs on port 8888. Enter http://10.70.3.48:8888/#/ in your browser. You should see a welcome page of zeppelin

The zeppelin port is defined at {zeppelin-path}/conf/zeppelin-site.xml

<code>
<property>
  <name>zeppelin.server.port</name>
  <value>8888</value>
  <description>Server port.</description>
</property>

</code>




===== Official doc =====

https://zeppelin.apache.org/docs/0.5.0-incubating/install/install.html

===== Trouble Shoot =====

==== Q1 NullPointerException on spark context ====

Getting NullPointerException when running Spark Code in Zeppelin 0.7.1

Cause of this error
<code>
Root Cause is : Spark trying to setup Hive context, but hdfs services is not running, that's why HiveContext become null and throwing null pointer exception.
</code>

Solution
<code>
1. Setup Saprk Home [optional] and HDFS.
2. Run HDFS service
3. Restart zeppelin server
OR
1. Go to Zeppelin's Interpreter settings.
2. Select Spark Interpreter
3. zeppelin.spark.useHiveContext = false // I tested this, it works
</code>