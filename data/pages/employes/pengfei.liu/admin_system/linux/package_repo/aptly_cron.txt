====== Aptly release cron job ======

This cron job is designed to publish aptly snapshots automatically

<file bash aptly_build_release.bash>
#!/bin/bash

# if we put this script in cron.weekly, this script will be executed with root privilege. And the aptly db data is user specific.
# So run as root can not get the information about the mirror and snapshoot. So for the aptly command, we need to use sudo -u aptly
# to run the command as user `aptly`.
# script config
uid=aptly
dist_name=bullseye
root_path=/pathToYourAptlyRoot/.aptly
log_file_path="${root_path}/log/aptly_log.out"
gpg_pwd_file_path="${root_path}/creds/pwd"
repo_path="${root_path}/public"
export_repo_path="${root_path}/export"

# don't modify below variables
release_date="$(date '+%Y%m%d')"
snapshot_merge_list=()

# Saves file descriptors so they can be restored to whatever they were before 
#redirection or used themselves to output to whatever they were before the following redirect.
exec 3>&1 4>&2
# Restore file descriptors for particular signals. Not generally necessary since they 
# should be restored when the sub-shell exits.
trap 'exec 2>&4 1>&3' 0 1 2 3
# Redirect stdout to file log.out then redirect stderr to stdout. Note that the order is 
# important when you want them going to the same file. stdout must be redirected 
# before stderr is redirected to stdout.
exec 1>"${log_file_path}" 2>&1
# Everything below will go to the file 'aptly_log.out':

# clean the old graph
rm "${repo_path}/package_build_history_*.png"

# read the gpg private key password from a file
gpg_pwd=$(<"${gpg_pwd_file_path}")

# update all existing mirror
sudo -u $uid aptly mirror list --raw | xargs -n1 sudo -u $uid aptly mirror update


# create a list of mirror
REPOS=$(aptly mirror list --raw | cut -d '#' -f1 | sort | uniq | xargs)

# loop through the mirror list, create new snapshot for each mirror
# build a snapshot merge list
for REPO in $REPOS; do
    sudo -u $uid aptly snapshot create "${REPO}-${release_date}" from mirror "${REPO}"
    snapshot_merge_list+=("${REPO}-${release_date}")
done

echo "${snapshot_merge_list}"


# merge the snapshot
sudo -u $uid aptly snapshot merge -latest "${dist_name}-stable-${release_date}" "${snapshot_merge_list[@]}"

# publish the new release
# when there is already a release in use, you need to add switch to replace the old release
# we need to put -batch=true when run this script in cron, otherwise, aptly and gpg will use the same /dev/tty. And this will cause 
# the -passphrase option fail, and a promt will show up. 
sudo -u $uid aptly publish switch -batch=true -passphrase="${gpg_pwd}" "${dist_name}" "${dist_name}-stable-${release_date}"

# generate the build graph
sudo -u $uid aptly graph -output="${repo_path}/package_build_history_${release_date}.png" -format="png"

# if you don't need the old release anymore, you can drop them
sudo -u $uid aptly db cleanup

# zip the release and put it to the export repo
zip -r "${export_repo_path}/${dist_name}-${release_date}.zip" "${repo_path}"
</file>

===== Script configuration =====

The first section of this script is the configuration. 

  * **uid**: The uid of the user which you want to run the aptly script
  * **dist_name**: The name of the Debian distribution which you want to publish
  * **root_path**: The root folder path of the aptly app. This path will be different if you follow an other installation guide. If you follow my guide. It should be located at `~/.aptly`. By default, it should contain three folders `db`, `pool` and `public`. To make the corn script work, you must create three new folders(i.e. `log`, `creds`, and `public`) under the root_path.
  * **log_file_path**: The path of the log file of the cron job
  *  **gpg_pwd_file_path**: The path of the file which contains the password of the GPG private key
  * **repo_path**: This folder will host the source of the deb package, and it will be used by the webserver to publish the package
  * **export_repo_path**: This folder contains the zip file of all the publish deb packages. Each zip file can be used as an export of a release.  

The aptly root path folder should have the following shape:

<code>

.aptly/
├── creds
├── db
├── export
├── log
├── pool
└── public

</code>  

  * In **creds** folder, it contains the passphrase of the GPG private key. This key is used to sign all the packages that are published by you. The default file name is `pwd`. If you change the file name, you need to change the config too in the cron script.
  * In **db** folder, it contains the database of the aptly which stores the state of the aptly (e.g. mirror list, snapshot list, published package list, etc.)
  * In **export** folder, it contains a zip file of all published packages. This zip file can be copied and deployed on another web server. The web server can act as a deb repo afterward.
  *  In **log** folder, it contains a log file of the cron script execution
  * In **pool** folder, it contains all the packages of the available mirrors
  * In **public** folder, it contains all the publish packages of the current deb repo.
  

===== Update the script =====

By default, the script will consider all mirrors available in the aptly, update it, create a snapshot, build a merge of all snapshots and publish the merged snapshot.

If you want to add a new mirror and enable the mirror update via the corn job,  you only need to create a mirror and update the mirror. **You don't need to modify the above script**

For example, we want to add two more mirror:
  - containerD: 
  - k8s


==== Create Mirror for k8s ====

<code bash>
# add gpg key of k8s repo as trusted key
gpg --no-default-keyring --keyring trustedkeys.gpg --keyserver keyserver.ubuntu.com --recv-keys B53DC80D13EDEF05

# create mirror
aptly mirror create -architectures=amd64 k8s-main  http://apt.kubernetes.io/ kubernetes-xenial main

# update mirror
aptly mirror update k8s-main
</code>

==== Create Mirror for docker ====

<code bash>
# add public key of the docker repo as trusted key
wget -qO- http://deb.casd.local/casd_gpg_key.asc | sudo tee /etc/apt/trusted.gpg.d/casd_gpg_key.asc
</code>




===== Improve the script =====

The snapshot will not be cleaned automatically. As a result, every week we will have at least 4 more snapshot in the db. So we need to clean them at a point to make the db clean. Two solution is possible:

  * Add a task in the current cron job, and clean the old snapshots after publishing a new snapshot. Pros: The aptly db only contains currently published snapshots, so db is very clean. Cons: All history snapshots are removed. So unable to rollback in case of  problems.
  * Create a new cronjob that cleans the snapshot. Pros: Can have a different run policy. So we can run it monthly, and we keep 4 weekly snapshots for rollback when needed.

<file bash clean_snapshot.bash>
# script config, you can change the days to set the snapshot interval
days=30
uid=coder
log_file_path=/home/coder/.aptly/log/aptly_snapshot_clean_log.out

day_in_sec=86400
interval=$((days * day_in_sec))

# setup log 

exec 3>&1 4>&2
trap 'exec 2>&4 1>&3' 0 1 2 3
# By default, the log will be appended to the log file. If you only want to keep the log
# of the last run, replace >> by >
exec 1>>"${log_file_path}" 2>&1

# get the list of the snapshot
SNAP_SHOTS=$(sudo -u $uid aptly snapshot list --raw | cut -d '#' -f1 | sort | uniq | xargs)

# for each snapshot check if it is older than the given day or not. If yes, then delete
for SNAP in $SNAP_SHOTS; do
   echo $SNAP
   # delete the longest match of pattern "-" from the beginning
   release_date=${SNAP##*-}
   # convert the string date to the numeric timestamp, here we choose %s (seconde) as prcision. 
   # It can be %m (month), %d (day)
   # current date timestamp
   cd_timestamp=$(date --date "$date" +'%s')
   # release date timestamp
   rd_timestamp=$(date --date "$release_date" +'%s')
   # get the expected timestamp
   expected_timestamp=$((cd_timestamp - interval))
   # compare it
   if [ $rd_timestamp -lt $expected_timestamp ]
   then
      echo "INFO: snapshot $SNAP is older than $days days" >&2
      sudo -u $uid aptly snapshot drop -force $SNAP
   fi
done
</file>