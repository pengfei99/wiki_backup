====== 08: K8s services ======

Service is an abstract way to **expose an application running on a set of Pods as a network service** (Micro-service).

Each Pod gets its own IP address, however, the Deployment does not provide a way to provide the service of these pods. For example, if I have two deployments one called backend and one called frontend. They both have multiple pods. How frontend knows which backend pod to use through the backend deployment. 

So we need another abstraction of the backend pod to provide service.

If you're able to use Kubernetes APIs for service discovery in your application, you can query the API server for **Endpoints**, that get updated whenever the set of Pods in a Service changes.

<code>
kubectl get endpoints -n user-pengfei
</code>


===== 8.1 Defining a service =====
First we create a simple deployment which runs a static web site on port 80
<file yaml deployment.yaml>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: static-web
spec:
  replicas: 3
  selector:
    matchLabels:
      app: static-web
  template:
    metadata:
      labels:
        app: static-web
    spec:
      containers:
        - name: static-site
          image: dockersamples/static-site
          imagePullPolicy: IfNotPresent
          # note if the image only listens to port 80, and you set other port below, the container will not work
          ports:
            - name: http
              containerPort: 80
</file>

Then we create a service which links to the deployment
<file yaml service.yaml>
apiVersion: v1
kind: Service
# service name
metadata:
  name: static-web-service
spec:
# The type indicates how the ip address will be generated and handled. We will give more details in the next section
  type: ClusterIP
# service selector will link targets pod to this service
# In this example, all pods with label app=static-web will be linked to this service
  selector:
    app: static-web
# ports specify how service port will match to pod's port
# In this example, the service listens to port 80, and forward the query to the endpoint's port 80
# by using tcp protocol.
  ports:
    # The default protocol is TCP, and UDP, SCTP is also supported
    - protocol: TCP
      port: 80
      targetPort: 80
</file>

Kubernetes assigns this Service an IP address based on the service type(default value is the "ClusterIP"), which is used by the Service proxies (see Virtual IPs and service proxies in below section).

An **Endpoint** is created by the service selector too. You can get the details of endpoint with the following command

<code>
$ kubectl get ep
# The endpoint contains the ip and ports of all pods which matche the service selector
static-web-service                    10.233.103.25:80,10.233.118.225:80,10.233.121.122:80          50m
</code> 

The controller for the Service selector continuously scans for Pods that match its selector, and then POSTs any updates to an Endpoint object. It means if a pod died, the related ip will be removed from the endpoint. If a new pod matches the selector, then its ip will be added to the endpoint.

===== 8.2 Services without selectors =====

Services most commonly abstract access to Kubernetes Pods, but they can also abstract other kinds of backends. For example:

  * You want to have an external database cluster in production, but in your test environment, you use your own databases.
  * You want to point your Service to a Service in a different Namespace or on another cluster.
  * You are migrating a workload to Kubernetes. While evaluating the approach, you run only a proportion of your backends in Kubernetes.

For example, you have a database cluster running on some physical server on another data center. Then you can create a service without pod selectors

<file yaml service-without-selector.yaml>
apiVersion: v1
kind: Service
metadata:
  name: my-db-service
spec:
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5432
</file>

As there is no selector, you need to create your own endpoint manually. The EndPoint matches a service by name, which means the endpoint you create must have the same name of your service. In this example, the name of the endpoint must be "my-db-service"

<file yaml endpoint.yaml>
apiVersion: v1
kind: Endpoints
metadata:
  name: my-db-service
subsets:
  - addresses:
      - ip: 192.0.2.42
    ports:
      - port: 5432
</file>

===== 8.3 Service Types  =====

For some parts of your application (for example, frontends) you may want to expose a Service onto an external IP address, that's outside of your cluster.

Kubernetes ServiceTypes allow you to specify what kind of "service" you want. The default is **ClusterIP**.

Service type values and their behaviors are:

  * **ClusterIP**: Exposes the Service on a cluster-internal IP. Choosing this value makes the Service only reachable from within the cluster. This is the default ServiceType.
  * **NodePort**: Exposes the Service on each Node's IP at a static port (the NodePort). A ClusterIP Service, to which the NodePort Service routes, is automatically created. You'll be able to contact the NodePort Service, from outside the cluster, by requesting <NodeIP>:<NodePort>.
  * **LoadBalancer**: Exposes the Service externally using a **cloud provider's load balancer** (e.g. aws, gcp, etc.). NodePort and ClusterIP Services, to which the external load balancer routes, are automatically created.
  * **ExternalName**: Maps the Service to the contents of the externalName field (e.g. foo.bar.example.com), by returning a CNAME record with its value. No proxying of any kind is set up. **Note: You need either kube-dns version 1.7 or CoreDNS version 0.0.8 or higher to use the ExternalName type.**


**You can also use Ingress to expose your Service**. Ingress is not a Service type, but it acts as the entry point for your cluster. We will give more details of Ingress in the next section.

==== 8.3.1 NodePort ====

If you set the service type to **NodePort**, the Kubernetes control plane allocates a port that you specified in .spec.ports[*].nodePort field. The port must be in the range specified by --service-node-port-range flag (default: 30000-32767). kube-proxies on each node match the node port (the same port number on every Node) with your Service port. 

If you want to specify particular IP(s) to proxy the port, you can set the --nodeport-addresses flag in kube-proxy to particular IP block(s); this is supported since Kubernetes v1.10. This flag takes a comma-delimited list of IP blocks (e.g. 10.0.0.0/8, 192.0.2.0/25) to specify IP address ranges that kube-proxy should consider as local to this node.

<file yaml service-nodeport.yaml>
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: NodePort
  selector:
    app: MyApp
  ports:
      # By default and for convenience, the `targetPort` is set to the same value as the `port` field.
    - port: 80
      targetPort: 80
      # Optional field
      # By default and for convenience, the Kubernetes control plane will allocate a port from a range (default: 30000-32767)
      nodePort: 30007
</file>
==== 8.3.2 LoadBalancer ====

The LoadBalancer config is provided by each cloud provider, for more details plz visit https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer

==== 8.3.3 ExternalName ====

**Services of type ExternalName map a Service to a DNS name**, not to a typical selector such as my-service or cassandra. You specify these Services with the spec.externalName parameter.

This Service definition, for example, maps the my-service Service in the prod namespace to my.database.example.com:
<file yaml service-externalName.yaml>
apiVersion: v1
kind: Service
metadata:
  name: my-service
  namespace: prod
spec:
  type: ExternalName
  externalName: my.database.example.com
</file>

===== 8.4 Virtual IPs and service proxies =====

Every node in a Kubernetes cluster runs a kube-proxy. kube-proxy is responsible for implementing a form of virtual IP for Services of type other than **ExternalName**.

Based on different version of k8s, the default implementation of proxy is different too.  
The default is :
  * "user space":  Before k8s v1.1.2
  * iptables: between v1.1.2 and v1.1.4
  * ipvs: after v1.1.4


==== 8.4.1 Why not use round-robin DNS? ====
A question that pops up every now and then is why Kubernetes relies on proxying to forward inbound traffic to backends. What about other approaches? For example, would it be possible to configure DNS records that have multiple A values (or AAAA for IPv6), and rely on round-robin name resolution?

There are a few reasons for using proxying for Services:

  * There is a long history of DNS implementations not respecting record TTLs, and caching the results of name lookups after they should have expired.
  * Some apps do DNS lookups only once and cache the results indefinitely.
  * Even if apps and libraries did proper re-resolution, the low or zero TTLs on the DNS records could impose a high load on DNS that then becomes difficult to manage.


===== 8.5 Service Topology =====

**Service Topology enables a service to route traffic based upon the Node topology of the cluster.** This can make the service more performant. Because by default, the query may be routed to any backend of the Service. And backend may run in another cluster or in another datacenter of other regions. **For example, a service can specify that traffic be preferentially routed to endpoints that are on the same Node as the client, or in the same availability zone**

The Service Topology feature resolves this by allowing the Service creator to define a policy for routing traffic based upon the Node labels for the originating and destination Nodes.

Consider a cluster with Nodes that are labeled with their hostname, zone name, and region name. Then you can set the topologyKeys values of a service to direct traffic as follows.

  * **Only to endpoints on the same node**, failing if no endpoint exists on the node: ["kubernetes.io/hostname"].
  * **Preferentially to endpoints on the same node, falling back to endpoints in the same zone**, followed by the same region, and failing otherwise: ["kubernetes.io/hostname", "topology.kubernetes.io/zone", "topology.kubernetes.io/region"]. This may be useful, for example, in cases where data locality is critical.
  * **Preferentially to the same zone, but fallback on any available endpoint if none are available within this zone**: ["topology.kubernetes.io/zone", "*"]

The below service definition prefers **node local**, **zonal, then regional endpoints but falls back to cluster wide endpoints.**
<file yaml service-topo.yaml>
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - "kubernetes.io/hostname"
    - "topology.kubernetes.io/zone"
    - "topology.kubernetes.io/region"
    - "*"
</file>

==== 8.5.1 Constraints ====

Service topology has the following constraints:
  * Service topology is not compatible with externalTrafficPolicy=Local, and therefore a Service cannot use both of these features. It is possible to use both features in the same cluster on different Services, just not on the same Service.
  * Valid topology keys are currently limited to kubernetes.io/hostname, topology.kubernetes.io/zone, and topology.kubernetes.io/region, but will be generalized to other node labels in the future.
  * Topology keys must be valid label keys and at most 16 keys may be specified.
  * The catch-all value, "*", must be the last value in the topology keys, if it is used.

===== 8.6 EndpointSlices =====

Since all network endpoints for a Service were stored in a single Endpoints resource, those resources could get quite large. For example, an Endpoint may have thousands of backend pods in it. That affected the performance of Kubernetes components (notably the master control plane) and resulted in significant amounts of network traffic and processing when Endpoints changed. EndpointSlices help you mitigate those issues as well as provide an extensible platform for additional features such as topological routing.

For more info: https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/
==== 8.6.1 EndpointSlice resources ====

**In Kubernetes, an EndpointSlice contains references to a set of network endpoints.** The control plane **automatically** creates EndpointSlices for any Kubernetes Service that has a selector specified. These EndpointSlices include references to all the Pods that match the Service selector. 

Just like when you define a service with a selector, an Endpoint is created automatically. If you define a service with service topology, an EndpointSlice is created automatically too. So most of the time, you don't need to define an EndpointSlice by yourself.


===== 8.7 Headless service =====

Sometimes you don't need **load-balancing** and **a single Service IP**. In this case, you can create a "headless" Services.

**Headless service is typically used with StatefulSets where the name of the pods are fixed.** This is useful in situations like when you're settling up a MySQL cluster where you need to know the name of the master. StatefulSets appends an ordinal number to the name of the pod and it will always assign the same ordinal number of the pod is restarted or migrated by the scheduler.

In the case of a regular Deployment, ReplicaSet appends a hash to the pod's name making addressing specific pods difficult.

So if your application is stateless then you will just use a 'regular' service because you don't care which pod you get. They're all the same.

In the following example, I will create a depoyment with 5 pods, a normal service and a headless service.
<file yaml deployment.yaml>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-deployment
  labels:
    app: api
spec:
  replicas: 5
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api
        image: eddiehale/hellonodeapi
        ports:
        - containerPort: 3000
</file>

<file yaml normal-service.yaml>
apiVersion: v1
kind: Service
metadata:
  name: normal-service
spec:
  selector:
    app: api
  ports:
    - protocol: TCP
      port: 80
      targetPort: 3000
</file>

<file yaml headless-service.yaml>
apiVersion: v1
kind: Service
metadata:
  name: headless-service
spec:
# if we don't specify a type. "type: ClusterIP" will be set as default. 
# Here we set cluterIP type with None to indicate this is a 
  clusterIP: None # <-- Don't forget!!
  selector:
    app: api
  ports:
    - protocol: TCP
      port: 80
      targetPort: 3000
</file>

After we apply the three above files. We can first check the created services
<code>
$ kubectl get svc -n user-pengfei

headless-service                      ClusterIP   None            <none>        80/TCP     11m
normal-service                        ClusterIP   10.233.22.13    <none>        80/TCP     11m

</code>

You can notice that headless-service does not have cluster IP. But you can still call this service on the network.

For example, we create a new pod called utils. And we will try ns-lookup in this pod to check normal-service and headless-service

<code>
# this command creat a pod and return an interactive shell 
$ kubectl run --rm utils -it --image eddiehale/utils --restart=Never bash
If you don't see a command prompt, try pressing enter.
root@utils:/# nslookup normal-service
Server:		169.254.25.10
Address:	169.254.25.10#53

Name:	normal-service.user-pengfei.svc.cluster.local
Address: 10.233.56.36

root@utils:/# nslookup headless-service
Server:		169.254.25.10
Address:	169.254.25.10#53

Name:	headless-service.user-pengfei.svc.cluster.local
Address: 10.233.119.4
Name:	headless-service.user-pengfei.svc.cluster.local
Address: 10.233.118.251
Name:	headless-service.user-pengfei.svc.cluster.local
Address: 10.233.104.4
Name:	headless-service.user-pengfei.svc.cluster.local
Address: 10.233.86.86
Name:	headless-service.user-pengfei.svc.cluster.local
Address: 10.233.121.127

</code>

You can notice, the normal service has only one IP which will be used as a load balancer to redirect queries to the pod. The headless service does not have IP, but directly expose the ip of the pods.
