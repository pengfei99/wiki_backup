====== 07: k8s pod controllers ======

In chapter [[employes:pengfei.liu:admin_system:container:k8s:06_deploy_k8s_objects|06: Deploy k8s objects]], we have seen how to deploy a pod manually. But most of the time, we will use a controller to deploy a pod for us. 


K8s has four types of controllers to manage pods:
  * ReplicationController, ReplicaSet, Deployment (For managing stateless pods)
  * StatefullSet (For managing stateful pods)
  * DaemonSet (For managing pods need to run on every single working node)
  * Job, CronJob


The most common controller to deploy pod is Deployment


===== 7.1 Deployment =====

Below is an example of a simple deployment

<file yaml ngix-deployment.yaml>
apiVersion: apps/v1
kind: Deployment
metadata:
  # define the name of this deployment
  name: nginx-deployment
  # define a label of this deployment, usefull to group a set of deployment
  labels: 
    app: pengfei-deployment-test
# spec of the deployment
spec:
  # defines which template this deployment uses, it must match the template(i.e. pod) label
  selector:
    matchLabels:
      app: pengfei-test
  # number of the replicas of the pod    
  replicas: 2
  # template(i.e. description) of the pod
  template:
    metadata:
      # label of the pod
      labels:
        app: pengfei-test
    spec:
      containers:
        # no 1 container of the pod
      - name: nginx-container
        image: nginx:1.7.9
        # set the limit of the pod resource, by default there is no limit
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 80
        imagePullPolicy: Always

</file>

To apply the above deployment

<code>
# the record option will save the command and the config details of the deployment
kubectl apply -f nginx-deployment.yaml --record

# To get all the registered history of a deployment
kubectl rollout history deployment.v1.apps/nginx-deployment

deployment.apps/nginx-deployment 
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=nginx-deployment.yaml --record=true
2         kubectl apply --filename=nginx-deployment.yaml --record=true

# To list the details of a particular
kubectl rollout history deployment.v1.apps/nginx-deployment --revision=2
</code>

You can check the deployment you just created

<code>
# check all deployment
kubectl get deployment --show-labels

# check all pods
kubectl get pods --show-labels

# get details of a deployment
kubectl describe deployment.v1.apps/nginx-deployment 
</code>


Note Do not change the **Pod-template-hash label**

The **pod-template-hash** label is added by the Deployment controller to every ReplicaSet that a Deployment creates or adopts.

This label ensures that child ReplicaSets of a Deployment do not overlap. It is generated by hashing the PodTemplate of the ReplicaSet and using the resulting hash as the label value that is added to the ReplicaSet selector, Pod template labels, and in any existing Pods that the ReplicaSet might have.


==== 7.1.1 Change deployment config via command ====

You can modify the deployment.yaml file to change the config. 
<code>
# you can modify the config directly from the server side
$ kubectl edit deployment.v1.apps/nginx-deployment

# you can modify your local config and re-apply it. 
</code>

And you can also use kubectl directly. Check the below examples

<code>
# update the container image, here nginx-deployment is the name of deployment, nginx-container is the name of container, nginx:1.16.1 is the new image name
kubectl set image deployment/nginx-deployment nginx-container=nginx:1.16.1 --record


# re-scale the deployment, note we did not set option record, so this command will not be registered 
$ kubectl scale deployment.v1.apps/nginx-deployment --replicas=6

deployment.apps/nginx-deployment scaled

# we can add an auto-scale to this deployment, note autoscale does not create a new RS.
$ kubectl autoscale deployment nginx-deployment --min=6 --max=10 --cpu-percent=80 --record

</code>


After the change, you can check out the rollout status of the deployment

<code>
# check out the rollout status of the deployment 
$ kubectl rollout status deployment/nginx-deployment

deployment "nginx-deployment" successfully rolled out

# You can noticed that for each modification, a new ReplicaSet is created
$ kubectl get rs --show-labels
NAME                                   DESIRED   CURRENT   READY   AGE     LABELS
nginx-deployment-59d95dccd7            0         0         0       52m     app=pengfei-test,pod-template-hash=59d95dccd7
nginx-deployment-5b45544d45            2         2         2       7m40s   app=pengfei-test,pod-template-hash=5b45544d45
nginx-deployment-5fc6c48565            0         0         0       35m     app=pengfei-test,pod-template-hash=5fc6c48565
</code>

==== 7.1.2 Undo changes ====

If you want to undo the changes, you can run this command

<code>
# this will rollback to previous config, and we can't record a undo
$ kubectl rollout undo deployment/nginx-deployment
</code>

You can set **.spec.revisionHistoryLimit** field in a Deployment to specify how many old ReplicaSets for this Deployment you want to retain. The rest will be garbage-collected in the background. By default, it is 10.

**Explicitly setting this field to 0, will result in cleaning up all the history of your Deployment thus that Deployment will not be able to roll back.**


===== 7.2 Jobs =====

A Job creates one or more Pods and ensures that **a specified number of them successfully terminate**. As pods successfully completed, the Job tracks the successful completions. When a specified number of successful completions is reached, the task (ie, Job) is complete. Deleting a Job will clean up the Pods it created.

A simple case is to create one Job object in order to reliably run one Pod to completion. The Job object will start a new Pod if the first Pod fails or is deleted (for example due to a node hardware failure or a node reboot).

You can also use a Job to run multiple Pods in parallel.

==== 7.2.1 A simple job ====

The following job create a pod with image perl and use perl to calculate the value of pi. Then Print the first 2000 number of pi value

<file yaml job.yaml>
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
  labels: 
   app: pengfei-job-test    
spec:
  template:
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
  # A job's spec are immutable, we can't change them after job creation. We need to delete old job, and submit new job.
  # completions default value is 1, it means if 1 pod complete and return 0. The job is considered finished succesfully.
  completions: 4
  # parallelism default value is 1, it means 1 pod can run in parallel. 
  parallelism: 2
  backoffLimit: 4
</file>

<code>
# Run the job
kubectl apply -f job.yaml 

# get job list
kubectl get jobs --show-labels

# decribe the job
kubectl describe jobs/pi

# get all pods related to a job
pods=$(kubectl get pods --selector=job-name=pi --output=jsonpath='{.items[*].metadata.name}')
echo $pods

# get the log of a job
kubectl logs $pods
</code>
==== 7.2.2 Writing a Job spec ====


As with all other Kubernetes config, a Job needs 
  * apiVersion
  * kind
  * metadata
  * spec.template : is a **pod template**. It has exactly the same schema as a Pod, except it is nested and does not have an apiVersion or kind. In addition to required fields for a Pod, a pod template in a Job must specify appropriate **labels** (see pod selector) and **an appropriate restart policy**.

Some rules on Job spec
  * **Its name must be a valid DNS subdomain name.**
  * **Pod RestartPolicy** can only equal to **Never** or **OnFailure**.


===== 7.3 CronJob =====

A CronJob creates Jobs on a repeating schedule.

One CronJob object is like one line of a crontab (cron table) file. It runs a job periodically on a given schedule, written in Cron format.

<file yaml cronjob.yaml>
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: pengfei-cronjob-hello
  labels:
    app: pengfei-cronjob
spec:
  # schedule defines how the job repeats, it uses the same syntax as the crontab, first arg is second, 2nd arg is minutes, 3: hour, 4: day 5: month
  # */1 means every second. If you want every second starts after 6 second, you write 6/1. 8/2 means every 2 second starts after 8 second
  schedule: "*/10 * * * *"
  # job template specify the job 

   # It stands for the deadline in seconds for starting the job if it misses its scheduled time for any reason. After the deadline, 
    # the cron job does not start the job. Jobs that do not meet their deadline in this way count as failed jobs. 
    # If this field is not specified, the jobs have no deadline.
  startingDeadlineSeconds: 10
   # if the job is long to finish, the schedule may start a new job without finishing the old one. Thus you need to set a policy to allow concurrency or
    # not.
    # It has three possible values
    # - "Allow" (default). 
    # - "Forbid" Ignore the new schedule job until the old job finishes
    # - "Replace" The new schedule job replaces the unfinish old job
  concurrencyPolicy: Forbid

  # You can suspend a job by setting suspend = true. default value is false
  suspend: true 

  # set the controller to save the number of succeed jobs, default value is 3
  successfulJobsHistoryLimit: 10

  # set the controller to save the number of failed jobs, default valie is 1
  failedJobsHistoryLimit: 1
  jobTemplate:
    metadata:
      name: subjob
      labels:
        app: pengfei-cronjob-subjob
    spec:
    # template specify the pod of the job
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            imagePullPolicy: IfNotPresent
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
</file>




<code>
# To apply this cronjob in a namespace
kubectl apply -f cronjob.yaml -n user-pengfei

# to list existing cronjob
kubectl get cronjob -n user-pengfei
</code>

As we said, cronjob is just a higher layer of jobs. So cronjob will create job

<code>
# to watch the job created by cronjob
kubectl get jobs --watch

# to see the log of a pod attached to a job
# Replace "hello-4111706356" with the job name in your system
pods=$(kubectl get pods --selector=job-name=pengfei-cronjob-hello-1607949840 --output=jsonpath={.items[*].metadata.name})
kubectl logs $pods
</code> 

To delete a cronjob

<code>
kubectl delete cronjob pengfei-cronjob-hello
</code>

==== 7.3.1 CronJob limitations ====

=== No guaranee to a job schedule ===

**A cron job creates a job object about once per execution time of its schedule**. **We say "about" because there are certain circumstances where two jobs might be created, or no job might be created.** We attempt to make these rare, but do not completely prevent them. Therefore, jobs should be idempotent.

**If startingDeadlineSeconds is set to a large value or left unset (the default) and if concurrencyPolicy is set to Allow, the jobs will always run at least once.**

=== Suspend automatic ===

For every CronJob, the CronJob Controller checks how many schedules it missed in the duration from its last scheduled time until now. **If there are more than 100 missed schedules, then it does not start the job and logs the error**
