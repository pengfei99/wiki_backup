====== Flume agent seq generator source, mem channel, hdfs sink ======

In this tutorial, we will build a flume agent which fetch data from a Sequence generator source. The sequence generator source is for test purpose only, don't use it in a production environment. 

===== Configure flume =====

As we said, this flume agent has a seq source, a mem channel and a hdfs sink

==== Sequence Generator Source ====


It is the source that generates the events continuously. It maintains a counter that starts from 0 and increments by 1. It is used for testing purpose. While configuring this source, you must provide values to the following properties:

  * Channels
  * Source type − seq

==== Channel ====

We are using the **memory channel**. To configure the memory channel, you must provide value to the type of the channel. Given below are the list of properties that you need to supply while configuring the memory channel:

  * **type** − It holds the type of the channel. In our example the type is MemChannel.
  * **Capacity** − It is the maximum number of events stored in the channel. Its default value is 100. (optional)
  * **TransactionCapacity** − It is the maximum number of events the channel accepts or sends. Its default is 100. (optional).

==== Sink ====

In this tutorial, we use an HDFS Sink which writes data into the HDFS. To configure this sink, you must provide the following details:

  * **Channel**
  * **type** : hdfs
  * **hdfs.path** : the path of the directory in HDFS where data is to be stored.

And we can provide some optional values based on the scenario. Given below are the optional properties of the HDFS sink that we are configuring in our application.

  * **fileType **: This is the required file format of our HDFS file. **SequenceFile**, **DataStream** and **CompressedStream** are the three types available with this stream. In our example, we are using the **DataStream**.
  * **writeFormat**: Could be either text or writable.
  * **batchSize**: It is the number of events written to a file before it is flushed into the HDFS. Its default value is 100.
  * **rollsize**: It is the file size to trigger a roll. Its default value is 100.
  * **rollCount**: It is the number of events written into the file before it is rolled. Its default value is 10.

===== Full flume agent conf =====

We put the following config into "/opt/flume/flume-1.9.0/conf/agent-example/seq-gen.conf". You can put it wherever you want, we do it like this just as a good practice.

<code>
# In this agent, we use a Sequence generator as the source, a memory channel, and hdfs as the sink

# Naming the components on the current agent 

SeqGenAgent.sources = SeqSource   
SeqGenAgent.channels = MemChannel 
SeqGenAgent.sinks = HDFS 
 
# Describing/Configuring the source 
SeqGenAgent.sources.SeqSource.type = seq
  
# Describing/Configuring the sink
# sink writes data into the HDFS. To configure this sink, you must provide the following details:
SeqGenAgent.sinks.HDFS.type = hdfs 
SeqGenAgent.sinks.HDFS.hdfs.path = hdfs://localhost:9000/tmp/seqgen_data
SeqGenAgent.sinks.HDFS.hdfs.filePrefix = log 
SeqGenAgent.sinks.HDFS.hdfs.rollInterval = 0
SeqGenAgent.sinks.HDFS.hdfs.rollCount = 10000
SeqGenAgent.sinks.HDFS.hdfs.fileType = DataStream 
 
# Describing/Configuring the channel 
SeqGenAgent.channels.MemChannel.type = memory 
SeqGenAgent.channels.MemChannel.capacity = 1000 
SeqGenAgent.channels.MemChannel.transactionCapacity = 100 
 
# Binding the source and sink to the channel 
SeqGenAgent.sources.SeqSource.channels = MemChannel
SeqGenAgent.sinks.HDFS.channel = MemChannel 

</code>


Now we need to run this flume agent

<code>
# the full command for launching the flume agent
flume-ng agent -f seq-gen.conf -n SeqGenAgent -Dflume.root.logger=INFO,console

# -f indicates where is the flume agent conf file
# -n indicates the flume agent name in the conf file
# -Dflume.root.logger=INFO,console means the log level is INFO, the output is redirected to console.
</code>