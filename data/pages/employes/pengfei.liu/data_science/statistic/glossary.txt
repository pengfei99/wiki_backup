====== Key concepts/words in statistics ======

===== 1. Skewness (偏度) =====


Skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. The skewness value can be positive or negative, or undefined.

Two types of skewness

negative skew: The left tail is longer; the mass of the distribution is concentrated on the right of the figure. The distribution is said to be left-skewed, left-tailed, or skewed to the left, despite the fact that the curve itself appears to be skewed or leaning to the right; left instead refers to the left tail being drawn out and, often, the mean being skewed to the left of a typical center of the data. A left-skewed distribution usually appears as a right-leaning curve
負偏態或左偏態：左側的尾部更長，分布的主體集中在右側。

positive skew: The right tail is longer; the mass of the distribution is concentrated on the left of the figure. The distribution is said to be right-skewed, right-tailed, or skewed to the right, despite the fact that the curve itself appears to be skewed or leaning to the left; right instead refers to the right tail being drawn out and, often, the mean being skewed to the right of a typical center of the data. A right-skewed distribution usually appears as a left-leaning curve.
正偏態或右偏態：右側的尾部更長，分布的主體集中在左側

===== 2. Median (中位數) =====

中位數（又稱中值，英语：Median），統計學中的專有名詞，代表一個樣本、種群或概率分佈中的一個數值，其可將數值集合劃分爲相等的上下兩部分
對於有限的數集，可以通過把所有觀察值高低排序後找出正中間的一個作爲中位數。如果觀察值有偶數個，則中位數不唯一，通常取最中間的兩個數值的平均數作爲中位數。


===== 3. Arithmetic Mean(算术平均数)/Average of data set =====


In mathematics and statistics, the arithmetic mean, or simply the mean or average when the context is clear, is the sum of a collection of numbers divided by the number of numbers in the collection.


===== 4. Median vs Arithmetic Mean =====


Data_set1 [11, 23, 30, 47, 56]
Data_set2 [11, 23, 30, 47, 52, 56]

Mean of Data_set1 = 11+23+30+47+56/5= 33
Median of Data_set1 = 30 (odd, so pick the only middle number )

Mean of Data_set1 = 11+23+30+47+52+56/6= 33
Median of Data_set1 = (30+47)/2  (even, so pick the two middle number and divided by 2  )

===== 5. Statistical distribution =====

Frequency distribution vs probability distribution

Normal(Gaussian) distribution is also called a bell-shaped curve.

===== 6. Statistic models =====

In this context, the model refers to a relationship. For example, a coin diameter and mass have a relation with the coin value(10 cents, 50, or 1 euro). The statistic function(equation) which describes this relation is called a model.

===== 7. P-value =====


A p-value is a probability that random chance generated the data or something else that is equal or rare.

For example, if we flip a coin twice, there are in total 4 results when we flip a coin twice (HH, HT, TH, TT). The probability of 2 heads(HH) is 0.25. 1 heads and 1 tails (0.5), 2 tails (0.25).

The P-value of HH=0.25(Probability of HH)+0.25(Probability of TT)=0.5.

Why we add the probability of TT because the probability of  TT is equal or less the probability of HH.


If we flip a coin 5 times. What’s the p-value of 5 Heads(HHHHH)?

P of (HHHHH)= 1/32 (Probability of HHHHH)+1/32(Probability of TTTTT) = 0.0625

Nothing else (HTTTT, HHTTT, etc.) has the same probability or rarer than HHHHH, but TTTTT. So we only add the probability of TTTTT.

The p-value of 4 Heads and 1 Tail?

Pr(HHHHT)=  5/32(Probability of HHHHT) + 5/32 (Probability of TTTTH) + 1/32(Probability of HHHHH) + 1/32 (Probability of TTTTT)   = 0.375            

The p value should be less than 0.05 to be called statistical significant. So all the above Heads and tails are not statistically significant. They are just random data

===== 8. Student’s T-test (T-test) =====

The purpose of a T-test is to eliminate bias and tell is there a

Questions you want to ask before you do t-test:

1.One-tailed or two-tailed t-test?
The one-tailed test will test either if the mean is significantly greater than X or less than X, but not both.

A two-tailed test will test both. The mean is considered significantly different from X if the test statistic is in the top 2.5% or bottom 2.5% of its probability distribution, resulting in a p-value less than 0.05.

2. Is the data paired or unpaired?

If we have a Height data of a set of men at age 5 and 30. For example

Bob 50 170
Dav 55 175

The two columns represent the same person, so there are paired.

If the two columns have nothing to do with each other, then it’s called unpaired data. 

===== 9. Geometric Mean(几何平均数) =====


The geometric mean applies only to numbers of the same sign. It is also often used for a set of numbers whose values are meant to be multiplied together or are exponential in nature, such as data on the growth of the human population or interest rates of financial investment.


===== 10. Standard deviation =====

In statistics, the standard deviation (SD, also represented by the lower case Greek letter sigma σ for the population standard deviation or the Latin letter s for the sample standard deviation) is a measure of the amount of variation or dispersion of a set of values.[1] A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range.

===== 11. Unit standard deviation =====


It means you are converting your data features from its original units (miles, dollars, elapsed time,...) to units of standard deviation. 

Suppose we want to predict house prices from two features: the number of bedrooms (integer unit) and size (in square meters unit), like the fictitious data bellow:

<code>

import numpy as np

X = np.array([[1, 65],[3, 130],[2, 80],[2, 70],[1, 50]])
Notice that each feature have very different mean and standard deviation

print("mean={}, std{}".format(X.mean(axis=0), X.std(axis=0))
Outputs: mean=[  1.83333333,  78.33333333]), std=[  0.68718427,  24.94438258])

</code>

Noticed that the feature size has mean and std more than 30x bigger than the number of bedrooms, this produces distortions in some algorithms calculation (like neural nets, svm, knn, etc) where some feature with larger values dominates completely the others with smaller values. To solve that, there is a common and very effective practice is to transform the data to units of standard deviation with zero-mean, that is, you subtract the mean and divides by the standard deviation, like bellow:

<code>
X_t = (X - X.mean(axis=0))/X.std(axis=0)
</code>

The variable X_t (X transformed) contains your features with unit standard deviations with zero mean, printing X_t you get:

<code>
array([[-1.21267813, -0.53452248],
       [ 1.69774938,  2.07127462],
       [ 0.24253563,  0.06681531],
       [ 0.24253563, -0.33407655],
       [-1.21267813, -1.13586028],
       [ 0.24253563, -0.13363062]])
# Look how the numbers in both features have all the same magnitude. If you print X_t mean and std now you get

mean=[  1.11022302e-16   2.08166817e-16], std=[ 1.  1.]
</code>


===== 12 Gradient decent =====

https://www.youtube.com/watch?v=sDv4f4s2SB8

When you have two or more derivatives of the same function, they are called **gradient**.  
===== 13 Stochastic Gradient decent =====

https://www.youtube.com/watch?v=vMh0zPT0tLI&vl=en

**Neural networks** are trained using stochastic gradient descent and require that you choose a **loss function** when designing and configuring your model.
===== 14 Derivative (导数) =====

https://www.youtube.com/watch?v=vloi4gsz7ZQ

Slop 