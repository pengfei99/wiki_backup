====== Transmart For Realism ======

===== Install Transmart =====

VM dedie a tranSMART : CCLinTransMartP01 (10.70.3.29)

OS : Ubuntu 14.04

The following install tutorial install an all in one transmart (r,postgres,etc.) on a vm. It's not optimal for data analysis.

==== Create linux account for transmart ====

To run the installation correctly, we need to create a user transmart in ubuntu

<code>
# set the password for your new user 'transmart'
# use defaults for the other values if you wish
sudo adduser transmart
 
# add the user transmart to the sudo group
sudo adduser transmart sudo
  
# log out and log back in with your new user
</code>

The installation script requrire sudo right, and may take more than 10 mins, to avoid sudo timeout during execution, I highly recommand that you change the default 10 mins sudo timeout.
 
change sudo timeout,
''sudo visudo''
Then, edit or add the following line, it means no more sudo timeout for all users

<code>
Defaults        env_reset,timestamp_timeout=-1
</code>

==== Get the installation script ====

You can use the script of transmart fondation and follow their instructions from here -> https://wiki.transmartfoundation.org/pages/viewpage.action?pageId=9535811

But it will fail, you can use the bioaster version which is based on the transmart fondation version but with bug corrected.

You can download it from here -> https://gitlab.in2p3.fr/bioaster/tranSMAT-Installation. 

==== Run the script ====

Login as transmart user, then goto transmart user home.
For example in my case, it's /home/transmart, you put the folder ''Scripts'' in it.

Then run ''./Scripts/install-ubuntu/InstallTransmart.sh 2>&1 | tee ~/install.log '' 

It will create a install.log file, and a transmart folder,

In transmart folder it will contain all the downloaded dependencies. 

The script may stop 2 times, the first time because after java install and java_home set, the terminal is not updated, it thinks java is not install, just rerun ''./Scripts/install-ubuntu/InstallTransmart.sh 2>&1 | tee ~/install.log '' .

The second time, when it install R dependencies, it will say "QDNAseq_1.10.0.tar.gz" can't be download, it's true, this package has been removed. 

To continue, you need to go to /home/transmart/transmart/transmart-data/R/
''vim /home/transmart/transmart/transmart-data/R/other_pkg.R ''

<code>
#find this line
url="http://bioconductor.org/packages/release/bioc/src/contrib/QDNAseq_1.10.0.tar.gz",

#Replace it by the follwoing line
url="http://bioconductor.org/packages/release/bioc/src/contrib/QDNAseq_1.12.0.tar.gz",

</code>


After the installation is finished, you can view the transmart

<code>http://<vm-ip>:8080/transmart</code>


===== Configure Transmart =====

transMart is released as a java war file, it requires a java container to run it. In our case, we use tomcat7, you can find the executable at ''/usr/share/tomcat7'', The conf and and war file is locate at ''/var/lib/tomcat7/''.

<code>
root@CCLinTransMartP01:/var/lib/tomcat7# ls 
common  conf  logs  policy  server  shared  webapps  work
</code>

To avoid exposing tomcat, we use apache2 as front end, and use ajp to interconnect apche and tomcat7

To enable ajp in tomcat7, ''vim /var/lib/tomcat7/conf/server.xml''
add or uncomment the following line.

<code> 
<Connector port="8009" enableLookups="false" protocol="AJP/1.3" redirectPort="8443" />
</code>

In apache2, we add a new virtual host.

3 module needs to be activate in apache2, ssl, rewrite, proxy-ajp

<code>
a2enmod ssl
a2enmod rewrite
a2enmod proxy_ajp
</code>

Then edit the virtual host to connect to tomcat7 hosted transmart,
''vim /etc/apache2/sites-available/transmart-ssl.conf''

<code>
<VirtualHost *:80>

  Redirect permanent / https://transmart.bioaster.org/

  CustomLog /var/log/transmart/access.log combined
  
  ErrorLog /var/log/transmart/error.log

</VirtualHost>

NameVirtualHost *:443

<VirtualHost *:443>
    
    ServerName transmart.bioaster.org

    SSLEngine on
    SSLProtocol all -SSLv2
    SSLCipherSuite 
    ALL:!ADH:!EXPORT:!SSLv2:RC4+RSA:+HIGH:+MEDIUM:+LOW
    SSLCertificateFile /etc/apache2/ssl/cert.pem
    SSLCertificateKeyFile /etc/apache2/ssl/private.key

    ErrorDocument 503 /503.html

    Include /etc/apache2/custom-conf/transmart.conf

</VirtualHost>

</code>

''vim /etc/apache2/custom-conf/transmart.conf''

<code>
RewriteEngine On
  RewriteCond %{REQUEST_URI}  !^/transmart/.*
  RewriteRule ^/.* /transmart/ [R,L]



	<Location /transmart>
		ProxyPass ajp://127.0.0.1:8009/transmart
		ProxyPassReverse ajp://127.0.0.1:8009/transmart
	</Location>
</code>

You also need to put the certificate and private key in /etc/apache2/ssl/

Now, restart the apache and tomcat7

''service tomcat7 restart''

''service apache2 restart''

===== Optimize tomcat =====
transmart requires many memory, the default tomcat set up can't run transmart smoothly.

To increase the heap and pem memory size of tomcat, goto /usr/share/tomcat7/bin

''touch /usr/share/tomcat7/bin/setenv.sh''

''vim /usr/share/tomcat7/bin/setenv.sh''

<code>
export JAVA_OPTS="-Dfile.encoding=UTF-8 -Xms512m -Xmx8192m -XX:PermSize=256m -XX:MaxPermSize=2048m"
</code>

==== Transmart web application and database config ====

The config file of transmart is locate at /usr/share/tomcat7/.grails/transmartConfig

<code>
root@CCLinTransMartP01:/usr/share/tomcat7/.grails/transmartConfig# ls -lah
-rw-r--r-- 1 tomcat7 tomcat7 1.5K May  3 11:50 BuildConfig.groovy
-rw-r--r-- 1 tomcat7 tomcat7  32K May  3 11:50 Config.groovy
-rw-r--r-- 1 tomcat7 tomcat7 1.6K May  3 11:50 DataSource.groovy
</code>

The Config.groovy is the main config of transmart

The DataSource.groovy is the data base config of transmart



===== Data Curation =====

===== Data Loading =====

==== Access aux curation server on etriks platform====

To load data in bioaster eTRIKS platform, you need to connect to the data curation server first.

ssh <userName>@ssh.etriks.org

ssh <userName>@curation.bioaster.etriks.org

==== Curation server on transmart.bioaster.org ====

To load data in transmart.bioaster.org, you need to connect to transmart.bioaster.org as user 'transmart'

In the home of transmart, you can find a folder training. You can find the data (to be loaded to transmart) and loading script in it.
Data is organized by study name, it can contain clinical, gene_expression and annotaion. For more details, see the next section.

The loading script dependens on the etl_scipt. The etl_scripts are located at /usr/share/transmart-data-loading/ETL_scripts


==== Requirements ====
The transmart loading process use pentaho (i.e. http://www.pentaho.com/) kettle script. 

The script can be found at owncloud, the repo name is Kettle-ETL.
It contains all the dependance which we will use in the loading script.

==== Load clinical data ====

With the transmart requirements, all the data should be orgnized by study. In one study, you can have clinical data, gene-expression, gene-annotation (platform dependent).

The tree should like this:

<code>
GSE4382
├── annotation
│   └── GSE4382PDM.txt
├── clinical
│   ├── Excluding_mapping.txt
│   ├── GSE4382.columns
│   ├── GSE4382_raw.txt
│   └── Word_mapping.txt
└── gene_expression
    ├── GSE4382_mRNA.txt
    └── GSE4382.subject_mapping
</code>

**GSE4382** is the study name. 

**In annotaion**, you put the gene annotation file(i.e. GSE4382PDM.txt).

**In clinical**, you have four files,

Excluding_mapping.txt : exclude column in raw.txt which you don't want to load to tranSMART

GSE4382.columns : Mapping of column in raw.txt and tranSMART tree

GSE4382_raw.txt : raw data of patient clinical info 

Word_mapping.txt : change variable name in raw.txt

**In gene_expression**, you have two files,

GSE4382_mRNA.txt : raw data of gene expression. (PS. To load into transmart, the gene expression value must be in [-2.5, 2.5], as a result, for the raw data which not in this format, we have to do log on the gene expression value.)


GSE4382.subject_mapping : mapping of gene expression and subject(i.e. patient)

==== Work flow for loading a study ====
  - Load clinical data
  - Load platform of gene expression (gene annotation file(i.e. GSE4382PDM.txt))
  - Load gene expression with the platform indexe

=== Loading script ===

There are three principal loading(e.g. clinical, gene-annotaion and gene-expression). For each loading, we have a loading script for it.

Before you start your loading script, you need to setup your kettle env in your home.

<code>
$ cd
$ mkdir .kettle
$ vim .kettle/kettle.properties
</code>

Then put the following code in it.

<code>
DEAPP_DB_USER=deapp
DEAPP_DB_PWD=<password>
BIOMART_DB_NAME=transmart
BIOMART_DB_PORT=<PORT>
BIOMART_DB_SERVER=<server>
BIOMART_PWD=<password>
BIOMART_USER=biomart
DEAPP_DB_NAME=transmart
DEAPP_DB_PORT=<PORT>
DEAPP_DB_SERVER=<server>
DEAPP_PWD=<password>
DEAPP_USER=deapp
KETTLE_BATCHING_ROWSET=N
KETTLE_CARTE_OBJECT_TIMEOUT_MINUTES=1440
KETTLE_CHANNEL_LOG_DB=
KETTLE_CHANNEL_LOG_SCHEMA=
KETTLE_CHANNEL_LOG_TABLE=
KETTLE_CORE_JOBENTRIES_FILE=
KETTLE_CORE_STEPS_FILE=
KETTLE_EMPTY_STRING_DIFFERS_FROM_NULL=N
KETTLE_JOBENTRY_LOG_DB=
KETTLE_JOBENTRY_LOG_SCHEMA=
KETTLE_JOBENTRY_LOG_TABLE=
KETTLE_JOB_LOG_DB=
KETTLE_JOB_LOG_SCHEMA=
KETTLE_JOB_LOG_TABLE=
KETTLE_LOG_SIZE_LIMIT=0
KETTLE_MAX_JOB_ENTRIES_LOGGED=1000
KETTLE_MAX_JOB_TRACKER_SIZE=1000
KETTLE_MAX_LOGGING_REGISTRY_SIZE=1000
KETTLE_MAX_LOG_SIZE_IN_LINES=5000
KETTLE_MAX_LOG_TIMEOUT_IN_MINUTES=1440
KETTLE_PLUGIN_CLASSES=
KETTLE_ROWSET_GET_TIMEOUT=50
KETTLE_ROWSET_PUT_TIMEOUT=50
KETTLE_SHARED_OBJECTS=
KETTLE_STEP_LOG_DB=
KETTLE_STEP_LOG_SCHEMA=
KETTLE_STEP_LOG_TABLE=
KETTLE_STEP_PERFORMANCE_SNAPSHOT_LIMIT=0
KETTLE_TRANS_LOG_DB=
KETTLE_TRANS_LOG_SCHEMA=
KETTLE_TRANS_LOG_TABLE=
KETTLE_TRANS_PERFORMANCE_LOG_DB=
KETTLE_TRANS_PERFORMANCE_LOG_SCHEMA=
KETTLE_TRANS_PERFORMANCE_LOG_TABLE=
TM_CZ_DB_NAME=transmart
TM_CZ_DB_PORT=<PORT>
TM_CZ_DB_PWD=<password>
TM_CZ_DB_SERVER=<server>
TM_CZ_DB_USER=tm_cz
TM_LZ_DB_NAME=transmart
TM_LZ_DB_PORT=<PORT>
TM_LZ_DB_PWD=<password>
TM_LZ_DB_SERVER=<server>
TM_LZ_DB_USER=tm_lz
TM_WZ_DB_NAME=transmart
TM_WZ_DB_PORT=<PORT>
TM_WZ_DB_PWD=<password>
TM_WZ_DB_SERVER=<server>
TM_WZ_DB_USER=tm_wz
BACKOUT_DB_PWD=<password>
BACKOUT_DB_USER=tm_cz
</code>

To avoid type login password during loading, you can creat .pgpass in your home. It should look like this

<code>
<db-url>:<port>:<db-name>:<login>:<pwd>
pgsql.etriks.org:5472:transmart:tm_cz:tm_cz
</code>

**load_clinical_data.sh**

<code>
#  JAVA_HOME variable must be set if none exists globally
# export JAVA_HOME=/mnt/CinderFileShare/jdk1.6.0_31
set -x
/mnt/curation01/ETL_scripts/data-integration/kitchen.sh -norep=Y -file=/mnt/curation01/ETL_scripts/Kettle-ETL/create_clinical_data.kjb -log=/mnt/homedirs/users/p.liu/training/logs/load_clinical_data.log \
-param:STUDY_ID=GSE4382 \
-param:DATA_LOCATION=/mnt/homedirs/users/p.liu/training/GSE4382/clinical \
-param:COLUMN_MAP_FILE=GSE4382.columns \
-param:LOAD_TYPE=I \
-param:SECURITY_REQUIRED=N \
-param:SORT_DIR=/mnt/homedirs/users/p.liu/tmp/ \
-param:PSQL_PATH=/usr/bin/psql \
-param:TOP_NODE="\Public Studies\GSE4382" \
-param:WORD_MAP_FILE=Word_mapping.txt \
-param:RECORD_EXCLUSION_FILE=
</code>

**load_GEX_annotation.sh**

<code>
#  JAVA_HOME variable must be set if none exists globally
# export JAVA_HOME=/mnt/CinderFileShare/jdk1.6.0_27
#
set -x
/mnt/curation01/ETL_scripts/data-integration/kitchen.sh -norep=Y -file=/mnt/curation01/ETL_scripts/Kettle-ETL/load_annotation.kjb -log=/mnt/homedirs/users/p.liu/training/logs/load_annotation.log \
-param:DATA_LOCATION=/mnt/homedirs/users/p.liu/training/GSE4382/annotation \
-param:SOURCE_FILENAME="GSE4382PDM.txt" \
-param:GPL_ID=GSE4382PDM \
-param:ANNOTATION_TITLE=Custom_Array_Stanford_Microarray_Database \
-param:ANNOTATION_DATE=2012/01/01 \
-param:ANNOTATION_RELEASE=1 \
-param:DATA_SOURCE=A  \
-param:PROBE_COL=2 \
-param:GENE_ID_COL=4 \
-param:GENE_SYMBOL_COL=3 \
-param:ORGANISM_COL=5 \
-param:SKIP_ROWS=1 \
-param:SORT_DIR=/mnt/homedirs/users/p.liu/tmp \
-param:BULK_LOADER_PATH=/usr/bin/psql \
-param:LOAD_TYPE=I \
-param:EMBEDDED_GENE_TABLE=N \
-param:GENETAB_DELIM=// \
-param:GENETAB_ID_COL=-1 \
-param:GENETAB_REC_DELIM=/// \
-param:GENETAB_SYMBOL_COL=-1
</code>

**load_gene_expression_data.sh**

<code>
#  JAVA_HOME variable must be set if none exists globally
#export JAVA_HOME=/usr
# $1=Disease, $2=Study_ID, $3=Auther(year) $4=DATA_TYPE $5=Data_folder $6=Log_base $7=Source_CD
set -x
/mnt/curation01/ETL_scripts/data-integration/kitchen.sh -norep=Y -file=/mnt/curation01/ETL_scripts/Kettle-ETL/load_gene_expression_data.kjb -log=/mnt/homedirs/users/p.liu/training/logs/load_gene_expression_data.log \
-param:STUDY_ID=GSE4382 \
-param:DATA_FILE_PREFIX=GSE4382 \
-param:DATA_LOCATION=/mnt/homedirs/users/p.liu/training/GSE4382/gene_expression \
-param:DATA_TYPE=L \
-param:FilePivot_LOCATION=${HOME}/training/Loading \
-param:LOAD_TYPE=L \
-param:LOG_BASE=2 \
-param:MAP_FILENAME="GSE4382.subject_mapping" \
-param:SAMPLE_REMAP_FILENAME=NOSAMPLEREMAP \
-param:SECURITY_REQUIRED=N \
-param:SORT_DIR=/mnt/homedirs/users/p.liu/tmp \
-param:SOURCE_CD=GEO \
-param:BULK_LOADER_PATH=/usr/bin/psql \
-param:TOP_NODE="\Public Studies\GSE4382" \
</code>

**PS: You must load gene annotation first,then gene-expression**

==== Verification and deletion ====

Normally, if everything goes well, you should see your study in the transmart front end (https://bioaster.etriks.org/transmart/login/auth).

if not, you can go verify in the data base.

To verify the gene-annotation, 

<code>
psql -h <db-url> -p <port> -d transmart -U tm_cz
select * from deapp.de_gpl_info;
</code>

To verify the job status and errors

<code>
select * from tm_cz.cz_job_audit;
select * from tm_cz.cz_job_error;
</code>

If you are not happy with the result, you can delete your study with 

<code>
select tm_cz.i2b2_backout_trial('<study_id>','',0);
</code>


